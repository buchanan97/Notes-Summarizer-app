Programming Languages: Application and Interpretation Version Second Edition Shriram Krishnamurthi April 14, 2017 Contents 1 Introduction 7 1.1 Our Philosophy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.2 The Structure of This Book . . . . . . . . . . . . . . . . . . . . . . . 7 1.3 The Language of This Book . . . . . . . . . . . . . . . . . . . . . . 7 2 Everything (We Will Say) About Parsing 10 2.1 A Lightweight, Built-In First Half of a Parser . . . . . . . . . . . . . 10 2.2 A Convenient Shortcut . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.3 Types for Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.4 Completing the Parser . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.5 Coda . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 3 A First Look at Interpretation 13 3.1 Representing Arithmetic . . . . . . . . . . . . . . . . . . . . . . . . 14 3.2 Writing an Interpreter . . . . . . . . . . . . . . . . . . . . . . . . . . 14 3.3 Did You Notice? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 3.4 Growing the Language . . . . . . . . . . . . . . . . . . . . . . . . . 16 4 A First Taste of Desugaring 16 4.1 Extension: Binary Subtraction . . . . . . . . . . . . . . . . . . . . . 17 4.2 Extension: Unary Negation . . . . . . . . . . . . . . . . . . . . . . . 18 5 Adding Functions to the Language 19 5.1 Deﬁning Data Representations . . . . . . . . . . . . . . . . . . . . . 19 5.2 Growing the Interpreter . . . . . . . . . . . . . . . . . . . . . . . . . 21 5.3 Substitution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 5.4 The Interpreter, Resumed . . . . . . . . . . . . . . . . . . . . . . . . 23 5.5 Oh Wait, There’s More! . . . . . . . . . . . . . . . . . . . . . . . . . 25 6 From Substitution to Environments 25 6.1 Introducing the Environment . . . . . . . . . . . . . . . . . . . . . . 26 6.2 Interpreting with Environments . . . . . . . . . . . . . . . . . . . . . 27 6.3 Deferring Correctly . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 6.4 Scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 6.4.1 How Bad Is It? . . . . . . . . . . . . . . . . . . . . . . . . . 30 6.4.2 The Top-Level Scope . . . . . . . . . . . . . . . . . . . . . . 31 6.5 Exposing the Environment . . . . . . . . . . . . . . . . . . . . . . . 31 7 Functions Anywhere 31 7.1 Functions as Expressions and Values . . . . . . . . . . . . . . . . . . 32 7.2 Nested What? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 7.3 Implementing Closures . . . . . . . . . . . . . . . . . . . . . . . . . 37 7.4 Substitution, Again . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 7.5 Sugaring Over Anonymity . . . . . . . . . . . . . . . . . . . . . . . 39 8 Mutation: Structures and Variables 41 8.1 Mutable Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 8.1.1 A Simple Model of Mutable Structures . . . . . . . . . . . . . 41 8.1.2 Scaffolding . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 8.1.3 Interaction with Closures . . . . . . . . . . . . . . . . . . . . 43 8.1.4 Understanding the Interpretation of Boxes . . . . . . . . . . . 44 8.1.5 Can the Environment Help? . . . . . . . . . . . . . . . . . . . 46 8.1.6 Introducing the Store . . . . . . . . . . . . . . . . . . . . . . 48 8.1.7 Interpreting Boxes . . . . . . . . . . . . . . . . . . . . . . . . 49 8.1.8 The Bigger Picture . . . . . . . . . . . . . . . . . . . . . . . 54 8.2 Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 8.2.1 Terminology . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 8.2.2 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 8.2.3 Interpreting Variables . . . . . . . . . . . . . . . . . . . . . . 58 8.3 The Design of Stateful Language Operations . . . . . . . . . . . . . . 59 8.4 Parameter Passing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 9 Recursion and Cycles: Procedures and Data 62 9.1 Recursive and Cyclic Data . . . . . . . . . . . . . . . . . . . . . . . 62 9.2 Recursive Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 9.3 Premature Observation . . . . . . . . . . . . . . . . . . . . . . . . . 65 9.4 Without Explicit State . . . . . . . . . . . . . . . . . . . . . . . . . . 66 10 Objects 67 10.1 Objects Without Inheritance . . . . . . . . . . . . . . . . . . . . . . 67 10.1.1 Objects in the Core . . . . . . . . . . . . . . . . . . . . . . . 68 10.1.2 Objects by Desugaring . . . . . . . . . . . . . . . . . . . . . 69 10.1.3 Objects as Named Collections . . . . . . . . . . . . . . . . . 69 10.1.4 Constructors . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 10.1.5 State . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 10.1.6 Private Members . . . . . . . . . . . . . . . . . . . . . . . . 71 10.1.7 Static Members . . . . . . . . . . . . . . . . . . . . . . . . . 72 10.1.8 Objects with Self-Reference . . . . . . . . . . . . . . . . . . 72 10.1.9 Dynamic Dispatch . . . . . . . . . . . . . . . . . . . . . . . . 73 10.2 Member Access Design Space . . . . . . . . . . . . . . . . . . . . . 75 10.3 What (Goes In) Else? . . . . . . . . . . . . . . . . . . . . . . . . . . 75 10.3.1 Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 10.3.2 Prototypes . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 10.3.3 Multiple Inheritance . . . . . . . . . . . . . . . . . . . . . . . 78 10.3.4 Super-Duper! . . . . . . . . . . . . . . . . . . . . . . . . . . 79 10.3.5 Mixins and Traits . . . . . . . . . . . . . . . . . . . . . . . . 79 11 Memory Management 81 11.1 Garbage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 11.2 What is “Correct” Garbage Recovery? . . . . . . . . . . . . . . . . . 81 11.3 Manual Reclamation . . . . . . . . . . . . . . . . . . . . . . . . . . 82 11.3.1 The Cost of Fully-Manual Reclamation . . . . . . . . . . . . 82 11.3.2 Reference Counting . . . . . . . . . . . . . . . . . . . . . . . 83 11.4 Automated Reclamation, or Garbage Collection . . . . . . . . . . . . 84 11.4.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 11.4.2 Truth and Provability . . . . . . . . . . . . . . . . . . . . . . 84 11.4.3 Central Assumptions . . . . . . . . . . . . . . . . . . . . . . 85 11.5 Convervative Garbage Collection . . . . . . . . . . . . . . . . . . . . 86 11.6 Precise Garbage Collection . . . . . . . . . . . . . . . . . . . . . . . 87 12 Representation Decisions 87 12.1 Changing Representations . . . . . . . . . . . . . . . . . . . . . . . 87 12.2 Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 12.3 Changing Meaning . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 12.4 One More Example . . . . . . . . . . . . . . . . . . . . . . . . . . . 90 13 Desugaring as a Language Feature 90 13.1 A First Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 13.2 Syntax Transformers as Functions . . . . . . . . . . . . . . . . . . . 92 13.3 Guards . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94 13.4 Or: A Simple Macro with Many Features . . . . . . . . . . . . . . . 95 13.4.1 A First Attempt . . . . . . . . . . . . . . . . . . . . . . . . . 95 13.4.2 Guarding Evaluation . . . . . . . . . . . . . . . . . . . . . . 97 13.4.3 Hygiene . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 13.5 Identiﬁer Capture . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99 13.6 Inﬂuence on Compiler Design . . . . . . . . . . . . . . . . . . . . . 101 13.7 Desugaring in Other Languages . . . . . . . . . . . . . . . . . . . . . 101 14 Control Operations 102 14.1 Control on the Web . . . . . . . . . . . . . . . . . . . . . . . . . . . 102 14.1.1 Program Decomposition into Now and Later . . . . . . . . . . 103 14.1.2 A Partial Solution . . . . . . . . . . . . . . . . . . . . . . . . 104 14.1.3 Achieving Statelessness . . . . . . . . . . . . . . . . . . . . . 106 14.1.4 Interaction with State . . . . . . . . . . . . . . . . . . . . . . 107 14.2 Continuation-Passing Style . . . . . . . . . . . . . . . . . . . . . . . 109 14.2.1 Implementation by Desugaring . . . . . . . . . . . . . . . . . 109 14.2.2 Converting the Example . . . . . . . . . . . . . . . . . . . . . 114 14.2.3 Implementation in the Core . . . . . . . . . . . . . . . . . . . 115 14.3 Generators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117 14.3.1 Design Variations . . . . . . . . . . . . . . . . . . . . . . . . 117 14.3.2 Implementing Generators . . . . . . . . . . . . . . . . . . . . 118 14.4 Continuations and Stacks . . . . . . . . . . . . . . . . . . . . . . . . 120 14.5 Tail Calls . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122 14.6 Continuations as a Language Feature . . . . . . . . . . . . . . . . . . 123 14.6.1 Presentation in the Language . . . . . . . . . . . . . . . . . . 125 14.6.2 Deﬁning Generators . . . . . . . . . . . . . . . . . . . . . . . 125 14.6.3 Deﬁning Threads . . . . . . . . . . . . . . . . . . . . . . . . 127 14.6.4 Better Primitives for Web Programming . . . . . . . . . . . . 130 15 Checking Program Invariants Statically: Types 130 15.1 Types as Static Disciplines . . . . . . . . . . . . . . . . . . . . . . . 132 15.2 A Classical View of Types . . . . . . . . . . . . . . . . . . . . . . . 133 15.2.1 A Simple Type Checker . . . . . . . . . . . . . . . . . . . . . 133 15.2.2 Type-Checking Conditionals . . . . . . . . . . . . . . . . . . 138 15.2.3 Recursion in Code . . . . . . . . . . . . . . . . . . . . . . . . 138 15.2.4 Recursion in Data . . . . . . . . . . . . . . . . . . . . . . . . 141 15.2.5 Types, Time, and Space . . . . . . . . . . . . . . . . . . . . . 143 15.2.6 Types and Mutation . . . . . . . . . . . . . . . . . . . . . . . 145 15.2.7 The Central Theorem: Type Soundness . . . . . . . . . . . . . 145 15.3 Extensions to the Core . . . . . . . . . . . . . . . . . . . . . . . . . 147 15.3.1 Explicit Parametric Polymorphism . . . . . . . . . . . . . . . 147 15.3.2 Type Inference . . . . . . . . . . . . . . . . . . . . . . . . . 153 15.3.3 Union Types . . . . . . . . . . . . . . . . . . . . . . . . . . . 163 15.3.4 Nominal Versus Structural Systems . . . . . . . . . . . . . . . 168 15.3.5 Intersection Types . . . . . . . . . . . . . . . . . . . . . . . . 169 15.3.6 Recursive Types . . . . . . . . . . . . . . . . . . . . . . . . . 170 15.3.7 Subtyping . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171 15.3.8 Object Types . . . . . . . . . . . . . . . . . . . . . . . . . . 175 16 Checking Program Invariants Dynamically: Contracts 177 16.1 Contracts as Predicates . . . . . . . . . . . . . . . . . . . . . . . . . 179 16.2 Tags, Types, and Observations on Values . . . . . . . . . . . . . . . . 180 16.3 Higher-Order Contracts . . . . . . . . . . . . . . . . . . . . . . . . . 181 16.4 Syntactic Convenience . . . . . . . . . . . . . . . . . . . . . . . . . 185 16.5 Extending to Compound Data Structures . . . . . . . . . . . . . . . . 186 16.6 More on Contracts and Observations . . . . . . . . . . . . . . . . . . 187 16.7 Contracts and Mutation . . . . . . . . . . . . . . . . . . . . . . . . . 187 16.8 Combining Contracts . . . . . . . . . . . . . . . . . . . . . . . . . . 188 16.9 Blame . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189 17 Alternate Application Semantics 193 17.1 Lazy Application . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194 17.1.1 A Lazy Application Example . . . . . . . . . . . . . . . . . . 194 17.1.2 What Are Values? . . . . . . . . . . . . . . . . . . . . . . . . 195 17.1.3 What Causes Evaluation? . . . . . . . . . . . . . . . . . . . . 196 17.1.4 An Interpreter . . . . . . . . . . . . . . . . . . . . . . . . . . 197 17.1.5 Laziness and Mutation . . . . . . . . . . . . . . . . . . . . . 199 17.1.6 Caching Computation . . . . . . . . . . . . . . . . . . . . . . 199 17.2 Reactive Application . . . . . . . . . . . . . . . . . . . . . . . . . . 199 17.2.1 Motivating Example: A Timer . . . . . . . . . . . . . . . . . 200 17.2.2 Callback Types are Four-Letter Words . . . . . . . . . . . . . 201 17.2.3 The Alternative: Reactive Languages . . . . . . . . . . . . . . 202 17.2.4 Implementing Transparent Reactivity . . . . . . . . . . . . . . 203 17.3 Backtracking Application . . . . . . . . . . . . . . . . . . . . . . . . 205 17.3.1 Searching for Satisfaction . . . . . . . . . . . . . . . . . . . . 205 1 Introduction 1.1 Our Philosophy Please watch the video on YouTube. Someday there will be a textual description here instead. 1.2 The Structure of This Book Unlike some other textbooks, this one does not follow a top-down narrative. Rather it has the ﬂow of a conversation, with backtracking. We will often build up programs incrementally, just as a pair of programmers would. We will include mistakes, not because I don’t know the answer, but because this is the best way for you to learn . Including mistakes makes it impossible for you to read passively: you must instead engage with the material, because you can never be sure of the veracity of what you’re reading. At the end, you’ll always get to the right answer. However, this non-linear path is more frustrating in the short term (you will often be tempted to say, “Just tell me the answer, already!”), and it makes the book a poor reference guide (you can’t open up to a random page and be sure what it says is correct). However, that feeling of frustration is the sensation of learning. I don’t know of a way around it. At various points you will encounter this: Exercise This is an exercise. Do try it. This is a traditional textbook exercise. It’s something you need to do on your own. If you’re using this book as part of a course, this may very well have been assigned as homework. In contrast, you will also ﬁnd exercise-like questions that look like this: Do Now! There’s an activity here! Do you see it? When you get to one of these, stop. Read, think, and formulate an answer before you proceed. You must do this because this is actually an exercise , but the answer is already in the book—most often in the text immediately following (i.e., in the part you’re reading right now)—or is something you can determine for yourself by running a program. If you just read on, you’ll see the answer without having thought about it (or not see it at all, if the instructions are to run a program), so you will get to neither (a) test your knowledge, nor (b) improve your intuitions. In other words, these are additional, explicit attempts to encourage active learning. Ultimately, however, I can only encourage it; it’s up to you to practice it. 1.3 The Language of This Book The main programming language used in this book is Racket. Like with all operating systems, however, Racket actually supports a host of programming languages, so you must tell Racket which language you’re programming in. You inform the Unix shell by writing a line like #!/bin/sh at the top of a script; you inform the browser by writing, say, <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" ...> Similarly, Racket asks that you declare which language you will be using. Racket languages can have the same parenthetical syntax as Racket but with a different semantics; the same semantics but a different syntax; or different syntax and semantics. Thus every Racket program begins with #lang followed by the name of some language: by default, it’s Racket (written as racket ). In this book we’ll almost always use the In DrRacket v. 5.3, go to Language, then Choose Language, and select “Use the language declared in the source”.language plai-typed . When we deviate we’ll say so explicitly, so unless indicated otherwise, put #lang plai-typed at the top of every ﬁle (and assume I’ve done the same). TheTyped PLAI language differs from traditional Racket most importantly by being statically typed. It also gives you some useful new constructs: define-type , type-case , and test . Here’s an example of each in use. We can introduce new There are additional commands for controlling the output of testing, for instance. Be sure to read the documentation for the language In DrRacket v. 5.3, go to Help, then Help Desk, and in the Help Desk search bar, type “plai-typed”.datatypes: (define-type MisspelledAnimal [caml (humps : number)] [yacc (height : number)]) You can roughly think of this as analogous to the following in Java: an abstract class MisspelledAnimal and two concrete sub-classes caml andyacc , each of which has one numeric constructor argument named humps andheight , respectively. In this language, we construct instances as follows: (caml 2) (yacc 1.9) As the name suggests, define-type creates a type of the given name. We can use this when, for instance, binding the above instances to names: (define ma1 : MisspelledAnimal (caml 2)) (define ma2 : MisspelledAnimal (yacc 1.9)) In fact you don’t need these particular type declarations, because Typed PLAI will infer types for you here and in many other cases. Thus you could just as well have written (define ma1 (caml 2)) (define ma2 (yacc 1.9)) but we prefer to write explicit type declarations as a matter of both discipline and comprehensibility when we return to programs later. The type names can even be used recursively, as we will see repeatedly in this book (for instance, section 2.4). The language provides a pattern-matcher for use when writing expressions, such as a function’s body: (define (good? [ma : MisspelledAnimal]) : boolean (type-case MisspelledAnimal ma [caml (humps) (>= humps 2)] [yacc (height) (> height 2.1)])) In the expression (>= humps 2) , for instance, humps is the name given to whatever value was given as the argument to the constructor caml . Finally, you should write test cases, ideally before you’ve deﬁned your function, but also afterwards to protect against accidental changes: (test (good? ma1) #t) (test (good? ma2) #f) When you run the above program, the language will give you verbose output telling you both tests passed. Read the documentation to learn how to suppress most of these messages. Here’s something important that is obscured above. We’ve used the same name, humps (and height ), in both the datatype deﬁnition and in the ﬁelds of the patternmatch. This is absolutely unnecessary because the two are related by position , not name. Thus, we could have as well written the function as (define (good? [ma : MisspelledAnimal]) : boolean (type-case MisspelledAnimal ma [caml (h) (>= h 2)] [yacc (h) (> h 2.1)])) Because each his only visible in the case branch in which it is introduced, the two hs do not in fact clash. You can therefore use convention and readability to dictate your choices. In general, it makes sense to provide a long and descriptive name when deﬁning the datatype (because you probably won’t use that name again), but shorter names in the type-case because you’re likely to use use those names one or more times. I did just say you’re unlikely to use the ﬁeld descriptors introduced in the datatype deﬁnition, but you can. The language provides selectors to extract ﬁelds without the need for pattern-matching: e.g., caml-humps . Sometimes, it’s much easier to use the selector directly rather than go through the pattern-matcher. It often isn’t, as when deﬁning good? above, but just to be clear, let’s write it without pattern-matching: (define (good? [ma : MisspelledAnimal]) : boolean (cond [(caml? ma) (>= (caml-humps ma) 2)] [(yacc? ma) (> (yacc-height ma) 2.1)])) Do Now! What happens if you mis-apply functions to the wrong kinds of values? For instance, what if you give the caml constructor a string? What if you send a number into each version of good? above? 2 Everything (We Will Say) About Parsing Parsing is the act of turning an input character stream into a more structured, internal representation. A common internal representation is as a tree, which programs can recursively process. For instance, given the stream 23 + 5 - 6 we might want a tree representing addition whose left node represents the number 23 and whose right node represents subtraction of 6from 5. Aparser is responsible for performing this transformation. Parsing is a large, complex problem that is far from solved due to the difﬁculties of ambiguity. For instance, an alternate parse tree for the above input expression might put subtraction at the top and addition below it. We might also want to consider whether this addition operation is commutative and hence whether the order of arguments can be switched. Everything only gets much, much worse when we get to full-ﬂedged programming languages (to say nothing of natural languages). 2.1 A Lightweight, Built-In First Half of a Parser These problems make parsing a worthy topic in its own right, and entire books, tools, and courses are devoted to it. However, from our perspective parsing is mostly a distraction, because we want to study the parts of programming languages that are not parsing. We will therefore exploit a handy feature of Racket to manage the transformation of input streams into trees: read .read is tied to the parenthetical form of the language, in that it parses fully (and hence unambiguously) parenthesized terms into a built-in tree form. For instance, running (read) on the parenthesized form of the above input— (+ 23 (- 5 6)) —will produce a list, whose ﬁrst element is the symbol ’+, second element is the number 23, and third element is a list; this list’s ﬁrst element is the symbol ’-, second element is the number 5, and third element is the number 6. 2.2 A Convenient Shortcut As you know you need to test your programs extensively, which is hard to do when you must manually type terms in over and over again. Fortunately, as you might expect, the parenthetical syntax is integrated deeply into Racket through the mechanism of quotation. That is, ’<expr> —which you saw a moment ago in the above example—acts as if you had run (read) and typed <expr> at the prompt (and, of course, evaluates to the value the (read) would have). 2.3 Types for Parsing Actually, I’ve lied a little. I said that (read )—or equivalently, using quotation—will produce a list, etc. That’s true in regular Racket, but in Typed PLAI, the type it returns a distinct type called an s-expression , written in Typed PLAI as s-expression : > (read) - s-expression [type in (+ 23 (- 5 6))] '(+ 23 (- 5 6)) Racket has a very rich language of s-expressions (it even has notation to represent cyclic structures), but we will use only the simple fragment of it. In the typed language, an s-expression is treated distinctly from the other types, such as numbers and lists. Underneath, an s-expression is a large recursive datatype that consists of all the base printable values—numbers, strings, symbols, and so on—and printable collections (lists, vectors, etc.) of s-expressions. As a result, base types like numbers, symbols, and strings are both their own type and an instance of s-expression. Typing such data can be fairly problematic, as we will discuss later [REF]. Typed PLAI takes a simple approach. When written on their own, values like numbers are of those respective types. But when written inside a complex s-expression—in particular, as created by read or quotation—they have type s-expression . You have to then cast them to their native types. For instance: - symbol > (define l '(+ 1 2)) - s-expression '(+ 1 2) > (first l) . typecheck failed: (listof '_a) vs s-expression in: first (quote (+ 1 2)) l first > (define f (first (s-exp->list l))) - s-expression This is similar to the casting that a Java programmer would have to insert. We will study casting itself later [REF]. Observe that the ﬁrst element of the list is still not treated by the type checker as a symbol: a list-shaped s-expression is a list of s-expressions . Thus, > (symbol->string f) . typecheck failed: symbol vs s-expression in: symbol->string f symbol->string f first (first (s-exp->list l)) s-exp->list whereas again, casting does the trick: > (symbol->string (s-exp->symbol f)) - string The need to cast s-expressions is a bit of a nuisance, but some complexity is unavoidable because of what we’re trying to accomplish: to convert an untyped input stream into a typed output stream through robustly typed means. Somehow we have to make explicit our assumptions about that input stream. Fortunately we will use s-expressions only in our parser, and our goal is to get away from parsing as quickly as possible ! Indeed, if anything this should be inducement to get away even quicker. 2.4 Completing the Parser In principle, we can think of read as a complete parser. However, its output is generic: it represents the token structure without offering any comment on its intent. We would instead prefer to have a representation that tells us something about the intended meaningof the terms in our language, just as we wrote at the very beginning: “representing addition”, “represents a number”, and so on. To do this, we must ﬁrst introduce a datatype that captures this representation. We will separately discuss (section 3.1) how and why we obtained this datatype, but for now let’s say it’s given to us: (define-type ArithC [numC (n : number)] [plusC (l : ArithC) (r : ArithC)] [multC (l : ArithC) (r : ArithC)]) We now need a function that will convert s-expressions into instances of this datatype. This is the other half of our parser: (define (parse [s : s-expression]) : ArithC (cond [(s-exp-number? s) (numC (s-exp->number s))] [(s-exp-list? s) (let ([sl (s-exp->list s)]) (case (s-exp->symbol (first sl)) [(+) (plusC (parse (second sl)) (parse (third sl)))] [(*) (multC (parse (second sl)) (parse (third sl)))] [else (error 'parse "invalid list input")]))] [else (error 'parse "invalid input")])) Thus: > (parse '(+ (* 1 2) (+ 2 3))) - ArithC (plusC (multC (numC 1) (numC 2)) (plusC (numC 2) (numC 3))) Congratulations! You have just completed your ﬁrst representation of a program . From now on we can focus entirely on programs represented as recursive trees, ignoring the vagaries of surface syntax and how to get them into the tree form. We’re ﬁnally ready to start studying programming languages! Exercise What happens if you forget to quote the argument to the parser? Why? 2.5 Coda Racket’s syntax, which it inherits from Scheme and Lisp, is controversial. Observe, however, something deeply valuable that we get from it. While parsing traditional languages can be very complex, parsing this syntax is virtually trivial. Given a sequence of tokens corresponding to the input, it is absolutely straightforward to turn parenthesized sequences into s-expressions; it is equally straightforward (as we see above) to turn sexpressions into proper syntax trees. I like to call such two-level languages bicameral , in loose analogy to government legislative houses: the lower-level does rudimentary well-formedness checking, while the upper-level does deeper validity checking. (We haven’t done any of the latter yet, but we will [REF].) The virtues of this syntax are thus manifold. The amount of code it requires is small, and can easily be embedded in many contexts. By integrating the syntax into the language, it becomes easy for programs to manipulate representations of programs (as we will see more of in [REF]). It’s therefore no surprise that even though many Lisp-based syntaxes have had wildly different semantics, they all share this syntactic legacy. Of course, we could just use XML instead. That would be much better. Or JSON . Because that wouldn’t be anything like an s-expression at all. 3 A First Look at Interpretation Now that we have a representation of programs, there are many ways in which we might want to manipulate them. We might want to display a program in an attractive way (“pretty-print”), convert into code in some other format (“compilation”), ask whether it obeys certain properties (“veriﬁcation”), and so on. For now, we’re going to focus on asking what value it corresponds to (“evaluation”—the reduction of programs to values ). Let’s write an evaluator, in the form of an interpreter , for our arithmetic language. We choose arithmetic ﬁrst for three reasons: (a) you already know how it works, so we can focus on the mechanics of writing evaluators; (b) it’s contained in every language we will encounter later, so we can build upwards and outwards from it; and (c) it’s at once both small and big enough to illustrate many points we’d like to get across. 3.1 Representing Arithmetic Let’s ﬁrst agree on how we will represent arithmetic expressions. Let’s say we want to support only two operations—addition and multiplication—in addition to primitive numbers. We need to represent arithmetic expressions . What are the rules that govern nesting of arithmetic expressions? We’re actually free to nest any expression inside another. Do Now! Why did we not include division? What impact does it have on the remarks above? We’ve ignored division because it forces us into a discussion of what expressions we might consider legal: clearly the representation of 1/2ought to be legal; the representation of 1/0is much more debatable; and that of 1/(1-1) seems even more controversial. We’d like to sidestep this controversy for now and return to it later [REF]. Thus, we want a representation for numbers and arbitrarily nestable addition and multiplication. Here’s one we can use: (define-type ArithC [numC (n : number)] [plusC (l : ArithC) (r : ArithC)] [multC (l : ArithC) (r : ArithC)]) 3.2 Writing an Interpreter Now let’s write an interpreter for this arithmetic language. First, we should think about what its type is. It clearly consumes a ArithC value. What does it produce? Well, an interpreter evaluates—and what kind of value might arithmetic expressions reduce to? Numbers, of course. So the interpreter is going to be a function from arithmet