Think Stats Exploratory Data Analysis in Python Version 2.2.0 Think Stats Exploratory Data Analysis in Python Version 2.2.0 Allen B. Downey Green Tea Press Needham, Massachusetts Copyright Â©2014 Allen B. Downey. Green Tea Press 9 Washburn Ave Needham MA 02492 Permission is granted to copy, distribute, and/or modify this document under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License, which is available at http://creativecommons. org/licenses/by-nc-sa/4.0/ . The LATEX source for this book is available from http://thinkstats2.com . Preface This book is an introduction to the practical tools of exploratory data analysis. The organization of the book follows the process I use when I start working with a dataset: â€¢Importing and cleaning: Whatever format the data is in, it usually takes some time and e ort to read the data, clean and transform it, and check that everything made it through the translation process intact. â€¢Single variable explorations: I usually start by examining one variable at a time, nding out what the variables mean, looking at distributions of the values, and choosing appropriate summary statistics. â€¢Pair-wise explorations: To identify possible relationships between variables, I look at tables and scatter plots, and compute correlations and linear ts. â€¢Multivariate analysis: If there are apparent relationships between variables, I use multiple regression to add control variables and investigate more complex relationships. â€¢Estimation and hypothesis testing: When reporting statistical results, it is important to answer three questions: How big is the e ect? How much variability should we expect if we run the same measurement again? Is it possible that the apparent e ect is due to chance? â€¢Visualization: During exploration, visualization is an important tool for nding possible relationships and e ects. Then if an apparent e ect holds up to scrutiny, visualization is an e ective way to communicate results. vi Chapter 0. Preface This book takes a computational approach, which has several advantages over mathematical approaches: â€¢I present most ideas using Python code, rather than mathematical notation. In general, Python code is more readable; also, because it is executable, readers can download it, run it, and modify it. â€¢Each chapter includes exercises readers can do to develop and solidify their learning. When you write programs, you express your understanding in code; while you are debugging the program, you are also correcting your understanding. â€¢Some exercises involve experiments to test statistical behavior. For example, you can explore the Central Limit Theorem (CLT) by generating random samples and computing their sums. The resulting visualizations demonstrate why the CLT works and when it doesn't. â€¢Some ideas that are hard to grasp mathematically are easy to understand by simulation. For example, we approximate p-values by running random simulations, which reinforces the meaning of the p-value. â€¢Because the book is based on a general-purpose programming language (Python), readers can import data from almost any source. They are not limited to datasets that have been cleaned and formatted for a particular statistics tool. The book lends itself to a project-based approach. In my class, students work on a semester-long project that requires them to pose a statistical question, nd a dataset that can address it, and apply each of the techniques they learn to their own data. To demonstrate my approach to statistical analysis, the book presents a case study that runs through all of the chapters. It uses data from two sources: â€¢The National Survey of Family Growth (NSFG), conducted by the U.S. Centers for Disease Control and Prevention (CDC) to gather \information on family life, marriage and divorce, pregnancy, infertility, use of contraception, and men's and women's health." (See http://cdc.gov/nchs/nsfg.htm .) 0.1. How I wrote this book vii â€¢The Behavioral Risk Factor Surveillance System (BRFSS), conducted by the National Center for Chronic Disease Prevention and Health Promotion to \track health conditions and risk behaviors in the United States." (See http://cdc.gov/BRFSS/ .) Other examples use data from the IRS, the U.S. Census, and the Boston Marathon. This second edition of Think Stats includes the chapters from the rst edition, many of them substantially revised, and new chapters on regression, time series analysis, survival analysis, and analytic methods. The previous edition did not use pandas, SciPy, or StatsModels, so all of that material is new. 0.1 How I wrote this book When people write a new textbook, they usually start by reading a stack of old textbooks. As a result, most books contain the same material in pretty much the same order. I did not do that. In fact, I used almost no printed material while I was writing this book, for several reasons: â€¢My goal was to explore a new approach to this material, so I didn't want much exposure to existing approaches. â€¢Since I am making this book available under a free license, I wanted to make sure that no part of it was encumbered by copyright restrictions. â€¢Many readers of my books don't have access to libraries of printed material, so I tried to make references to resources that are freely available on the Internet. â€¢Some proponents of old media think that the exclusive use of electronic resources is lazy and unreliable. They might be right about the rst part, but I think they are wrong about the second, so I wanted to test my theory. viii Chapter 0. Preface The resource I used more than any other is Wikipedia. In general, the articles I read on statistical topics were very good (although I made a few small changes along the way). I include references to Wikipedia pages throughout the book and I encourage you to follow those links; in many cases, the Wikipedia page picks up where my description leaves o . The vocabulary and notation in this book are generally consistent with Wikipedia, unless I had a good reason to deviate. Other resources I found useful were Wolfram MathWorld and the Reddit statistics forum, http://www.reddit.com/ r/statistics . 0.2 Using the code The code and data used in this book are available from https://github. com/AllenDowney/ThinkStats2 . Git is a version control system that allows you to keep track of the les that make up a project. A collection of les under Git's control is called a repository . GitHub is a hosting service that provides storage for Git repositories and a convenient web interface. The GitHub homepage for my repository provides several ways to work with the code: â€¢You can create a copy of my repository on GitHub by pressing the Fork button. If you don't already have a GitHub account, you'll need to create one. After forking, you'll have your own repository on GitHub that you can use to keep track of code you write while working on this book. Then you can clone the repo, which means that you make a copy of the les on your computer. â€¢Or you could clone my repository. You don't need a GitHub account to do this, but you won't be able to write your changes back to GitHub. â€¢If you don't want to use Git at all, you can download the les in a Zip le using the button in the lower-right corner of the GitHub page. All of the code is written to work in both Python 2 and Python 3 with no translation. I developed this book using Anaconda from Continuum Analytics, which is a free Python distribution that includes all the packages you'll need to run the 0.2. Using the code ix code (and lots more). I found Anaconda easy to install. By default it does a user-level installation, not system-level, so you don't need administrative privileges. And it supports both Python 2 and Python 3. You can download Anaconda from http://continuum.io/downloads . If you don't want to use Anaconda, you will need the following packages: â€¢pandas for representing and analyzing data, http://pandas.pydata. org/ ; â€¢NumPy for basic numerical computation, http://www.numpy.org/ ; â€¢SciPy for scienti c computation including statistics, http://www. scipy.org/ ; â€¢StatsModels for regression and other statistical analysis, http:// statsmodels.sourceforge.net/ ; and â€¢matplotlib for visualization, http://matplotlib.org/ . Although these are commonly used packages, they are not included with all Python installations, and they can be hard to install in some environments. If you have trouble installing them, I strongly recommend using Anaconda or one of the other Python distributions that include these packages. After you clone the repository or unzip the zip le, you should have a folder calledThinkStats2/code with a le called nsfg.py. If you run nsfg.py, it should read a data le, run some tests, and print a message like, \All tests passed." If you get import errors, it probably means there are packages you need to install. Most exercises use Python scripts, but some also use the IPython notebook. If you have not used IPython notebook before, I suggest you start with the documentation at http://ipython.org/ipython-doc/stable/notebook/ notebook.html . I wrote this book assuming that the reader is familiar with core Python, including object-oriented features, but not pandas, NumPy, and SciPy. If you are already familiar with these modules, you can skip a few sections. x Chapter 0. Preface I assume that the reader knows basic mathematics, including logarithms, for example, and summations. I refer to calculus concepts in a few places, but you don't have to do any calculus. If you have never studied statistics, I think this book is a good place to start. And if you have taken a traditional statistics class, I hope this book will help repair the damage. Allen B. Downey is a Professor of Computer Science at the Franklin W. Olin College of Engineering in Needham, MA. Contributor List If you have a suggestion or correction, please send email to downey@allendowney.com . If I make a change based on your feedback, I will add you to the contributor list (unless you ask to be omitted). If you include at least part of the sentence the error appears in, that makes it easy for me to search. Page and section numbers are ne, too, but not quite as easy to work with. Thanks! â€¢Lisa Downey and June Downey read an early draft and made many corrections and suggestions. â€¢Steven Zhang found several errors. â€¢Andy Pethan and Molly Farison helped debug some of the solutions, and Molly spotted several typos. â€¢Dr. Nikolas Akerblom knows how big a Hyracotherium is. â€¢Alex Morrow clari ed one of the code examples. â€¢Jonathan Street caught an error in the nick of time. â€¢Many thanks to Kevin Smith and Tim Arnold for their work on plasTeX, which I used to convert this book to DocBook. â€¢George Caplan sent several suggestions for improving clarity. 0.2. Using the code xi â€¢Julian Ceipek found an error and a number of typos. â€¢Stijn Debrouwere, Leo Marihart III, Jonathan Hammler, and Kent Johnson found errors in the rst print edition. â€¢J org Beyer found typos in the book and made many corrections in the docstrings of the accompanying code. â€¢Tommie Gannert sent a patch le with a number of corrections. â€¢Christoph Lendenmann submitted several errata. â€¢Michael Kearney sent me many excellent suggestions. â€¢Alex Birch made a number of helpful suggestions. â€¢Lindsey Vanderlyn, Grin Tschurwald, and Ben Small read an early version of this book and found many errors. â€¢John Roth, Carol Willing, and Carol Novitsky performed technical reviews of the book. They found many errors and made many helpful suggestions. â€¢David Palmer sent many helpful suggestions and corrections. â€¢Erik Kulyk found many typos. â€¢Nir So er sent several excellent pull requests for both the book and the supporting code. â€¢GitHub user othesof sent a number of corrections. â€¢Toshiaki Kurokawa, who is working on the Japanese translation of this book, has sent many corrections and helpful suggestions. â€¢Benjamin White suggested more idiomatic Pandas code. â€¢Takashi Sato spotted a code error. Other people who found typos and similar errors are Andrew Heine, G abor Lipt ak, Dan Kearney, Alexander Gryzlov, Martin Veillette, Haitao Ma, Je Pickhardt, Rohit Deshpande, Joanne Pratt, Lucian Ursu, Paul Glezen, Ting-kuang Lin, Scott Miller, Luigi Patruno. xii Chapter 0. Preface Contents Preface v 0.1 How I wrote this book . . . . . . . . . . . . . . . . . . . . . vii 0.2 Using the code . . . . . . . . . . . . . . . . . . . . . . . . . . viii 1 Exploratory data analysis 1 1.1 A statistical approach . . . . . . . . . . . . . . . . . . . . . . 2 1.2 The National Survey of Family Growth . . . . . . . . . . . . 3 1.3 Importing the data . . . . . . . . . . . . . . . . . . . . . . . 4 1.4 DataFrames . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1.5 Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.6 Transformation . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.7 Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.8 Interpretation . . . . . . . . . . . . . . . . . . . . . . . . . . 12 1.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 1.10 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 xiv Contents 2 Distributions 17 2.1 Histograms . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2.2 Representing histograms . . . . . . . . . . . . . . . . . . . . 18 2.3 Plotting histograms . . . . . . . . . . . . . . . . . . . . . . . 19 2.4 NSFG variables . . . . . . . . . . . . . . . . . . . . . . . . . 19 2.5 Outliers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.6 First babies . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 2.7 Summarizing distributions . . . . . . . . . . . . . . . . . . . 25 2.8 Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 2.9 E ect size . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 2.10 Reporting results . . . . . . . . . . . . . . . . . . . . . . . . 28 2.11 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 2.12 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 3 Probability mass functions 31 3.1 Pmfs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 3.2 Plotting PMFs . . . . . . . . . . . . . . . . . . . . . . . . . 33 3.3 Other visualizations . . . . . . . . . . . . . . . . . . . . . . . 35 3.4 The class size paradox . . . . . . . . . . . . . . . . . . . . . 35 3.5 DataFrame indexing . . . . . . . . . . . . . . . . . . . . . . 39 3.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 3.7 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 Contents xv 4 Cumulative distribution functions 45 4.1 The limits of PMFs . . . . . . . . . . . . . . . . . . . . . . . 45 4.2 Percentiles . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 4.3 CDFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4.4 Representing CDFs . . . . . . . . . . . . . . . . . . . . . . . 49 4.5 Comparing CDFs . . . . . . . . . . . . . . . . . . . . . . . . 50 4.6 Percentile-based statistics . . . . . . . . . . . . . . . . . . . . 51 4.7 Random numbers . . . . . . . . . . . . . . . . . . . . . . . . 52 4.8 Comparing percentile ranks . . . . . . . . . . . . . . . . . . 54 4.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 4.10 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 5 Modeling distributions 57 5.1 The exponential distribution . . . . . . . . . . . . . . . . . . 57 5.2 The normal distribution . . . . . . . . . . . . . . . . . . . . 60 5.3 Normal probability plot . . . . . . . . . . . . . . . . . . . . . 62 5.4 The lognormal distribution . . . . . . . . . . . . . . . . . . . 65 5.5 The Pareto distribution . . . . . . . . . . . . . . . . . . . . . 67 5.6 Generating random numbers . . . . . . . . . . . . . . . . . . 69 5.7 Why model? . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 5.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 5.9 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 xvi Contents 6 Probability density functions 75 6.1 PDFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 6.2 Kernel density estimation . . . . . . . . . . . . . . . . . . . . 77 6.3 The distribution framework . . . . . . . . . . . . . . . . . . 79 6.4 Hist implementation . . . . . . . . . . . . . . . . . . . . . . 80 6.5 Pmf implementation . . . . . . . . . . . . . . . . . . . . . . 81 6.6 Cdf implementation . . . . . . . . . . . . . . . . . . . . . . . 82 6.7 Moments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 6.8 Skewness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 6.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 6.10 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 7 Relationships between variables 91 7.1 Scatter plots . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 7.2 Characterizing relationships . . . . . . . . . . . . . . . . . . 95 7.3 Correlation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 7.4 Covariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 7.5 Pearson's correlation . . . . . . . . . . . . . . . . . . . . . . 98 7.6 Nonlinear relationships . . . . . . . . . . . . . . . . . . . . . 100 7.7 Spearman's rank correlation . . . . . . . . . . . . . . . . . . 101 7.8 Correlation and causation . . . . . . . . . . . . . . . . . . . 102 7.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 7.10 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 Contents xvii 8 Estimation 105 8.1 The estimation game . . . . . . . . . . . . . . . . . . . . . . 105 8.2 Guess the variance . . . . . . . . . . . . . . . . . . . . . . . 107 8.3 Sampling distributions . . . . . . . . . . . . . . . . . . . . . 109 8.4 Sampling bias . . . . . . . . . . . . . . . . . . . . . . . . . . 112 8.5 Exponential distributions . . . . . . . . . . . . . . . . . . . . 113 8.6 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 8.7 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 9 Hypothesis testing 117 9.1 Classical hypothesis testing . . . . . . . . . . . . . . . . . . . 117 9.2 HypothesisTest . . . . . . . . . . . . . . . . . . . . . . . . . 119 9.3 Testing a di erence in means . . . . . . . . . . . . . . . . . . 121 9.4 Other test statistics . . . . . . . . . . . . . . . . . . . . . . . 123 9.5 Testing a correlation . . . . . . . . . . . . . . . . . . . . . . 124 9.6 Testing proportions . . . . . . . . . . . . . . . . . . . . . . . 125 9.7 Chi-squared tests . . . . . . . . . . . . . . . . . . . . . . . . 127 9.8 First babies again . . . . . . . . . . . . . . . . . . . . . . . . 128 9.9 Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130 9.10 Power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130 9.11 Replication . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 9.12 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 9.13 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 xviii Contents 10 Linear least squares 137 10.1 Least squares t . . . . . . . . . . . . . . . . . . . . . . . . . 137 10.2 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . 139 10.3 Residuals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140 10.4 Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 10.5 Goodness of t . . . . . . . . . . . . . . . . . . . . . . . . . 144 10.6 Testing a linear model . . . . . . . . . . . . . . . . . . . . . 146 10.7 Weighted resampling . . . . . . . . . . . . . . . . . . . . . . 148 10.8 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150 10.9 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150 11 Regression 153 11.1 StatsModels . . . . . . . . . . . . . . . . . . . . . . . . . . . 154 11.2 Multiple regression . . . . . . . . . . . . . . . . . . . . . . . 156 11.3 Nonlinear relationships . . . . . . . . . . . . . . . . . . . . . 158 11.4 Data mining . . . . . . . . . . . . . . . . . . . . . . . . . . . 159 11.5 Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 11.6 Logistic regression . . . . . . . . . . . . . . . . . . . . . . . . 163 11.7 Estimating parameters . . . . . . . . . . . . . . . . . . . . . 165 11.8 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . 166 11.9 Accuracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168 11.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169 11.11 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170 Contents xix 12 Time series analysis 173 12.1 Importing and cleaning . . . . . . . . . . . . . . . . . . . . . 174 12.2 Plotting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176 12.3 Linear regression . . . . . . . . . . . . . . . . . . . . . . . . 178 12.4 Moving averages . . . . . . . . . . . . . . . . . . . . . . . . . 180 12.5 Missing values . . . . . . . . . . . . . . . . . . . . . . . . . . 182 12.6 Serial correlation . . . . . . . . . . . . . . . . . . . . . . . . 183 12.7 Autocorrelation . . . . . . . . . . . . . . . . . . . . . . . . . 185 12.8 Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187 12.9 Further reading . . . . . . . . . . . . . . . . . . . . . . . . . 192 12.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192 12.11 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193 13 Survival analysis 195 13.1 Survival curves . . . . . . . . . . . . . . . . . . . . . . . . . 195 13.2 Hazard function . . . . . . . . . . . . . . . . . . . . . . . . . 198 13.3 Inferring survival curves . . . . . . . . . . . . . . . . . . . . 199 13.4 Kaplan-Meier estimation . . . . . . . . . . . . . . . . . . . . 200 13.5 The marriage curve . . . . . . . . . . . . . . . . . . . . . . . 202 13.6 Estimating the survival curve . . . . . . . . . . . . . . . . . 203 13.7 Con dence intervals . . . . . . . . . . . . . . . . . . . . . . . 204 13.8 Cohort e ects . . . . . . . . . . . . . . . . . . . . . . . . . . 206 13.9 Extrapolation . . . . . . . . . . . . . . . . . . . . . . . . . . 209 13.10 Expected remaining lifetime . . . . . . . . . . . . . . . . . . 210 13.11 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214 13.12 Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214 xx Contents 14 Analytic methods 217 14.1 Normal distributions . . . . . . . . . . . . . . . . . . . . . . 217 14.2 Sampling distributions . . . . . . . . . . . . . . . . . . . . . 219 14.3 Representing normal distributions . . . . . . . . . . . . . . . 220 14.4 Central limit theorem . . . . . . . . . . . . . . . . . . . . . . 221 14.5 Testing the CLT . . . . . . . . . . . . . . . . . . . . . . . . . 222 14.6 Applying the CLT . . . . . . . . . . . . . . . . . . . . . . . . 227 14.7 Correlation test . . . . . . . . . . . . . . . . . . . . . . . . . 228 14.8 Chi-squared test . . . . . . . . . . . . . . . . . . . . . . . . . 230 14.9 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232 14.10 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233 Chapter 1 Exploratory data analysis The thesis of this book is that data combined with practical methods can answer questions and guide decisions under uncertainty. As an example, I present a case study motivated by a question I heard when my wife and I were expecting our rst child: do rst babies tend to arrive late? If you Google this question, you will nd plenty of discussion. Some people claim it's true, others say it's a myth, and some people say it's the other way around: rst babies come early. In many of these discussions, people provide data to support their claims. I found many examples like these: \My two friends that have given birth recently to their rst babies, BOTH went almost 2 weeks overdue before going into labour or being induced." \My rst one came 2 weeks late and now I think the second one is going to come out two weeks early!!" \I don't think that can be true because my sister was my mother's rst and she was early, as with many of my cousins." Reports like these are called anecdotal evidence because they are based on data that is unpublished and usually personal. In casual conversation, 2 Chapter 1. Exploratory data analysis there is nothing wrong with anecdotes, so I don't mean to pick on the people I quoted. But we might want evidence that is more persuasive and an answer that is more reliable. By those standards, anecdotal evidence usually fails, because: â€¢Small number of observations: If pregnancy length is longer for rst babies, the di erence is probably small compared to natural variation. In that case, we might have to compare a large number of pregnancies to be sure that a di erence exists. â€¢Selection bias: People who join a discussion of this question might be interested because their rst babies were late. In that case the process of selecting data would bias the results. â€¢Con rmation bias: People who believe the claim might be more likely to contribute examples that con rm it. People who doubt the claim are more likely to cite counterexamples. â€¢Inaccuracy: Anecdotes are often personal stories, and often misremembered, misrepresented, repeated inaccurately, etc. So how can we do better? 1.1 A statistical approach To address the limitations of anecdotes, we will use the tools of statistics, which include: â€¢Data collection: We will use data from a large national survey that was designed explicitly with the goal of generating statistically valid inferences about the U.S. population. â€¢Descriptive statistics: We will generate statistics that summarize the data concisely, and evaluate di erent ways to visualize data. â€¢Exploratory data analysis: We will look for patterns, di erences, and other features that address the questions we are interested in. At the same time we will check for inconsistencies and identify limitations. 1.2. The National Survey of Family Growth 3 â€¢Estimation: We will use data from a sample to estimate characteristics of the general population. â€¢Hypothesis testing: Where we see apparent e ects, like a di erence between two groups, we will evaluate whether the e ect might have happened by chance. By performing these steps with care to avoid pitfalls, we can reach conclusions that are more justi able and more likely to be correct. 1.2 The National Survey of Family Growth Since 1973 the U.S. Centers for Disease Control and Prevention (CDC) have conducted the National Survey of Family Growth (NSFG), which is intended to gather \information on family life, marriage and divorce, pregnancy, infertility, use of contraception, and men's and women's health. The survey results are used. . . to plan health services and health education programs, and to do statistical studies of families, fertility, and health." See http://cdc.gov/nchs/nsfg.htm . We will use data collected by this survey to investigate whether rst babies tend to come late, and other questions. In order to use this data e ectively, we have to understand the design of the study. The NSFG is a cross-sectional study, which means that it captures a snapshot of a group at a point in time. The most common alternative is a longitudinal study, which observes a group repeatedly over a period of time. The NSFG has been conducted seven times; each deployment is called a cycle . We will use data from Cycle 6, which was conducted from January 2002 to March 2003. The goal of the survey is to draw conclusions about a population ; the target population of the NSFG is people in the United States aged 15-44. Ideally surveys would collect data from every member of the population, but that's seldom possible. Instead we collect data from a subset of the 4 Chapter 1. Exploratory data analysis population called a sample . The people who participate in a survey are called respondents . In general, cross-sectional studies are meant to be representative , which means that every member of the target population has an equal chance of participating. That ideal is hard to achieve in practice, but people who conduct surveys come as close as they can. The NSFG is not representative; instead it is deliberately oversampled . The designers of the study recruited three groups|Hispanics, African-Americans and teenagers|at rates higher than their representation in the U.S. population, in order to make sure that the number of respondents in each of these groups is large enough to draw valid statistical inferences. Of course, the drawback of oversampling is that it is not as easy to draw conclusions about the general population based on statistics from the survey. We will come back to this point later. When working with this kind of data, it is important to be familiar with thecodebook , which documents the design of the study, the survey questions, and the encoding of the responses. The codebook and user's guide for the NSFG data are available from http://www.cdc.gov/nchs/nsfg/nsfg_ cycle6.htm 1.3 Importing the data The code and data used in this book are available from https://github. com/AllenDowney/ThinkStats2 . For information about downloading and working with this code, see Section 0.2. Once you download the code, you should have a le called ThinkStats2/code/nsfg.py . If you run it, it should read a data le, run some tests, and print a message like, \All tests passed." Let's see what it does. Pregnancy data from Cycle 6 of the NSFG is in a le called2002FemPreg.dat.gz ; it is a gzip-compressed data le in plain text (ASCII), with xed width columns. Each line in the le is a record that contains data about one pregnancy. 1.4. DataFrames 5 The format of the le is documented i