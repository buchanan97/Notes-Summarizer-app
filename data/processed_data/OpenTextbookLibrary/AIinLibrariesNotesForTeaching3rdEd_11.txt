the program is doing, what the program is using in its reasoning. But DL programs can lack transparency. Two areas of human intelligence had proved special challenges to AI: addressing text (including languages, and translation) and addressing images. Hitherto, computers could not understand or translate natural languages, and they could not recognize and process images, including videos, as sources of information. Machine learning and DL have changed that: text and images are now fair game for AI. AI as a scholarly discipline covers many different areas. But for the purposes of the cascade of recent AI developments, and of AI in libraries, we can focus on ML and DL. A Genuine Great Leap Forward A great leap forward came from Transformers, Large Language Models, and Foundation Models. At the end of November 2022, Chat GPT was released to the public. By January 2023, it had million active users. Many more interested observers were aware of its existence more than of the adults in the United States know about it. It is the fastest growing, and most widely used, software application of all time. There is some history to it. In 2017, Ashish Vaswani and co-authors published the paper Attention is all you need (Vaswani et al. 2017) (see also (Huang et al. 2018)). This introduced Transformers. Shortly thereafter there started to emerge Large Language Models and Foundation Models. (What all these are will be explained later in the book.) Chat GPT is a Transformer, and a Large Language Model, and initially it was a fine-tuned version of the Foundation Models GPT- and GPT- . (As of 2024, Chat GPT uses GPT-4o.) Pretty much any machine learning or deep learning program