force in the computer business. A cheap, statistically optimized memory system will be a better seller than a prohibitively expensive, blazingly fast one, so the first choice is not much of a choice at all. But these choices, used in combination, can attain a good fraction of the performance you would get if every component were fast. Chances are very good that your high performance workstation incorporates several or all of them. Once the memory system has been decided upon, there are things we can do in software to see that it is used ef ficiently . A compiler that has some knowledge of the way memory is arranged and the details of the caches can optimize their use to some extent. The other place for optimizations is in user applications, as we ll see later in the book. A good pattern of memory access will work with, rather than against, the components of the system. In this chapter we discuss how the pieces of a memory system work. W e look at how patterns of data and instruction access factor into your overall runtime, especially as CPU speeds increase. W e also talk a bit about the performance implications of running in a virtual memory environment. Memory T echnology Almost all fast memories used today are semiconductor -based. footnote They come in two flavors: dynamic random access memory (DRAM) and static random access memory (SRAM). The term random means that you can address memory locations in any order . This is to distinguish random access from serial memories, where you have to step through all intervening locations to get to the particular one you are interested in. An example