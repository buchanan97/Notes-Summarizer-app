can be built from a Foundation Model (that is why they are called 'Foundation Models'). Also, the results of systems built using Foundation Models will likely be superior to any other approach. So, a correct strategy in solving a machine learning problem is to address it using a Foundation Model. But Foundation Models themselves are very expensive, and resource needy, to create. We are talking here of hundreds of millions of dollars, months of computing time, and of using a large portion of the internet as data. Only a few large commercial companies have been able to produce the biggest and best of the Foundation Models. Producing Foundation Models is not the sort of thing that you and I are going to do, nor are most universities, nor even most governments. Some Foundation models have been open-sourced and are freely available to all. This is a mixed blessing. Allowing programmer users to have the code, lets them see what the code is and, historically, with open-sourced projects like Linux, the programmers can contribute, improve the code, 'catch bugs', etc. But Foundation model ML code is a little different. There are deep security concerns and great potential for unintentional, and even intentional, harm. Trusting a few massive companies like Google, Open AI, and Microsoft to look after us is not brilliant, but it is probably better than making the code available to all and sundry (including bad actors). That said, the massive company Meta open-sources its code. Also, Hugging Face provides a hub, a library of open-source Foundation Models (Hugging Face 2023). Some commercial Foundation Models have Application Programming Interfaces (APIs) that allow Users to pay a fee and use them