to follo w a p o w er la w, as Rob ert Axtell rep orts in Scienc e (see http: www.sciencemag.org content 5536 1818.full.pdf ). This la w suggests that if there are 1000 companies with few er than lo comotiv es, there migh t b e companies with lo comotiv es, companies with 1000, and p ossibly one compan y with , lo comotiv es. Mathematically , a p o w er la w means that the n um b er of companies with a giv en size is in v ersely prop ortional to size, or PMF(x) x where PMF(x) is the probabilit y mass function of x and is a parameter that is often near . W e can construct a p o w er la w prior lik e this: class Train(Dice): . Credible in terv als def init (self, hypos, alpha ): Pmf. init (self) for hypo in hypos: self.Set(hypo, hypo (-alpha)) self.Normalize() And here's the co de that constructs the prior: hypos range( , 1001) suite Train(hypos) Again, the upp er b ound is arbitrary , but with a p o w er la w prior, the p osterior is less sensitiv e to this c hoice. Figure sho ws the new p osterior based on the p o w er la w, compared to the p osterior based on the uniform prior. Using the bac kground information represen ted in the p o w er la w prior, w e can all but eliminate v alues of N greater than . If w e start with this prior and observ e trains , , and , the means of the p osteriors