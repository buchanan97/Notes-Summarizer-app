thinking, reasoning, responding, learning, paying attention, and other cognitive abilities. In a DL implementation, there is a network of software neurons organized in layers. Certain levels of thresholds of input features activate neurons in the first layer; in turn, first layer activated neurons activate some neurons in the second layer, and so on through several layers. At the output level, particular (software) units indicate, for example, whether the patient being diagnosed likely has cancer. DL is quite involved to set up, and it is demanding on resources. Large amounts of data are needed, then large amounts of training time and computing power to adjust the activation levels and various other biases . Separately, DL often can be opaque as to what is going on. By the time the triggering has gone through several layers, transparency can be lost and that is distinctly a drawback. Here is an example (Google for Developers 2022). A cancer diagnosis DL program may learn by processing images from different hospitals. But if one of the hospitals is specifically a cancer hospital, then that feature, if used by the DL program, may result in certain types of images being given a higher probability of indicating cancer those images sourced from the cancer hospital. And the program would be right (those images do have a higher probability of indicating cancer). But, really, this is being right for the wrong reason. You want the DL program to be analyzing the images (supplemented perhaps with facts about the patients and their histories) not reasoning from the originating hospital of the images. To guard against possibilities like these, transparency in the DL software program helps. You need to know what