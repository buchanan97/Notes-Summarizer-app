had a cache lar ge enough to contain the entire matrix for the duration of the benchmark. For the first time, a workstation had performance on this benchmark on the same order of supercomputers. In a sense, with the entire data structure in a SRAM cache, the RS-6000 was operating like a Cray vector supercomputer . The problem was that the Cray could maintain and improve the performance for a matrix, whereas the RS-6000 suf fered a significant performance loss at this increased matrix size. Soon, all the other workstation vendors introduced similarly lar ge caches, and the Linpack benchmark ceased to be useful as an indicator of average application performance. Wider Memory Systems Consider what happens when a cache line is refilled from memory: consecutive memory locations from main memory are read to fill consecutive locations within the cache line. The number of bytes transferred depends on how big the line is anywhere from bytes to bytes or more. W e want the refill to proceed quickly because an instruction is stalled in the pipeline, or perhaps the processor is waiting for more instructions. In link , if we have two DRAM chips that provide us with bits of data every ns (remember cycle time), a cache fill of a -byte line takes 1600 ns. Narrow memory system One way to make the cache-line fill operation faster is to widen the memory system as shown in link . Instead of having two rows of DRAMs, we create multiple rows of DRAMs. Now on every -ns cycle, we get contiguous bits, and our cache-line fills are four times faster . Wide memory system We can improve the performance of a