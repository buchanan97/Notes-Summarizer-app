link Chapter for measures of memory bandwidth. Because memory systems are divided into components, there are dif ferent bandwidth and latency figures between dif ferent components as shown in link . The bandwidth rate between a cache and the CPU will be higher than the bandwidth between main memory and the cache, for instance. There may be several caches and paths to memory as well. Usually , the peak memory bandwidth quoted by vendors is the speed between the data cache and the processor . In the rest of this section, we look at techniques to improve latency , bandwidth, or both. Large Caches As we mentioned at the start of this chapter , the disparity between CPU speeds and memory is growing. If you look closely , you can see vendors innovating in several ways. Some workstations are being of fered with MB data caches! This is lar ger than the main memory systems of machines just a few years ago. W ith a lar ge enough cache, a small (or even moderately lar ge) data set can fit completely inside and get incredibly good performance. W atch out for this when you are testing new hardware. When your program grows too lar ge for the cache, the performance may drop of f considerably , perhaps by a factor of or more, depending on the memory access patterns. Interestingly , an increase in cache size on the part of vendors can render a benchmark obsolete. Simple Memory System Up to 1992, the Linpack benchmark was probably the single mostrespected benchmark to determine the average performance across a wide range of applications. In 1992, IBM introduced the IBM RS-6000 which