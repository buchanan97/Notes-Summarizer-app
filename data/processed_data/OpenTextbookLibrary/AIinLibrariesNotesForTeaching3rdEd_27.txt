for example, clustering songs into playlists, but it is not really suitable for OCR. Semi-Supervised Supervised and unsupervised classification approaches can be combined. This might be useful when there is a huge amount of data, of which only a small proportion is labeled (i.e. it is known what those items are), and the process of labeling is expensive or time consuming or hard to do. For example:- imagine some historical biodiversity researchers who collected specimen samples in the style of Darwin; they also did as much labeling as they could manage, including labeling at least one example of what they thought was every species they came across; then the initially unlabeled specimens were later to be donated to many museums, who, of course, wanted them labeled; this problem might be approached by clustering, supplemented with a back-and-forth with supervised learning; then the final labeling of the museum samples could be done by machine. Self-Supervised The learning techniques mentioned to date have problems and issues. Supervised learning required large amounts of labeled data which is often difficult, expensive, or even near impossible, to obtain. The need for the quality labeling is the cause of the problem. Unsupervised learning simply might not give you what you want. Self-supervised Learning (SSL) is an ingenious idea which will often be far superior to its alternatives. Basically, it uses unsupervised learning, and the data itself, to label the data, then it uses supervised learning on the now labeled data. To do this the data has to have suitable structure or patterns in it. This gives a context, or contexts to items of data, and the general problem being addressed needs to be tightly specified or