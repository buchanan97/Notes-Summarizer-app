only one train-op erating compan y (or only one w e care ab out) and that w e are equally lik ely to see an y of its lo comotiv es, then the c hance of seeing an y particular lo comotiv e is N . Here's the lik eliho o d function: Chapter . Estimation class Train(Suite): def Likelihood(self, data, hypo): if hypo data: return else: return hypo This migh t lo ok familiar; the lik eliho o d functions for the lo comotiv e problem and the dice problem are iden tical. Here's the up date: suite Train(hypos) suite.Update( ) There are to o man y h yp otheses to prin t, so I plotted the results in Figure . Not surprisingly , all v alues of N b elo w ha v e b een eliminated. The most lik ely v alue, if y ou had to guess, is . That migh t not seem lik e a v ery go o d guess; after all, what are the c hances that y ou just happ ened to see the train with the highest n um b er? Nev ertheless, if y ou w an t to maximize the c hance of getting the answ er exactly righ t, y ou should guess . But ma yb e that's not the righ t goal. An alternativ e is to compute the mean of the p osterior distribution: def Mean(suite): total for hypo, prob in suite.Items(): total hypo prob return total print Mean(suite) Or y ou could use the v ery similar metho d pro vided b y Pmf : print suite.Mean() The mean of the p osterior