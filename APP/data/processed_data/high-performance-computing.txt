introduction connexion edition introduction high performance computing modern computer architecture memory introduction memory t echnology register cache cache ganization virtual memory improving memory performance closing note exercise number introduction reality representation effect representation algebra doe w ork improving accuracy using guard digit history ieee format ieee operation special v alues exception t rap compiler issue closing note exercise programming t uning software compiler doe introduction history language t o optimize optimizing compiler t optimization level classical optimization closing note exercise timing profiling introduction timing subroutine profiling basic block profilers virtual memory closing note exercise eliminating clutter introduction subroutine call branch branch w ith loop clutter closing note exercise loop optimization introduction operation counting basic loop unrolling qualifying candidate loop unrolling level nested loop loop interchange memory access pattern interchange w o w blocking ease memory access pattern program require memory y ou closing note exercise parallel processor understanding parallelism introduction dependency loop dependency ambiguous reference closing note exercise multiprocessor introduction symmetric multiprocessing hardware multiprocessor software concept technique multithreaded program real example closing note exercise programming multiprocessor introduction automatic parallelization assisting compiler closing note exercise scalable parallel processing language support performance introduction problem heat explicity parallel language tran problem decomposition high performance tran hpf closing note environment introduction parallel v irtual machine interface closing note appendix appendix c high performance microprocessor introduction cisc fundamental risc risc processor risc mean fast execution architecture closing note exercise appendix b looking assembly language assembly languageintroduction connexion edition provides introduction connexion republished version book introduction connexion edition purpose book teach new programmer scientist basic high performance computing t oo parallel high performance computing book focus architecture theory computer science surrounding hpc wanted book speak practicing chemistry student physicist biologist need write run program research using edition book written kevin dowd book going print immediately sent angry letter customer support imploring book going book kind marketplace complaint letter triggered conversation let author second edition true fashion complained got fix fall using book teach hpc course book chapter time fueled multiple night latte fear having ready week lecture second edition came july pretty received got good comment teacher scientist felt book did good job teaching practitioner happy book published crossroad history high performance computing late question lar ge vector supercomputer specialized memory system resist assault increasing clock rate microprocessor later question fast expensive power risc architecture win commodity intel microprocessor commodity memory technology market decided commodity microprocessor king performance performance commodity memorysubsystems kept increasing rapidly intel architecture eliminated risc architecture processor greatly increasing clock rate truly winning increasingly important floating point operation w att competition user figured ef fectively use loosely coupled processor overall cost improving ener gy consumption commodity microprocessor overriding factor market place change led book relevant common use case hpc field led book going print chagrin small devoted fan base reduced buying used copy book amazon order copy laying fice gift unsuspecting visitor thanks approach associate use founder copyright releasing book creative common attribution book rise ash like proverbial phoenix bringing book connexion publishing creative common attribution license insuring book obsolete w e core element book relevant new community author add adapt book needed time publishing connexion keep cost printed book low wise choice textbook college course high performance computing creative common licensing ability print locally make book available country school world like w ikipedia use book volunteer help improve book book need thank kevin dowd wrote edition graciously let alter cover cover second edition mike loukides editor second edition talk time time possible future edition book mike instrumental helping release book creative common attribution team connexion wonderful work w e share passion high performance computing new form publishing knowledge reach people possible iwant thank jan odegard kathi fletcher encouraging supporting helping process daniel w illiamson did amazing job converting material format connexion format truly look forward seeing far book unlimited number invest use book look forward work charles severance november high performance computing introduction book high performance computing w orry performance decade definition called high performance computing changed dramatically article appeared wall street journal titled attack killer micros described computing system small inexpensive processor soon make lar ge supercomputer obsolete time personal computer costing perform million operation second workstation costing perform million operation supercomputer costing million perform million operation second couldn t simply connect personal computer achieve performance supercomputer million vision come true way way original proponent killer micro theory envisioned instead microprocessor performance relentlessly gained supercomputer performance occurred reason technology headroom improving performance personal computer area supercomputer late pushing performance envelope supercomputer company broke technical barrier microprocessor company quickly adopt successful element supercomputer design short year later second important factor emer gence thriving personal business computer market increasing performance demand computer usage graphic graphical user interface multimedia game driving factor market w ith lar ge market available research dollar poured developing inexpensive high performance processor home market result trend faster smaller computer directly evident supercomputer manufacturer purchased workstation company silicon graphic purchased cray purchased convex result nearly person computer access high performance processing peak speed new personal computer increase computer encounter performance challenge typically supercomputer user personal workstation need know intimate detail high performance computing program system maximum performance benefit understanding strength weakness newest high performance system scope high performance computing high performance computing run broad range system desktop computer lar ge parallel processing system high performance system based reduced instruction set computer risc processor technique learned type transfer system high performance risc processor designed easily inserted cpu accessing single memory using symmetric multi pr ocessing smp programming multiple processor solve single problem add set additional challenge programmer programmer aware multiple processor operate work ef ficiently divided processor processor powerful small number processor single enclosure application lar ge need span multiple enclosure order cooperate solve lar ger application enclosure linked network function network workstation used individually batch queuing used lar ge multicomputer using message passing tool parallel virtual machine pvm interface mpi lar gest problem data interaction user compute budget million dollar end thehigh performance computing spectrum scalable parallel processing system hundred thousand processor system come flavor type programmed using message passing instead using standard local area network system connected using proprietary scalable interconnect marketing speak high performance interconnect system scale thousand processor keeping time spent wasted performing overhead communication minimum second type lar ge parallel processing scalable uniform memory access numa system system use high performance inter connect processor instead exchanging message system use interconnect implement distributed shared memory accessed processor using paradigm similar programming smp system area memory slower access studying high performance computing study high performance computing excellent chance revisit computer architecture set quest wring bit performance computer system motivated fully understand aspect computer architecture direct impact s performance computer history salesperson told compiler solve problem compiler writer absolute best performance hardware claim probably completely true ability compiler deliver peak performance available hardware improves succeeding generation hardware software hierarchy high performance computing architecture depend compiler programmer responsibility performance code single processor smp system cpu goal programmer stay way compiler oftenconstructs used improve performance particular architecture limit ability achieve performance architecture brilliant read obtuse hand optimization confuse compiler limiting ability automatically transform code advantage particular strength computer architecture programmer important know compiler work know help leave w e aware compiler improve salesperson claim s best leave compiler hierarchy high performance computer need learn new technique map program architecture including language extension library call compiler directive use feature program portable using higher construct make modification result poor performance individual risc microprocessor make parallel processing measuring performance computer purchased computationally intensive application important determine actually perform function way choose set competing system vendor loan period time test application end evaluation period send system did make grade pay favorite unfortunately vendor won t lend extended period time unless assurance eventually purchase evaluate s potential performance using benchmark industry benchmark locally developed benchmark type benchmark require careful thought planning ef fective tool determining best step quite aside economics computer performance fascinating challenging subject computer architecture interesting right topic computer professional comfortable getting bit formance important application stimulating exercise addition economic necessity probably people simply enjoy matching wit clever computer architecture need game basic understanding modern computer architecture y ou don t need advanced degree computer engineering need understand basic terminology basic understanding benchmarking performance measurement quantify success failure use information improve performance application book intended easily understood introduction overview high performance computing interesting field important make greater demand common personal computer high performance computer field tradeof f single cpu performance performance multiple processor multiple processor system generally expensive dif ficult program unless book people claim eventually single cpu fast won t need understand type advanced architecture require skill program far field computing performance single inexpensive microprocessor increased thousandfold lashing thousand processor millionfold increase power cheaper building block high performance computing greater benefit using processor point future single processor isfaster scalable system today think connect new processor single s book interested read memory let s say fast asleep night begin dreaming dream time machine superscalar processor y ou turn time machine arrive time purchase ibm pc intel microprocessor running mhz rest night toss turn try adapt processor intel socket using soldering iron swiss army knife just wake new computer finally work turn run linpack footnote benchmark issue press release w ould expect turn dream nightmare chance good turn nightmare just like previous night went middle age jet engine horse y ou got stop eating double pepperoni pizza late night link chapter using published benchmark detail linpack benchmark speed computational aspect processor infinitely fast load store data instruction memory today s processor continue creep closer infinitely fast processing memory performance increasing slower rate longer memory infinitely fast interesting problem high performance computing use lar ge memory computer getting faster size problem tend operate go trouble want solve problem high speed need memory lar ge time big challenge possible approach include following memory component individually fast respond memory access request slow memory accessed fashion hopefully ef fect faster memory memory design wide transfer contains byte divided faster slower portion arranged fast portion used slow economics dominant force computer business cheap statistically optimized memory better seller prohibitively expensive blazingly fast choice choice choice used combination attain good fraction performance component fast chance good high performance workstation incorporates memory decided thing software used ef ficiently compiler knowledge way memory arranged detail cache optimize use extent place optimization user application ll later book good pattern memory access work component chapter discus piece memory work w e look pattern data instruction access factor overall runtime especially cpu speed increase w e talk bit performance implication running virtual memory t echnology fast memory used today semiconductor footnote come flavor dynamic random access memory dram static random access memory sram term random mean address memory location order distinguish random access serial memory step intervening location particular interested example storage medium random magnetic tape term dynamic static technology used design memory cell dram char device bit represented electrical char ge stored small capacitor char ge leak away short time continually refreshed prevent data lost act reading bit dram dischar ge bit requiring refreshed s possible read memory bit dram s refreshed magnetic core memory used application radiation hardness resistance change caused ionizing radiation important sram based gate bit stored connected transistor sram memory retain data long power need form data refresh dram fers best highest density memory cell chip mean lower cost board space power heat hand application cache video memory require higher speed sram better suited currently choose sram dram slower speed nanosecond n sram access time n higher cost heat power board space addition basic technology store single bit data memory performance limited practical consideration wiring layout external pin chip communicate address data information memory processor t ime time take read write memory location called memory access time related quantity memory cycle time access time say quickly reference memory location cycle time describes repeat reference sound like thing instance ask data dram chip access time n ask data chip chip internally recover previous access retrieving data sequentially dram chip technology improved performance chip data immediately following previously accessed data accessed quickly n access cycle time commodity dram shorter just year ago meaning possible build faster memory system cpu clock speed increased home computer market make good study early access time commodity dram n shorter clock cycle mhz n ibm pc xt meant dram connected directly cpu worrying running memory faster xt t model introduced cpu clocked quickly access time available commodity memory faster memory available price vendor punted selling computer wait state added memory access cycle w ait state artificial delay slow reference memory appears match speed faster cpu penalty technique adding wait state begin significantly impact performance t oday cpu speed farther ahead dram speed clock time commodity home computer gone n xt n access time commodity dram decreased disproportionately n n processor performance double month memory performance double roughly seven speed gap lar ger workstation model clock interval short n vendor make dif ference cpu speed memory speed memory supercomputer used sram capable keeping clock cycle using sram main memory reason cray system needed liquid cooling unfortunately s practical moderately priced rely exclusively sram storage s practical manufacture inexpensive system storage using exclusively sram solution hierarchy memory using processor register level sram cache dram main memory virtual memory stored medium disk point memory hierarchy trick employed make best use available technology remainder chapter examine memory hierarchy impact performance sense today s high performance microprocessor performing computation quickly task high performance programmer careful management memory hierarchy sense s useful intellectual exercise view simple computation addition multiplication infinitely fast order programmer focus impact memory operation overall performance layer memory hierarchy cpu register operate fast rest processor goal operand register possible especially important intermediate value used long computation x g w w m computing value divided w store result multiplying g shame store intermediate result memory reload instruction later modern processor moderate optimization intermediate result stored register value w used computation loaded used twice eliminate wasted load compiler good detecting type optimization ef ficiently making use available register adding register processor performance benefit s practical add register processor store entire problem data use slower memory technology register memory hierarchy encounter cache cache small amount sram store subset content memory hope cache right subset main memory right time actual cache architecture change cycle time processor improved processor fast sram chip fast lead multilevel cache approach level cache implemented processor link show approximate speed accessing memory hierarchy dec alpha memory access speed dec alpharegisters n n n n memory n reference cache say hit rate generally hit rate better considered good cache cache hit rate considered acceptable application performance drop f steeply characterize average read performance memory hierarchy examining probability particular load satisfied particular level hierarchy example assume memory architecture cache speed n speed n memory speed n memory reference satisfied cache time cache time main memory time average memory performance n easily s important cache hit rate higher given cache hold subset main memory time s important index area main memory currently stored cache t o reduce space dedicated tracking memory area cache cache divided number equal sized slot known line line contains number sequential main memory location generally sixteen integer real number data line come memory line contain data far separated program data somebody s program link ask memory computer check data available cache line data returned minimal delay s program delayed new line fetched main memory course new line brought thrown lucky won t containing data just need cache line come dif ferent part memoryon multiprocessor computer cpu written data returned main memory rest processor processor aware local cache activity need told invalidate old line containing previous value written variable don t accidentally use stale data known maintaining coher ency dif ferent cache problem complex multiprocessor footnote link describes cache coherency cache ef fective program exhibit characteristic help kep hit rate high characteristic called spatial temporal locality r eference program make use instruction data near instruction data space time cache line retrieved main memory contains information caused cache miss neighboring information chance good time program need data cache line just fetched recently fetched cache work best program reading sequentially memory assume program reading integer cache line size bit program reference word cache line wait cache line loaded main memory seven reference memory satisfied quickly cache called unit stride address successive data element incremented data retrieved cache used following loop loop sum sum end program access lar ge data structure using stride performance suf fers data loaded cache used example sum sum end code experience number cache miss previous loop data loaded cache program need word loaded cache program performs addition previous loop elapsed time roughly previous loop memory operation dominate performance example bit contrived situation stride occur quite tran dimensional array stored memory successive element column stored sequentially followed element second column array processed row iteration inner loop produce reference pattern follows real j sum sum j end end interestingly tran programmer likely write loop alphabetical order follows producing stride byte successive load operation real j sum sum j end end compiler detect suboptimal loop order reverse order loop make best use memory link code transformation produce different result compiler permission interchange loop particular example reading book just code properly place ptr null ptr element retrieved based content current element type loop bounce memory particular pattern called pointer chasing good way improve performance code pattern certain type code called gather scatter occurs loop sum sum arr ind ind array contains fsets arr array like linked list exact pattern memory reference known runtime value stored ind array known system special hardware support accelerate particular ganization process pairing memory location cache line called mapping course given cache smaller main memory share cache line dif ferent memory location cache cache line record memory address called tag represents used tag used track area memory stored particular cache line way memory location tag mapped cache line beneficial ef fect way program run heavily used memory location map cache line miss rate higher like cache ganized way direct mapped fully associative set associative cache direct mapping shown link simplest algorithm deciding memory map cache say example computer cache direct mapped scheme memory location map cache location memory location word memory map cache size way think imagine metal spring chalk line marked time spring encounter chalk line place modulo circumference spring spring long chalk line cross coil analog lar ge memory location mapping cache line problem occur alternating runtime memory reference mapped cache point cache line reference cause cache miss replaces entry just replaced causing lot overhead popular word thrashing lot thrashing cache liability asset cache miss requires cache line refilled operation move data merely satisfying reference directly main memory easy construct pathological case cause thrashing cache memory address map cache line real b common b b end end array b exactly kb storage inclusion common assures array start exactly kb apart memory direct mapped cache line used used b likewise b alternating reference cause repeated cache miss t o fix adjust size array variable common reason generally avoid array dimension close power fully associative cache extreme direct mapped cache fully associative cache memory location mapped cache line regardless memory address fully associative cache type memory used construct associative memory associative memory like regular memory memory cell know data contains processor go looking piece data cache line asked cache line containing data hold hand say cache miss question cache line replaced new data map memory location cache line algorithm like mapped cache memory ask fully associative cache line choose memory location represent usually recently used line get overwritten new data assumption data hasn t used quite likely used future fully associative cache superior utilization compared direct mapped cache s difficult example program cause thrashing fully associative cache expense fully associative cache high term size price speed associative cache exist tend small cache imagine direct mapped cache sitting single cache unit shown link memory location corresponds particular cache line cache choose replace cache miss subject decision line used way decision fully associative cache choice called cache cache generally come separate bank cache called set associative cache respectively course benefit drawback type cache cache immune cache thrashing cache size foreach mapping memory address cache line choice beauty cache s easy implement lar ge perform roughly design y machine contain multiple cache dif ferent purpose s little program causing thrashing associative cache real b c common b c b c end end like previous cache thrasher program force repeated access cache line variable contending choose set mapping instead way fix change size array insert common way accidentally arranged program thrash like hard detect aside feeling program run little slow vendor provide tool measuring cache miss cacheinstruction cache far glossed kind information expect cache main memory cpu instruction data think demand data separate demand instruction superscalar processor example s possible execute instruction cause data cache miss alongside instruction require data cache operate register doesn t fair cache miss data reference instruction fetching instruction cache tied furthermore cache depends locality reference bit data bit data instruction instruction kind interplay instruction data possible instruction bump perfectly useful data cache vice versa complete disregard locality reference design used single cache instruction data newer design employing known harvar d memory ar chitectur e demand data segregated demand instruction main memory single lar ge pool processor separate data instruction cache possibly dif ferent design providing independent source data instruction aggregate rate information coming memory increased interference type memory reference minimized instruction generally extremely high level locality reference sequential nature program instruction cache don t particularly lar ge ef fective typical architecture separate cache instruction data combined cache example powerpc separate cache instruction data combined memory virtual memory decouples address used program virtual address actual address data stored memory physical address y program see address space starting working way lar ge number actual physical address assigned dif ferent give degree flexibility allowing process believe entire memory trait virtual memory system divide program s memory page chunk page size vary byte mb lar ger depending machine page don t allocated contiguously program see way separated page program easier arrange memory portion disk page t ables say program asks variable stored location virtual memory machine direct correspondence program s idea location physical memory system idea t o variable actually stored location translated virtual physical address map containing translation called page table process page table associated corresponding dif ferent region program text data segment understand address translation work imagine following scenario point program asks data location link show step required complete retrieval data choosing location identified region memory reference fall identifies page table involved location help processor choose entry table instance page size byte fall second page page range address second table entry hold address page housing value location address mapping operating store address virtually s going translation locate table memory physical translation finally true address location memory reference complete processor return executing program translation lookaside buffer address translation page table pretty complicated required table lookup maybe locate data memory reference complicated virtual memory computer horrible performer fortunately locality reference cause virtual address translation group program repeat virtual page mapping million time second repeated use data apply cache modern virtual memory machine special cache called translation lookaside buffer tlb translation input tlb integer identifies program making memory request virtual page requested output pop pointer physical page number virtual address physical address tlb lookup occur parallel instruction execution address data tlb memory reference proceed quickly like kind cache tlb limited size doesn t contain entry handle possible translation program run computer larger pool address translation kept memory page table program asks translation entry doesn t exist tlb suf fer tlb miss information needed generated new page need created retrieved page table tlb good reason type cache good reduces cost memory reference like cache pathological case tlb fail deliver value easiest case construct memory reference program make cause tlb miss real x common x sum sum x end end assume tlb page size computer kb time inner loop example code program asks data byte byte away reference reference fall dif ferent memory page cause tlb miss inner loop taken time total million tlb miss t o add insult injury reference guaranteed cause data cache miss admittedly start loop like presuming loop good restructured version code cruise memory like warm knife butter real x common x sum sum x end revised loop unit stride tlb miss occur usually necessary explicitly tune program make good use tlb program tuned nearly tuned tlb friendly performance benefit keeping tlb small tlb entry contains length field single tlb entry megabyte length used translate address stored multiple virtual memory page page fault page table entry contains information page represents including flag tell translation valid associated page modified information describing new page initialized reference page aren t marked valid called page fault taking scenario say program asks variable particular memory location processor go look cache find isn t cache miss mean loaded memory go tlb physical location data memory find tlb entry tlb miss try consulting page table refilling tlb find entry particular page memory page beenshipped disk page fault step memory hierarchy shrugged f request new page created memory possibly depending circumstance refilled disk lot time page fault aren t error optimal condition program suf fers number page fault writing variable time calling subroutine called cause page fault surprising thought illusion entire program present memory start portion loaded reason make space page data referenced instruction executed page required run job created pulled disk footnote term demand paging pool physical memory page limited physical memory limited machine program lobbying space higher number page fault physical memory page continually recycled purpose machine memory demand allocated page tend stick short expect fewer page fault quiet machine trick remember end working computer vendor run short benchmark twice system number page fault second run find page left memory won t pay page fault footnote text page identified disk device block number came paging space swap space disk slowest piece memory hierarchy machine scenario saw memory reference pushed slower slower performance medium finally satisfied step view disk paging space having relationship main memory main memory cache kind optimization apply locality reference important y ou run program lar ger main memory machine greatlydecreased performance look memory optimization link concentrate keeping activity fastest part memory avoiding slow memory performance given importance area high performance computing performance computer s memory subsystem technique used improve performance memory system computer attribute memory performance generally bandwidth latency memory design change improve expense improvement positively impact bandwidth latency bandwidth generally focus best possible transfer rate memory usually measured running long loop reading reading writing memory footnote latency measure performance memory move small data word processor memory important important high performance application stream section link chapter measure memory bandwidth memory system divided component dif ferent bandwidth latency figure dif ferent component shown link bandwidth rate cache cpu higher bandwidth main memory cache instance cache path memory usually peak memory bandwidth quoted vendor speed data cache processor rest section look technique improve latency bandwidth large cache mentioned start chapter disparity cpu speed memory growing look closely vendor innovating way workstation fered mb data cache lar ger main memory system machine just year ago w ith lar ge cache small moderately lar ge data set fit completely inside incredibly goodperformance w atch testing new hardware program grows lar ge cache performance drop f considerably factor depending memory access pattern interestingly increase cache size vendor render benchmark obsolete simple memory linpack benchmark probably single respected benchmark determine average performance wide range application ibm introduced ibm cache lar ge contain entire matrix duration benchmark time workstation performance benchmark order supercomputer sense entire data structure sram cache operating like cray vector supercomputer problem cray maintain improve performance matrix suf fered significant performance loss increased matrix size soon workstation vendor introduced similarly lar ge cache linpack benchmark ceased useful indicator average application performance wider memory system consider happens cache line refilled memory consecutive memory location main memory read consecutive location cache line number byte transferred depends big line byte byte w e want refill proceed quickly instruction stalled pipeline processor waiting instruction link dram chip provide bit data n remember cycle time cache line take n narrow memory way make operation faster widen memory shown link instead having row dram create multiple row dram cycle contiguous bit fill time faster wide memory improve performance memory increasing width memory length cache line time entire line single memory cycle sgi power challenge series system memory width bit downside wider memory dram added multiple modern workstation personal computer memory expanded form single inline memory module simms simms currently module dram chip ready installed memory bypassing cache s interesting spent nearly entire chapter great cache high performance computer going bypass cache improve performance mentioned earlier type processing result stride bouncing memory type memory reference pattern bring behavior architecture reference pattern improved performance bypassing cache inability support type computation remains area traditional supercomputer significantly outperform risc processor reason risc processor number crunching special instruction bypass data cache memory data transferred directly processor main memory footnote link bank simms cache fill bit n memory cycle remember data available n t data dram refresh n later doing stride load capability bypass cache load satisfied simms n simm refreshed load occur simms n random mix load chance load fall fresh dram load fall bank refreshing simply wait refresh completes way machine uncached memory space process synchronization device register memory reference location bypass cache address chosen necessarily instruction advantage bypassing cache data doesn t need moved sram cache operation add n load time single word avoids invalidating content entire cache line cache adding cache bypass increasing width adding bank increase cost memory computer vendor make economic choice technique need apply suf ficient performance particular processor processor speed increase vendor add memory feature commodity system maintain balance processor speed bypassing cache interleaved pipelined memory system vector supercomputer cra y convex machine depend multibanked memory system performance particular memory interleaving interleave bank bit wide expensive memory build nice performance characteristic having lar ge number bank help reduce chance repeated access memory bank hit bank twice row penalty delay nearly n long time machine clock speed n thing having lar ge number bank suf ficient feed processor using n dram addition interleaving memory subsystem need pipelined cpu begin second fourth load cpu received result load shown link time receives result bank n start load bank pipeline fed way brief startup delay load complete n memory appears operate clock rate cpu pipelined memory approach facilitated vector register processor using hardware operation pipelined dif ference operation bank accessed sequential order random pattern memory reference s possible reaccess memory bank completely refreshed previous access called bank stall multibanked memory different access pattern subject bank stall varying severity instance access fourth word memory subject bank stall recovery occur sooner reference second word experience bank stall bank recovered time reference come depends relative speed processor memory irregular access pattern sure encounter bank stall addition bank stall hazard reference directly multibanked memory carry greater latency successfully cached memory access reference going memory slower cache additional address translation step banked memory reference pipelined long reference started advance pipelined multibanked reference flight time giving good throughput performed vector operation fashion using set explicit memory pipeline superior performance long vector computation single instruction perform computation using memory pipe softwar e managed cache s interesting thought vector processor plan far advance start memory pipe t risc processor start really need data situation way priming cache hide latency far advance appear memory reference operate speed cache concept called prefetching supported using special prefetch instruction available risc processor prefetch instruction operates just like standard load instruction processor doesn t wait cache instruction completes idea prefetch far ahead computation data ready cache time actual computation occurs following example used prefetch arr end end actual tran prefetching usually assembly code generated compiler detects stepping array using fixed stride compiler typically estimate far ahead prefetching example particularly slow value changed value changed accordingly processor issue instruction cycle payback prefetch instruction valuable time instruction stream exchange uncertain benefit superscalar processor cache hint mixed rest instruction stream issued alongside real instruction saved program suf fering extra cache miss worth having effect memory refer ences memory operation typically access memory execute phase pipeline risc processor processor thing dif ferent risc processor load half finished given moment current processor memory operation active waiting memory arrive excellent way compensate slow memory latency compared cpu speed consider following loop loadi set iteration loadi set index variable loop load load value memory incr add store store incremented value memory incr add compare check loop termination blt loop branch loop example assume cycle access memory decode put load instruction reorder buf fer irb load start cycle suspended execute phase rest instruction irb incr wait load st ore wait using rename register incr comp bl t computed go loop sends load irb memory location wait looping continues iteration loop irb load actually show memory incr store iteration begin executing course store take time second load finish work like aspect computing architecture speculative execution optimizes memory reference risc processor dynamically unrolls loop execution time compensate memory subsystem delay assuming pipelined multibanked memory multiple memory operation started complete hp p chip memory operation flight time processor continues dispatch memory operation operation begin complete unlike vector processor prefetch instruction processor doe need anticipate precise pattern memory reference itcan carefully control memory subsystem result processor achieve peak performance far range code sequence vector processor risc processor prefetch capability implicit tolerance memory latency make processor ideal use scalable processor future memory hierarchy complex current processor level cache main memory unfortunately code segment doesn t benefit significantly architecture traversal address known previous load completed load fundamentally serialized dynamic ram t echnology t rends technique section focused deal imperfection dynamic ram chip clock rate hit mhz n sram start look pretty slow s clear demand ram continue increase gigabit dram fit single chip significant work underway make new super faster tuned extremely fast processor present future technology relatively straightforward require major redesign way processor memory manufactured dram improvement include fast page mode dram extended data ram edo ram synchronous dram sdram rambus cached dram cdram fast page mode dram save time allowing mode entire address doesn t chip memoryoperation instead assumption memory accessed sequentially bit address clocked successive read writes edo ram modification output buf fering page mode ram allows operate roughly twice quickly operation refresh synchr onous dram synchronized using external clock allows cache dram coordinate operation sdram pipeline retrieval multiple memory bit improve overall throughput rambus proprietary technology capable data transfer rambus us significant logic chip operates higher power level typical dram cached dram combine sram cache chip dram tightly couple sram dram provides performance similar sram device limitation cache architecture advantage cdram approach cache increased dram increased dealing memory system lar ge number interleaf interleave sram reduce latency assuming data requested sram advanced approach integrate processor sram dram single chip clocked say ghz containing mb data understandably wide range technical problem solve type component widely available s question manufacturing process dram processor beginning conver ge way rambus biggest performance problem type need mb closing note say computer future good memory just happens cpu attached high performance microprocessor system high performance computing engine problem memory us dram main memory solved architecture technology ef fort underway transform workstation personal computer memory capable supercomputer memory cpu speed increase faster memory speed need technique book multiple processor memory problem don t better usually worse w ith hungry processor ready data memory subsystem extremely strained just little skill restructure memory access play memory s strength instead exer cise pr oblem following code segment traverse pointer chain p char p null code interact cache reference fall small portion memory code interact cache reference stretched megabyte exer cise pr oblem code link behave multibanked memory cache exer cise pr oblem long time ago people regularly wrote code program wrote instruction memory changed behavior implication code machine harvard memory architecture exer cise pr oblem assume memory architecture cache speed n speed n memory speed n compare average memory performance memory memory exer cise pr oblem computer run loop process array varying length million array array doe number addition second change array length change experiment real real integer integer significant impact performance lar ger array element integer versus t ry range different computer exer cise pr oblem create array loop array row inner loop column inner loop perform simple operation element loop perform dif ferently experiment dif ferent dimension array performance impact exer cise pr oblem write program repeatedly executes timed loop dif ferent size determine cache size want make point sacred say plus doe equal designed shock attack fundamental assumption nature universe w ell chapter point number learn doe equal use number computation chapter explore limitation number programmer write code minimize ef fect limitation chapter just brief introduction significant field mathematics called numerical analysis real world real number quantity distance velocity mass angle quantity real number footnote wonderful property real number unlimited accuracy example considering ratio circumference circle diameter arrive value decimal value pi doe terminate real number unlimited accuracy t write pi real number real number rational number represented ratio integer real number rational number surprisingly real number aren t rational number called irrational y ou probably want start ar gument irrational number unless lot free time hand high performance computing simulate real world somewhat ironic use simulated real number simulation real world unfortunately piece paper computer don t space writing digit pi w e decide need accuracy round real number certain number digit example decide digit accuracy approximation pi state legislature attempted pas law pi cited evidence iq governmental entity legislature just suggesting need digit accuracy pi foresaw need save precious memory space computer representing real given perfectly represent real number digital computer come compromise allows approximate real number footnote number dif ferent way used represent real number challenge selecting representation f space accuracy tradeof f speed accuracy field high performance computing generally expect processor produce point result clock cycle pretty clear application aren t willing drop factor just little accuracy discus format used high performance computer discus alternative albeit slower technique representing real number interestingly analog computer easier time representing real number imagine water adding analog computer consists glass water glass water glass perfectly represented real number pouring glass adding real number perfectly unless spill wind real number water glass problem analog computer knowing just water glass problematic perform million addition second using technique getting pretty wet t ry resist temptation start ar gument quantum mechanic cause real number rational number don t point fact digital computer really analog computer core trying focus value drifting away binary coded decimal earliest computer technique use binary coded decimal bcd bcd digit stored bit number arbitrarily long precision memory format allows programmer choose precision required variable unfortunately dif ficult build extremely hardware perform arithmetic operation number number far longer bit did fit nicely register point operation bcd using loop microcode flexibility accuracy bcd representation need round real number fit limited space limitation bcd approach store value field field capable storing value space wasted rational number intriguing method storing real number store rational number t o briefly review mathematics rational number subset real number expressed ratio integer number example rational number rational number perfect representation decimal expressed decimal using rational number real number stored integer number representing numerator denominator basic fractional arithmetic operation used addition subtraction multiplication division shown link rational number mathematics limitation occurs using rational number represent real number size numerator denominator tends grow addition common denominator t o number extremely lar ge operation important greatest common divisor gcd reduce fraction compact representation value grow common divisor lar ge integer value stored using dynamic memory form approximation used losing primary advantage rational number mathematical package maple mathematica need produce exact result smaller data set use rational number represent real number time useful technique performance storage cost significant need produce exact result instance fixed point desired number decimal place known advance s possible use representation using technique real number stored scaled integer solves problem fraction perfectly represented fraction multiply store scaled integer perfectly represent fractional approach used value money number digit past decimal point small known just number accurately represented doesn t mean error format multiplying number fraction digit t represented point format form rounding used example bank bank balance digit accuracy resulting balance course probably heard story programmer getting rich depositing remaining amount account guess bank probably figured thebank keep money doe make wonder round truncate type calculation footnote bank round instead truncating knowing make teller machine fee format prevalent high performance computing variation scientific notation scientific notation real number represented using mantissa base exponent mantissa typically fixed number place accuracy mantissa represented base base bcd generally limited range exponent exponent expressed power primary advantage representation provides wide overall range value using storage representation primary limitation format dif ference successive value uniform example assume represent digit exponent range number close zero distance successive number small number lar ger number distance close small number number lar ger number distance close lar ge number million link use digit exponent ranging distance successive multiple equivalent representation number using scientific notation convention shift mantissa adjust exponent exactly nonzero digit left decimal point number expressed way said list normalized link show number link normalized dominant approach high performance computing wide variety specific format use computer vendor historically computer vendor particular format number program executed dif ferent brand computer generally produce dif ferent answer invariably led heated discussion provided right answer s generating meaningless result footnote interestingly easy answer question programmer generally trusted result computer used debug code dismissed result computer garbage normalized number storing number digital computer typically mantissa normalized mantissa exponent converted packed word bit exponent overall range format increased number digit accuracy decreased base exponent using base exponent increase overall range exponent normalization occur boundary available digit accuracy reduced average later ieee standard format represents representation problem representation number expressed perfectly number example represented perfectly value produce infinitely repeating decimal value rounded stored format w ith suf ficient digit precision generally problem computation doe lead anomaly algebraic rule appear apply consider following example real x y x y y y x enddo y print algebra truth print endif print end glance appears simple mathematics tell time unfortunately represented exactly decimal rounded end rounded bit slightly smaller number added doe quite add x y real dif ference real dif ference possible method comparing computed value constant subtract value test close value example rewrite test code type variable question expected error computation produce y determines appropriate value used declare value close declared equal area inexact representation problem fact algebraic inverse hold number example using real value x doe evaluate value x problem computing inverse matrix using decomposition repeatedly doe division multiplication addition subtraction straightforward matrix integer coef ficients integer solution pretty good chance won t exact solution run algorithm discussing technique improving accuracy matrix inverse computation best left numerical analysis text ab print close government work print close endif algebra doe w ork example proceeding section focused limitation multiplication division addition subtraction mean perfect limitation number digit precision certain addition subtraction ef fect consider following example using real digit precision x y x print nut endif number precisely representable adding problematic prior adding number decimal point aligned link figure loss accuracy aligning decimal point unfortunately computed exact result fit real variable digit accuracy truncating addition value y exactly sadder addition performed million time value y limitation precision algebraic law apply time instance answer obtain commutative law addition whichever operand pick operation yield result mathematically equivalent mean choose following form answer x y z y x z equivalent y z x version isn t equivalent order calculation changed rearrangement equivalent algebraically computationally changing order calculation taken advantage associativity operation associative transformation original code understand order calculation matter imagine computer perform arithmetic significant decimal place assume value x y z respectively mean x y z y z x version slightly dif ferent answer adding sum smaller number insignificant added lar ger number computing add small number combined sum lar ge influence final answer reason compiler rearrange operation sake performance generally user requested optimization default reason tran language strict exact order evaluation expression t o compliant compiler ensure operation occur exactly express footnote didn t mean kernighan ritchie c operator precedence rule dif ferent precedence operator honored come evaluation generally occurs left right operator equal precedence compiler allowed treat commutative operation  fully associative parenthesized instance tell c compiler x y z c compiler free ignore combine x y z order pleases armed knowledge view following code segment real sum sum sum sum enddo begin look like nightmare waiting happen accuracy sum depends relative magnitude order value array sort array smallest lar gest perform addition accurate value algorithm computing sum array reduce error requiring sort data consult good textbook numerical analysis detail algorithm range magnitude value array relatively small forward computation sum probably suf accuracy using guard digit section explore technique improve precision point computation using additional storage space point number consider following example digit accuracy performing following subtraction value perfectly represented using format digit precision available aligning decimal point computation result end significant error shown link need guard digit perform computation round correctly need increase number significant digit stored value w e need additional digit precision performing computation solution add extra guard digit maintained interim step computation case maintained digit accuracy aligning operand rounded normalizing assigning final value proper result guard digit need present execution unit cpu necessary add guard digit register value stored memory necessary extremely lar ge number guard digit point dif ference magnitude operand great lost digit af fect addition rounding result history ieee format history ieee format prior risc microprocessor revolution vendor point format based designer view relative importance range versus accuracy speed versus accuracy uncommon vendor carefully analyze limitation vendor s format use information convince user theirs accurate point implementation reality format perfect format simply imperfect dif ferent way institute electrical electronics engineer ieee produced standard format title standard ieee standard binary standard provided precise definition format described operation value ieee developed variety format use quite time ieee working group benefit examining existing design taking strong point avoiding mistake existing design ieee specification beginning design intel coprocessor format improved dec v ax format adding number significant feature near universal adoption ieee format occurred time period high performance computing vendor mid cray ibm dec control data proprietary format continue supporting installed user base really choice continue support existing format mid late primary system supported ieee format risc workstation coprocessors microprocessor designer system need protect proprietary format readily adopted ieee format risc processor moved integer computing high performance computing cpu designer way make ieee operation operate quickly year ieee gone standard coprocessors dominant standard computer standard user beneficiary portable standard ieee standard specified number dif ferent detail operation including storage format precise specification result operation special value specified runtime behavior illegal operation specifying format level insures computer compliant standard user expect repeatable execution hardware platform operation executed order ieee storage format common ieee format use number link give general parameter data type parameter ieee tran c bitsexponent bitsmantissa bit single real float double real double extendedreal double tran format usually called real format usually called double tran compiler double size data type reason safest declare tran variable real real format wellsupported compiler hardware format bit arrangement single double format shown link based storage layout link derive range accuracy format shown link format range accuracy ieee normalized numberlargest finite accuracy single digit double digit extended digit converting fr om ieee internal format examine number stored bit sign number number stored format s complement exponent stored field biased adding exponent result exponent ranging mantissa converted normalized nonzero digit left binary place adjusting exponent necessary digit right binary point stored bit word number normalized need store leading give free extra bit precision bit dropped s longer proper refer stored value mantissa ieee parlance mantissa minus leading digit called significand link show example conversion ieee format converting ieee format format similar exponent bit long biased adding exponent significand bit long ieee operation ieee standard specifies computation performed point value following operation addition subtraction multiplication division square root remainder modulo conversion integer conversion printed operation specified manner giving flexibility cpu designer implement operation ef ficiently possible maintaining compliance standard operation ieee standard requires maintenance guard digit sticky bit intermediate value guard digit sticky bit used indicate bit second guard digit nonzero computation using guard sticky bit link bit normal precision guard digit sticky bit guard bit simply operate normal bit significand bit guard bit participate rounding extended operand added sticky bit set bit guard bit nonzero operand footnote extended sum computed rounded value stored memory closest possible value extended sum including guard digit link show possible value guard digit sticky bit resulting stored value explanation somewhat think moment soon come way properly maintain sticky bit computing infinite precision y ou just track thing shifted extended sumstored valuewhy truncated based guard digit truncated based guard digit based guard digit based guard digit rounded based sticky bit rounded based sticky bit rounded based guard digitsextended sum stored v rounded based guard digit priority check guard digit sticky bit just hint real digit make decision looking sticky bit good decision making round storable bit stored value retrieved computation guard digit set zero helpful think stored value having guard digit set zero guard digit sticky bit ieee format insures operation yield rounding intermediate result computed using unlimited precision rounded fit limit precision final computed value point asking care minutia level unless hardware designer don t care examine detail like assured thing developed ieee standard looked detail carefully goal produce accurate possible standard constraint format did good job s thing worry stuf f make great exam v alues addition specifying result operation numeric data ieee standard specifies precise behavior undefined operation dividing zero result indicated using special value value bit pattern stored variable checked operation performed ieee operation defined special value addition normal numeric value link summarizes special value ieee number special v alues ieee numberspecial v alue exponent significand denormalized number nonzero nan number nonzero infinity value exponent significand determines type special value particular number represents zero designed integer zero zero bit pattern denormalized number occur point number continues smaller exponent reached minimum value w e declare minimum smallest representable value denormalized value continue setting exponent bit zero shifting significand bit right adding leading dropped continuing add leading zero indicate smaller value point nonzero digit shifted f right andthe value zero approach called gradual underflow value keep approaching zero eventually zero implementation support denormalized number hardware trap software routine handle number significant performance cost end biased exponent value exponent represent number nan value infinity infinity occurs computation roughly according principle mathematics continue increase magnitude number range format range exceeded value infinity value infinity addition won t increase subtraction won t decrease y ou produce value infinity dividing nonzero value zero divide nonzero value infinity zero result nan value indicates number mathematically defined y ou generate nan dividing zero zero dividing infinity infinity taking square root dif ference infinity nan nan value nonzero significand nan value sticky operation nan input produce nan t rap addition defining result computation aren t mathematically defined ieee standard provides programmer ability detect special value produced way programmer write code adding extensive test code checking magnitude value instead register trap handler event underflow handle event occurs exception defined ieee standard include overflow infinity underflow zero division zero invalid operation inexact operation according standard trap control user case compiler runtime library manages trap direction user compiler flag runtime library call trap generally significant overhead compared single point instruction program continually executing trap code significantly impact performance case s appropriate ignore trap certain operation commonly ignored trap underflow trap iterative program s quite natural value reducing point depending application error situation exception safely ignored run program terminates message overflow handler called time probably mean need figure code exceeding range format probably mean code executing slowly spending time error issue ieee standard doe good job describing point operation performed generally don t write assembly language program write higher language tran s dif ficult compiler generate assembly language need application problem fall category compiler conservative trying generate code produce code doesn t operate peak speed processor processor fully support gradual underflow extra instruction generated certain instruction code underflow instruction unnecessary overhead optimizer take liberty rewriting code improve performance eliminating necessary step example following code z x y z optimizer replace y x case value x close overflow sequence produce result user prefers fast code loosely conforms ieee standard time user writing numerical library routine need total control operation compiler challenge supporting need type user nature high performance computing market benchmark fast loose approach prevails note relatively long chapter lot technical doe begin scratch surface ieee format entire field numerical analysis w e programmer careful accuracy program lest result meaningless basic rule started look compiler option relax enforce strict ieee compliance choose appropriate option program y ou want change option dif ferent portion program use real computation unless sure real sufficient precision given real roughly digit precision digit meaningless rounding computation danger seeing ef fect error result real digit make likely happen aware relative magnitude number performing addition summing number wide range sum smallest lar gest perform multiplication division possible performing comparison computed value check value close identical make sure performing unnecessary type conversion critical portion code excellent reference issue ieee format computer scientist know arithmetic written david goldber g acm computing survey magazine march article give example common problem outline solution cover ieee format thoroughly recommend consult william kahan s home page http excellent material ieee format challenge using point arithmetic dr kahan original designer intel ieee exer cise pr oblem run following code count number inverse perfectly accurate real x y z integer y x z y x z endif enddo print end exer cise pr oblem change type variable real repeat make sure optimization suf ficiently low level compiler eliminating computation exer cise pr oblem write program determine number digit precision real real exer cise pr oblem write program demonstrate summing array forward backward backward forward yield dif ferent result exer cise pr oblem assuming compiler support varying level ieee compliance significant computational code test overall performance various ieee compliance option result program change introduction compiler doe goal optimizing compiler ef ficient translation higher level language fastest possible machine language accurately represents language source make representation good give correct answer executes quickly naturally make dif ference fast program run doesn t produce right answer footnote given expression program executes correctly optimizing compiler look way streamline cut usually mean simplifying code throwing extraneous instruction sharing intermediate result statement advanced optimization seek restructure program actually make code grow size number instruction executed hopefully shrink trade accuracy speed come finally generating machine language compiler know register rule issuing instruction performance need understand cost instruction latency machine resource pipeline especially true processor execute instruction time take balanced instruction mix right proportion fixed point memory branch operation machine busy initially compiler tool allowed write readable assembly language t oday border artificial intelligence source code translate highly optimized machine language wide variety architecture area high performance computing compiler time greater impact performance program processor memory architecture history high performance computing satisfied performance program written language gladly rewrite program assemblylanguage thankfully today s compiler usually make step unnecessary chapter cover basic operation optimizing compiler later chapter cover technique used analyze compile program advanced architecture parallel vector processing system w e start look compiler examining relationship programmer compiler changed compiler high performance computing beginning programmed language time early programmed assembly language constraint memory slow clock rate instruction precious small memory overall program size typically small assembly language suf ficient t oward end programmer began writing code language tran w riting language work portable reliable maintainable given increasing speed capacity computer cost using language programmer willing accept program spent particularly lar ge time particular routine routine operating commonly used library likely written assembly language late early optimizing compiler continued improve point critical portion purpose program written language average compiler generate better code assembly language programmer compiler make better use hardware resource register processor register programmer adopt convention regarding use register help track value register compiler use register like precisely track register available use time high performance computer architecture evolving cray research developing vector processor end computing spectrum compiler quite ready determine new vector instruction used programmer forced write assembly language create highly tran called appropriate vector routine code sense vector processor turned clock came trusting compiler programmer lapsed completely assembly language tran started looking tran like vector computer matured compiler increasingly able detect vectorization performed point compiler better programmer architecture new compiler reduced need extensive directive language extension footnote livermore loop benchmark specifically tested capability compiler ef fectively optimize set loop addition performance benchmark compiler benchmark risc revolution led increasing dependence compiler programming early risc processor intel painful compared cisc processor subtle dif ferences way program coded machine language significant impact overall performance program example programmer count instruction cycle load instruction use result load computational instruction superscalar processor developed certain pair instruction issued simultaneously issued serially large number dif ferent risc processor produced programmer did time learn nuance wringing bit performance processor easier lock processor designer compiler writer hopefully work company hash best way generate machine code use compiler code reasonably good use hardware compiler important tool processor design cycle processor designer greater flexibility type change make example good design revision processor execute existing code slower new revision recompiling code perform faster course important actually provide compiler new processor shipped compiler level performance wide range code just particular benchmark language t o optimize said don t know language using program high performance computer year know called risk inciting outright warfare need discus strength weakness language used high performance computing computer scientist computational scientist train steady diet c footnote language focused data structure object student encounter high performance computing time immediate desire programming favorite language peak performance wide range architecture tran practical language just record author book quite accomplished c tran preconceived notion student ask usually answer way way correct physicist mechanical engineer chemist structural engineer meteorologist programming high performance computer tran language field time computer science student wrote properly working program computed week naturally high performance computer vendor ef fort making tran work architecture reason tran better language fundamental element make c data language unsuitable high performance programming word problem pointer pointer address way good computer scientist construct linked list binary tree binomial queue nifty data structure problem pointer ef fect pointer operation known execution time value pointer loaded memory optimizing compiler see pointer bet make assumption effect pointer operation compile time generate conservative optimized code simply doe exactly operation machine code language lack pointer tran boon optimization seriously limit programmer s ability create data structure application especially highly scalable application use good data structure significantly improve overall performance application t o solve tran specification pointer added tran way attempt tran community programmer beginning use c application data structure area application programmer begin use pointer code tran program suf fer problem inhibit optimization c program sense tran given primary advantage c trying like debate pointer reason adoption rate tran somewhat slowed programmer prefer data structure communication bookkeeping work c doing computation tran tran strength weakness compared tran high performance computing platform tran strong advantage tran area improved semantics enable opportunity advanced optimization advantage especially true distributed memory system data decomposition significant factor link tran popular vendor won t motivated squeeze bit performance tran tran continues mainstream language high performance computing near future language like c tran limited potentially increasing role play way strongest potential challenger tran long run come form numerical tool set matlab package matlab set optimization challenge overcome topple tran s compiler t start taking walk optimizing compiler work w e think s interesting empathize compiler better programmer know compiler want compilation pr ocess basic compiler process compilation process typically broken number identifiable step shown link compiler implemented exactly way help understand dif ferent function compiler perform precompiler preprocessor phase simple textual manipulation source code performed preprocessing step processing include file making simple string substitution code lexical analysis phase incoming source statement decomposed token variable constant comment language element parsing phase input checked syntax compiler translates incoming program intermediate language ready optimization optimization pass performed intermediate language object code generator translates intermediate language assembly code taking consideration particular architectural detail processor question compiler sophisticated order wring bit performance processor step especially optimization step blurred chapter focus traditional optimizing compiler later chapter look closely modern compiler sophisticated optimization intermediate language repr esentation interested optimization program start discussion output parse phase compiler parse phase output form intermediate language il language assembly language intermediate language express calculation original program form compiler manipulate easily furthermore instruction aren t present source address expression array reference visible rest program making subject optimization intermediate language look term complexity s similar assembly code simple definition footnote us variable lost w e ll need definition use information analyze flow data program t ypically calculation areexpressed stream quadruple statement exactly operator operand result footnote presuming original source program recast term quadruple usable intermediate language t o idea work w e going rewrite statement series quadruple definition mean assignment value declaration generally code cast depends level intermediate language c d e taken statement operator operand negate b c d clearly fit quadruple w e need form exactly operator operand statement recast version follows manages employing temporary variable hold intermediate result d e c workable intermediate language course need feature like pointer w e going suggest create intermediate language investigate optimization work t o begin need establish rule instruction consist opcode operand result depending instruction operand assignment form x y op z meaning x get result op applied y memory reference explicit load store temporary value used branch calculated separately actual branch jump absolute address building compiler d need little specific purpose consider following bit c code j n k k j m j loop translates intermediate language representation shown j n jmp b jmp c true b k j k j m j j jmp true c c source line represented il statement risc processor il code close machine language turn directly object code footnote lowest optimization level doe literal translation intermediate language machine code code generally lar ge performs poorly looking place save instruction instance j get loaded temporary place surely reduce w e analysis make optimization link example machine code translated directly intermediate language basic block generating intermediate language want cut basic block code sequence start instruction follows branch tar branch way basic block entrance exit link represents il code group basic block basic block make code easier analyze restricting flow control basic block eliminating branch sure statement get executed second doe course branch haven t disappeared forced outside block form connecting arrow flow graph intermediate language divided basic blockswe free extract information block instance say certainty variable given block us variable defines set value w e able block contained branch w e gather kind information calculation performs analyzed block know go come modify improve performance just worry interaction block optimization level wide variety optimization technique applicable situation user typically given choice particular optimization performed expressed form optimization level specified compiler option dif ferent level optimization controlled compiler flag include following optimization generates machine code directly intermediate language lar ge slow code primary us optimization debugger establishing correct program output operation precisely user specified right basic optimization similar described chapter generally work minimize intermediate language generate fast compact code interpr ocedural analysis look boundary single routine optimization opportunity optimization level include extending basic optimization copy propagation multiple routine result technique procedure inlining improve performance runtime pr ofile analysis possible use runtime profile help compiler generate improved code based knowledge pattern runtime execution gathered profile information optimization ieee standard ieee specifies precisely point operation performed precise ef fects operation compiler identify certain algebraic transformation increase speed program replacing division reciprocal multiplication change output result unoptimized code data flow analysis identifies potential parallelism instruction block successive loop optimization include automatic vectorization parallelization data decomposition advanced architecture computer optimization controlled dif ferent compiler option take time figure best combination compiler flag particular code set code case programmer compile dif ferent routine using dif ferent optimization setting best overall optimization intermediate language broken basic block number optimization performed code block optimization simple af fect tuples basic block optimization code basic block altering program result example valuable computation body loop code immediately preceding loop section going list classical optimization tell suggesting make change compiler automatically perform optimization lowest optimization level said start chapter understand compiler t better programmer able play compiler s strength copy pr opagation start let s look technique untangling calculation t ake look following segment code notice computation involving x y z x written second statement requires result proceed need x calculate unnecessary dependency translate delay runtime footnote little bit rearrangement make second statement independent propagating copy new calculation z us value y directly code example flow dependence dependency link x y z y notice left statement intact y ou ask problem t tell value x needed analysis decide turn statement need new value x assignment eliminated later dead code removal constant folding clever compiler constant program obvious constant like defined parameter statement obvious local variable redefined combine calculation constant expr ession little program constant k program main integer k parameter k j k end k constant individually combination constant mean j constant compiler reduces constant expression like constant technique called constant folding doe constant folding work y ou possible examine path given variable defined en route aparticular basic block discover path lead value constant replace reference variable constant replacement ef fect compiler find looking expression solely constant evaluate expression compile time replace constant iteration compiler located expression candidate constant folding programmer improve performance making compiler aware constant value application example following code segment x x y compiler generate quite dif ferent runtime code knew y doe know value y generate conservative necessarily fastest code sequence programmer communicate value use parameter statement tran use parameter statement compiler know value constant runtime example seen idim enddo enddo looking code s clear idim depending data set use clearly compiler knew idim generate simpler faster code dead code removalprograms contain section dead code ef fect answer removed occasionally dead code written program author common source compiler optimization produce dead code need swept dead code come type instruction unreachable instruction produce result used easily write unreachable code program directing flow control permanently compiler tell s unreachable eliminate example s impossible reach statement program program main write stop write end compiler throw stop statement probably give warning unreachable code produced compiler optimization quietly whisked away computation local variable produce result used analyzing variable s definition us compiler routine reference course compiler t tell ultimate fate variable passed routine external common computation kept long reachable footnote following program computation involving kcontribute final answer good candidate dead code elimination compiler doe suf ficient interprocedural analysis optimize variable routine boundary interprocedural analysis bane benchmark code trying time computation using result computation main int k k k printf dead code elimination produced amazing benchmark result poorly written benchmark link example type code strength reduction operation expression time cost associated s possible replace expensive calculation cheaper w e strength r eduction following code fragment contains expensive operation real x y y x j k exponentiation operation line compiler generally make embedded mathematical subroutine library library routine x converted logarithm multiplied converted overall raising x power expensive taking hundred machine cycle key notice x raised small integer power cheaper alternative express x x pay cost multiplication second statement show integer multiplication variable k adding yield answer take time opportunity compiler strength reduction just couple w e important special case look induction variable simplification example strength reduction replacing multiplication integer power logical shift variable renaming link talked register renaming processor make runtime decision replace reference register register instance eliminate bottleneck register renaming keep instruction recycling register dif ferent purpose having wait previous instruction finished situation occur program variable memory location recycled unrelated purpose example variable x following fragment x y z q r x x x b compiler recognizes variable recycled current us independent substitute new variable tokeep calculation separate y z q r x b variable r enaming important technique clarifies calculation independent increase number thing parallel common subexpr ession elimination subexpressions piece expression instance subexpression c appears place like doe common subexpr ession d c b e b calculate b twice compiler generate temporary variable use b required temp b d c temp e different compiler dif ferent length common subexpressions pair recognized recognize reuse ofintrinsics sin x don t expect compiler far subexpressions like computationally equivalent reassociated form like algebraically order provide predictable result computation tran perform operation order specified user reorder way guarantee exactly result user doesn t care way associate compiler assume user doe care address calculation provide particularly rich opportunity common subexpression elimination y ou don t calculation source code generated compiler instance reference array element j translate intermediate language expression address j used multiple copy address computation common subexpression elimination hopefully discover redundant computation group code motion loop high performance computing program spend majority time compiler look opportunity calculation loop body surrounding code expression don t change loop entered expr essions prime tar get following loop expression n b c d e g k enddo modified expression moved outside temp c d n b temp enddo e g k possible code loop body common subexpression elimination address arithmetic particularly important target invariant code motion slowly changing portion index calculation pushed suburb executed needed induction v ariable simplification loop contain called induction variable value change linear function loop iteration count example k induction variable following loop value tied loop index n k m enddo induction variable simplification replaces calculation variable like k simpler one given starting point expression s derivative arrive k s value nth iteration stepping intervening iteration k m n k k enddo form loop aren t equivalent second won t value k given value t jump middle loop nth iteration k take value kept original expression induction variable simplification probably wouldn t important optimization array address calculation look like calculation k example instance address calculation loop iterating variable look like address performing math unnecessary compiler create new induction variable reference simplify address calculation outside loop address indie loop address address induction variable simplification especially useful processor automatically increment register time used pointer memory reference stepping loop memory reference address arithmetic squeezed single great saving object code generation precompilation lexical analysis parsing optimization technique somewhat portable code generation specific tar processor way phase compiler earn risc system isn t handled hardware addressed software mean processor t resolve resource conflict overuse register pipeline compiler going care allowing compiler care isn t necessarily bad thing s design decision complicated compiler simple fast hardware cost ef fective certain application t wo processor opposite end spectrum mips hp p depends heavily compiler schedule instruction fairly distribute resource second manages thing runtime depend compiler provide balanced instruction mix computer register selection challenge spite number register precious y ou want sure active variable register resident expense machine register renaming link sure compiler doesn t try recycle register quickly processor delay computation wait freed instruction repertoire save compiler having issue example register used array index conditional assignment lieu branch save theprocessor extra calculation make instruction stream compact lastly opportunity increased parallelism programmer generally think serially specifying step logical succession unfortunately serial source code make serial object code compiler hope ef ficiently use parallelism processor able instruction operation issued biggest challenge compiler writer today superscalar long instruction wor d vliw design capable executing instruction clock cycle compiler dig deeper operation execute note chapter basic introduction optimizing compiler operates talk compiler order perform automatic vectorization parallelization data decomposition compiler analyze source code encounter topic discus compiler impact programmer best interact compiler modern risc architecture compiler usually generate better code assembly language programmer instead compensating simplistic compiler adding hand optimization programmer program simple confuse compiler understanding pattern compiler quite capable optimizing focus writing straightforward program portable exer cise pr oblem doe compiler recognize dead code program sure doe compiler warning main int k printf statement exer cise pr oblem compile following code execute various optimization level try guess dif ferent type optimization performed improve performance optimization increased real enddo sin co enddo print exer cise pr oblem following code segment compile various optimization level look generated assembly language code option compiler ef fects optimization level machine language t ime program performance dif ferent optimization level access multiple architecture look code generated using optimization level dif ferent architecture real time enddo time end necessary array common block introduction getting code produce right answer plan use program take minute run execution time isn t going matter way typically people start taking runtime program reason workload increased considering new machine s clear care performance program workload increase t rying cram hour computing time hour day administrative nightmare people considering new machine care runtime new machine presumably faster old time reason people evaluating new machine need basis benchmark people use familiar program benchmark make sense want benchmark representative kind work representative work work benchmarking sound easy provided timing tool know meaning time footnote just want sure tool reporting think getting especially used tool t o illustrate imagine took watch replaced expressed time funny unit overlapping set hand confusing problem reading y ou justifiably nervous conducting af fair watch don t understand time money unix timing tool like watch reporting dif ferent kind time measurement aren t giving conflicting information just present information jam single number trick learning read watch s ofthis chapter w e ll investigate dif ferent type measurement determine program doing plan tune program need timing information time spent single loop subroutine overhead memory problem tuner section chapter discus profile code procedural statement level w e discus profile mean predict approach decide tweak code performance chance success assume program run correctly ridiculous time program s running right doesn t mean doesn t happen depending doing interested knowing time spent overall looking just portion program w e time program talk timing individual loop subroutine timing pr ogram unix time program execution placing time command normally type command line program finish timing summary produced instance program called foo time execution typing time foo using c shell korn shell time shell s command w ith bourne shell time separate command executable case following information appears end run user time time elapsed time timing figure easier understand little background program run switch forth fundamentally different mode user mode kernel mode normal operating state user mode user mode instruction compiler generated behalf executed addition subroutine library call linked program footnote run user mode forever program generally need service require intervention operating kernel kernel service request program event outside program cause switch user mode kernel mode cache miss time buried spent executing mode accounted separately user time figure describes time spent user mode similarly time measure time spent kernel mode far user time go program machine accounted separately won t charged activity somebody s application time accounting work way instance char ged service performed people s behalf addition incorrect char ging occurs program executing moment outside activity cause interrupt unfair consolation fact work way user char ged activity reason taken user time time called cpu time generally user time far greater time y ou expect application occasionally ask service fact disproportionately lar ge time probably indicates trouble instance program repeatedly generating exception condition page fault misaligned memory reference point exception use inordinate time t ime spent doing thing like seeking disk rewinding tape waiting character terminal doesn t cpu time s activity don t require cpu cpu free f execute program piece information corresponding set hand watch elapsed time measure actual wall clock time passed program started program spend time computing elapsed time close cpu time reason elapsed time greater timesharing machine active program footnote uptime command give rough indication activity machine field tell average number process ready run minute respectively application performs lot application requires memory bandwidth available machine program paging swapped people record cpu time use estimate elapsed time using cpu time okay single cpu machine provided seen program run machine quiet noticed number close multiprocessor total cpu time far dif ferent elapsed time doubt wait machine self time program using elapsed time important produce timing result verified using run result used make important purchasing decision running berkeley unix derivative c shell s time command report number useful statistic default form output shown link check csh manual page possibility addition figure cpu elapsed time csh time command produce information cpu utilization page fault swap blocked operation usually disk activity measure physical memory gram occupied ran w e turn percent utilization percent utilization corresponds ratio elapsed time cpu time mentioned number reason cpu utilization wouldn t mighty close y ou hint field problem program sharing machine ran average r eal memory utilizationthe average memory utilization measurement shown link characterize program s resource requirement ran measurement space account average real memory taken program s text segment portion hold machine instruction called shared concurrently running copy program share text segment save memory y ear ago possible text segment consume significant portion memory day memory size starting mb compile pretty huge source program use bit create usage figure big cause concern space requirement usually quite low relative memory available machine csh time function second average memory utilization measurement unshar space describes average real storage dedicated program s data structure ran storage includes saved local variable common fortran static external variable w e stress word real number talk physical memory usage taken time allocated array trillion element virtual space program crawl corner space runtime memory requirement pretty low space measurement doesn t tell unfortunately program s demand memory greediest application requires mb time kb rest time appears need mb average revealing picture program s memory requirement blocked operation figure blocked operation primarily disk usage tape device peripheral used blocked character operation terminal input output appear lar ge number blocked operation explain lower cpu utilization page fault swap unusually high number page fault swap probably indicates choked memory explain longer expected elapsed time program competing space don t forget optimal condition program suf fers number page fault explained link technique minimizing page fault described link timing portion pr ogram benchmarking tuning ef fort measurement taken outside program tell need know trying isolate performance figure individual loop portion code want include timing routine inside basic technique simple record time start doing x x record time completion x subtract start time completion time instance x s primary job calculate particle position divide total time obtain number particle y ou careful call timing routine observer experiment timing routine time presence increase instruction cache miss paging furthermore want x significant time measurement meaningful paying attention time timer call really important clock used timing function limited resolution event occurs fraction second hard measure accuracy getting t ime information section discus method getting various timer value execution program tran program library timing function machine called etime take real array argument fill slot user cpu time cpu time respectively value returned function sum s etime used real tarray etime real start finish start etime tarray finish etime tarray write cpu time finish start vendor supply etime function fact doesn t provide timing routine tran t ry show undefined symbol program linked use following c routine provides functionality etime include define tick float etime part struct float user float part struct tm local time local float float return user couple thing tweak make work linking c routine tran routine computer require add underscore function change entry float part furthermore adjust tick parameter assumed clock resolution second true machine version etime written common number y ou value file named machine determine empirically c routine retrieving wall time using calling gettimeofday shown suitable use c tran program us parameter passing include include include void hpcwall double retval static long zsec static long zusec double esec struct timeval tp struct timezone tzp gettimeofday tp tzp zsec zsec zusec zusec retval zsec zusec void double retval hpcwall retval convention given need cpu wall time ally computing dif ference successive call routine want write routine return elapsed wall cpu time follows subroutine hpctim wtime ctime implicit real wtime ctime wbegin real cbegin cend wbegin wend real etime cscratch hpcwall wend cscratch wtime wend wbegin ctime cend cbegin wbegin wend cbegin cend end using t iming information lot information timing facility unix machine tell long take perform given job hint machine operating ef ficiently problem need factored inadequate memory program running anomaly explained away record time baseline tuning baseline reference tell little tuning improved thing benchmarking use baseline judge overall incremental performance new machine remember watch figure paging cpu utilization dif fer machine machine reason unrelated raw cpu performance y ou want sure getting profiling want overall timing application don t time modify code insert etime call code profile useful handed strange application program told figure work improve performance compiler provide facility automatically insert timing call code entry exit routine compile time program run entry exit time recorded dumped file separate utility summarizes execution pattern produce report show percentage time spent routine library routine profile give sense shape execution profile time spent subroutine subroutine b naturally add routine account overall time spent percentage construct picture profile execution distributed program run representative particular profiling tool histogram link link depict percentage sorted left right vertical column representing dif ferent routine help illustrate dif ferent profile shape sharp profile dominated routine sharp pr ofile say time spent procedure want improve program s performance focus ef fort tuning procedure minor optimization heavily executed line code great ef fect overall runtime given right opportunity flat pr ofile footnote hand tell runtime spread routine ef fort spent optimizing little benefit speeding program course program execution profile fall middle term flat profile little overloaded w e using profile show distribution time program y ou label flat profile used draw distinction graph profile described flat profile routine predominates predict absolute certainty likely profile program general trend instance engineering scientific code built matrix solution exhibit sharp profile runtime dominated work performed handful routine t o tune code need focus ef fort routine make ef ficient involve restructuring loop expose parallelism providing hint compiler rearranging memory reference case challenge tangible problem fix limit tuning routine improve runtime course quoted rule thumb amdahl s law derived remark designer ibm series founder amdahl computer gene amdahl strictly speaking remark performance potential parallel computer people adapted amdahl s law thing purpose go like say program part optimized go infinitely fast t optimized optimizable portion make initial runtime best able cut total runtime half runtime eventually dominated portion t optimized put upper limit expectation tuning given finite return ef fort suggested amdahl s law tuning program sharp profile rewarding program flat profile dif ficult tune code nonnumeric application variety numerical code matrix solution take global tuning approach reduce justifiable degree runtime program flat profile instance optimize instruction cache usage complicated program s equal distribution activity lar ge number routine help reduce subroutine overhead folding callees caller occasionally memory reference problem endemic program fixed look profile unusually lar ge percentage time spent library routine log exp sin function software routine inline y ou able rewrite code eliminate operation important pattern look routine take far longer expect unexpected execution time indicate accessing memory pattern bad performance aspect code optimized properly case profile need profiler subroutine profilers come standard software development environment unix machine w e discus prof gprof addition mention profilers subroutine profilers general overall view time spent y ou probably start prof machine use gprof line profiler need know statement time prof prof common unix profiling tool sense extension compiler linker object library plus extrautilities hard look thing say profile prof work periodically sampling program counter application run t o enable profiling recompile relink using flag example program module need compile link according following code cc cc cc stuff creates stuf f binary ready profiling y ou don t need special run just treat normally entering stuff runtime statistic gathered take little longer usual execute footnote completion new file called directory ran file contains history stuff binary form t look directly use prof utility read create profile stuff default information written screen standard output easily redirect file remember code profiling enabled take longer run y ou recompile relink thing flag finished profiling prof stuff explore prof command work created following ridiculous little application contains main routine subroutine predict time distribution just looking code main int l l l foo bar baz foo int j j bar int baz int k k need compile link loop flag run program run prof utility extract profile follows cc loop prof loop following example show look like column time second cumsecs call column described follows time percentage cpu time consumed routine second cpu time consumed routine cumsecs running total time consumed preceding routine list call number time particular routine called second divided number call giving average length time taken invocation routine routine routine listed y ou entry main routine halfway list depending vendor name routine contain leading trailing underscore routine listed don t recognize contribution c library possibly tran library using tran profiling introduces overhead run show subroutine prof output case entry represents code inserted linker collecting runtime profiling data intention tune loop consider profile like figure fairly good sign lead routine take runtime chance significant impact overall runtime course program trivial loop plenty loop doe gprof just s important know time distributed program run s valuable able tell called list routine imagine instance labeled showed high list prof output y ou say hmmm don t remember calling named exp wonder came tree help subroutine function thought member family tree tree root actually routine precedes main routine coded application call main routine turn call way leaf node tree tree properly known graph footnote relationship routine node graph parent child node separated hop referred ancestor descendant doesn t tree subroutine parent furthermore recursive subroutine call introduce cycle graph child call parent figure graphically depicts kind graph small application main parent ancestor rest routine g parent e routine doesn t appear ancestor descendant problem happen routine compiled profiling enabled aren t invoked subroutine case exception handler unix profiler extract kind information called gprof replicates ability prof plus give graph profile call graph profile handy youare trying figure piece code work unknown routine came looking candidate subroutine inlining use graph profiling need step prof flag substituted flag footnote additionally come time produce actual profile use gprof utility instead dif ference statistic file instead hp machine flag cc cc stuff stuff gprof stuff simple graph output gprof divided section graph profile timing profile index section textually map graph second section list routine percentage time devoted number call similar prof section cross reference locate routine number section especially useful lar ge application routine sorted based time use dif ficult locate particular routine scanning let s invent trivial application illustrate gprof work link show short piece tran code diagram routine connected subroutine b called main turn call following example show section output gprof s graph profile footnote conserving space clipped section relevant discussion included example lot including call setup routine like run gprof tran example parent index time self descendant index child sandwiched set dashed line information describing given routine relationship parent child easy tellwhich routine block represents shifted farther left parent listed child prof underscore tacked label footnote description column follows noticed main routine tran program actual tran main routine s called subroutine provided library link time profiling c code won t index notice routine associated number bracket n locating routine profile example looking block describing wanted know child say scanning left page index time meaning time field little dif ferent case describes percentage time spent routine plus time spent child give quick way determine busiest section graph self listed second self column dif ferent meaning parent routine question child starting middle entry routine self figure show overall time dedicated routine case instance amount second self column entry show time attributed call parent look routine example consumed total time second note parent second time attributable call second child self figure show time spent executing child call routine child consumed time overall time accounted call routine example accumulated second overall look blockdescribing listed child second s total time spent executing behalf descendant self column figure descendant column dif ferent meaning routine parent child routine show number second spent descendant routine s parent descendant figure describes time spent routine traced call parent looking routine total time second second attributable parent child descendant column show child s time attributed call routine child accumulated time overall time displayed time associated call routine call call column show number time routine invoked distribution call associated parent child starting routine figure call column show total number entry routine situation routine called immediately appended showing additional n call recursively parent child figure expressed ratio parent ratio say n time routine called m call came child say n time child called m call came gprof s flat pr ofile mentioned previously gprof produce timing profile called flat profile just confuse thing similar produced field dif ferent prof extra information help explain briefly following example show line gprof flat profile stuff recognize routine original program library function included cumulative self self total time second second call s column mean time field describes runtime routine age overall time taken program expect entry column total nearly cumulative second given routine column called cumulative second tally running sum time taken preceding routine plus time scan number asymptotically approach total runtime program self second routine s individual contribution runtime call number time particular routine second spent inside routine divided number call give average length time taken invocation routine figure presented millisecond total second spent inside routine plus descendant divided number call routine notice number appears accumulating result gpr run possible accumulate statistic multiple run picture program doing variety data set instance say wanted profile application bar different set input data y ou perform run separately saving file combine result single profile end bar bar mv bar mv bar gprof bar example profile run way creates new file renamed make room end gprof combine infor mation data file produce summary profile bar file additionally don t gprof creates file named contains mer ged data original data file format use input mer ged profile form output mer ged profile look exactly individual run couple interesting thing note thing main routine appears invoked time run fact furthermore depending application multiple run tend smooth contour profile exaggerate feature y ou imagine happen single routine consistently called come input data change take increasing importance tuning ef fort w ords accuracy processor running mhz time hz hz sample veritable eternity furthermore experience quantization error sampling frequency fixed true steady second sample t o exaggerated example assume timeline link show alternating call subroutine bar foo tick mark represent sample point profiling quantization error profiling bar foo turn running fact bar take time foo sampling interval closely match frequency subroutine alternate quantizing error sample happen taken foo running profile tell foo took cpu time bar described tried true unix subroutine profilers available year case vendor better tool available asking fee doing tuning ask vendor representative look tool block profilers good reason desire finer level subroutine profiler human trying understand subroutine function used profiler tell line source code actually executed invaluable clue focus tuning ef fort save time profiler save discovering particularly clever optimization make dif ference section code get executed overall strategy subroutine profile direct handful routine account runtime take basic block pr ofiler footnote associated source code line basic block section code entrance exit know time block entered know time statement block executed give profile concept basic block explained link basic block profilers provide compiler information need perform optimization compiler work dark restructure unroll loop tell pay worse misplaced optimization adverse ef fect slowing code result added instruction cache burden wasted test introduced compiler incorrect assumption way branch runtime compiler automatically interpret result basic block profile supply compiler hint mean reduced time little ef fort basic block profilers world closest thing standard tcov shipped sun workstation s standard installed base big workstation silicon graphic dec profiler packaged extension prof called pixie explain briefly run profiler using reasonable set switch y ou consult manual page tcov available sun workstation sp arc machine run sunos give execution statistic number time source statement executed easy use assume illustration source program called following step create basic block profile cc foo foo tcov option tell compiler include necessary support tcov footnote file created process called accumulates history cution frequency program foo old data updated new data time foo run overall picture happens inside foo given variety data set just remember clean old data want start profile go file called sun solaris system option used let s look illustration short c program performs bubble sort integer int n main int j ktemp j n j n ktemp n n n j n j ktemp tcov produce basic block profile contains execution count source line plus summary statistic shown int n main int j ktemp j n j n ktemp n n n j n j ktemp number left tell number time block entered instance routine entered just highest count occurs test n j n tcov show count line place compiler created block pixie pixie little dif ferent tcov reporting number time source line executed pixie report number machineclock cycle devoted executing line theory use calculate time spent statement anomaly like cache miss represented pixie work pixifying executable file compiled linked normal way run pixie foo create new executable called cc foo pixie foo prof foo created file named contains address basic block foo new program run creates file called containing execution count basic block address stored pixie data accumulates run run statistic retrieved using prof special flag pixie s default output come section show cycle routine procedure invocation count cycle basic line listed output section bubble sort procedure file line byte cycle cum main fclose fclose fclose main main entry main routine plus number library routine entry associated line number number machine cycle dedicated executing line program ran instance line took cycle runtime memory addition negative performance impact cache miss virtual memory slow program lar ge fit memory competing lar ge job scarce memory resource unix implementation operating automatically page piece program lar ge available memory swap area program won t tossed completely happens memory get extremely tight program inactive individual page placed swap area later retrieval need aware happening don t know second happening memory access pattern critical reference widely scattered runtime completely dominated disk plan advance make virtual memory work program lar ge physical memory machine technique exactly tuning solution loop nest process blocking memory reference data consumed neighborhood us bigger portion virtual memory page rotating disk make room footnote examine technique blocking link chapter gauging size y pr ogram machine s memory tell running way check ing machine straightforward check compare size program available memory size command size myprogram v unix machine output look like berkeley unix derivative like text data bs hex decimal field memory required different portion program text account machine instruction make program second data includes initialized value gram content data statement common block external character string component bs block started symbol usually lar gest describes uninitialized data area program area common block set block data field total section added byte footnote warning size command won t picture program allocates memory dynamically keep data stack area especially important c program tran program create large array common need know memory unfortunately isn t standard unix command tell sgi machine doe v unix implementation command berkeley derivative type p aux command give listing process running machine process lar gest value mem divide value rss field percentage memory used rough figure memory machine memory instance lar gest process show memory usage resident set size rss kb machine mb memory footnote answer size command show total near memory stand good chance paging run especially doing thing machine time reboot machine tell memory available come checking page fault s performance monitoring tool tell program paging paging ok page fault occur naturally program run careful competing resource user ture won t computer check paging activity berkeley unix derivative use vmstat command commonly people invoke time increment report paging regular interval vmstat command produce output second procs memory page disk fault cpu r b w avm fre pi po fr sr sy c sy id lot valuable information produced purpose important field avm active virtual memory fre free real memory pi po number showing paging activity fre figure drop near zero po field show lot activity s indication memory overworked sysv machine paging activity seen sar command sar command show free memory swap space presently available free memory figure low assume program paging sat apr r freemem freeswap mentioned earlier run job lar ger size memory machine sort advice applied conserving cache activity applies paging activity footnote try minimize stride code t blocking memory reference help lot way getting message memory running csh try typing unlimit message go away mean don t swap space available run job note memory performance monitoring tool check workstation vendor available vmstat sar sophisticated graphical tool help understand program using memory note seen tool timing profiling like covered lot kind profile like able cover cache miss measurement runtime dependency analysis flop measurement profile good looking particular anomaly cache miss pipeline utilization profilers quantity exist machine aren t widely distributed thing mind profile code limited view way program used especially true perform type analysis dif ferent set input data working just profile distorted picture code operates overall imagine following scenario invite ride automobile y ou passenger s seat sketch pad pen record happens y observation include following radio windshield wiper used car move forward direction danger given limited view way car operated want disconnect radio s f knob remove windshield wiper eliminate reverse gear come real surprise person try car rainy day point unless careful gather data kind us really picture program operates single profile fine tuning benchmark miss important detail multipurpose application w orse optimize case cripple far harm good profiling saw chapter pretty mechanical t uning requires insight s fair warn isn t rewarding pour soul clever modification actually increase runtime ar gh went wrong y ou ll need depend profiling tool answer exer cise pr oblem profile following program using gprof way tell time spent routine c recursive call main int c n n c n int n n c n int n c n exer cise pr oblem profile engineering code intensive optimization doe profile change explain change exer cise pr oblem write program determine overhead getrusage etime call consuming processor time making check time alter application performance introduction looked code compiler s point view profile code trouble spot good information dissatisfied code s performance wondering possibility code obtuse compiler optimize properly excess code modularization previous improvement clutter code confuse compiler clutter contributes runtime contributing answer come form thing contribute overhead subroutine call indirect memory reference test loop wordy test type conversion variable preserved unnecessarily thing r estrict compiler flexibility subroutine call indirect memory reference test loop ambiguous pointer s mistake item appear list subroutine call loop bite scratch taking time creating fence place program instruction appear t safely intermixed instruction appear great deal care goal chapter eliminate clutter restructure s left fastest execution w e save specific topic fit especially regarding memory reference later chapter treated subject start ll remind look way improve eye mind open possibility fundamentally better way ef ficient sorting technique random number generator solver dif ferent algorithm buy far speed tuning algorithm scope book discussing help recognize good code help code new algorithm best call typical corporation frightening example overhead say department prepared stack paperwork completed department transfer work sure portion completed t ask material need aren t ready need package material data form char ge number like finally come ficial transfer receiving sent department unpack job repackage send lot time get wasted moving work department course overhead minimal compared useful work won t big deal ef ficient small job stay department true subroutine function call enter exit module relative overhead saving register preparing ar gument list won t significant repeatedly calling small subroutine overhead buoy profile better work stayed calling routine additionally subroutine call inhibit compiler flexibility given right opportunity d like compiler freedom intermix instruction aren t dependent subroutine caller callee opportunity lost compiler t peer subroutine function instruction overlap nicely stay respective side artificial fence help illustrate challenge subroutine boundary present exaggerated example following loop run wide range processor n b c enddo code performs calculation look n madd b c enddo subroutine madd b c b c return end iteration call subroutine small work loop particularly painful example involves point calculation resulting loss parallelism coupled procedure overhead produce code run time slower remember operation pipelined take certain time throughput reach operation clock cycle operation perform subroutine call time spent winding winding pipeline figure prominently subroutine function call complicate compiler s ability efficiently age common external variable delaying possible moment actually storing memory compiler us register hold live value variable make compiler tell subroutine changing variable declared external common s forced store modified external common variable memory callee likewise returned variable reloaded register compiler longer trust old register copy penalty saving andrestoring variable substantial especially using lot unwarranted variable ought local specified external common following code common k k aux enddo example k declared common variable used counter really reason local common block aux force compiler store reload k iteration effect unknown far look preparing case huge main program subroutine function modularity important keeping source code compact understandable frankly need maintainability modularity important need small performance improvement approach streamlining subroutine call don t require scrap modular coding technique macro procedure inlining remember function subroutine doe reasonable work procedure overhead isn t going matter small routine appears leaf node busiest section graph want think inserting appropriate place program macr o macr o little procedure substituted inline compile time unlike subroutine function included link macro replicated place used compiler makesits pas program look pattern match previous macro definition expands inline fact later stage compiler see expanded macro source code macro c tran tran notion macro statement function reviled tran community won t survive longer footnote c program macro created define construct demonstrated statement function eliminated tran define average x y main float q p float average p q printf compilation step c program pas c preprocessor cpp happens automatically invoke compiler cpp expands define statement inline replacing pattern matched macro definition program statement average p q get replaced careful define macro literally replaces pattern located cpp instance macro definition said define multiply b b invoked c multiply resulting expansion probably intended c programmer using macro conscious c header file contain macro definition fact standard c library function really defined macro header file instance function getchar linked build program statement include file getchar replaced macro definition compile time replacing c library function make cpp macro work tran program footnote example tran version c program look like programmer use standard unix preprocessor tran define averag x y c program main real p q data p q averag p q write end little preparation define statement rejected tran compiler program preprocessed cpp replace use averag macro definition make compilation procedure shouldn t burden especially building program control make utility suggest store tran program containing cpp directive distinguish unadorned tran just sure make change file output cpp preprocess tran file hand tran compiler see original code instead macro definition substituted inline typed c program main real p q data p q write end way tran compiler recognize extension making process unnecessary compiler see extension invokes cpp automatically compiles output throw away intermediate file t ry compiling computer work aware macro expansion make source line extend past column probably make tran compiler complain worse pas unnoticed compiler support input line longer character sun compiler option allows extended input line character long procedur e inlining macro definition tend pretty short usually just single statement time slightly longer long bit code benefit copied inline called subroutine function reason doing eliminate procedure overhead expose lelism compiler capable inlining subroutine function definition module natural portable way write modular code suf fering cost subroutine call depending vendor ask compiler procedure inlining specifying routine inlined compiler s command line putting inlining directive source program letting compiler inline automatically directive compile line option standard check compiler documentation unfortunately learn thatthere feature s expensive extra form inlining list automatic available just vendor automatic inlining depends sophisticated compiler view definition module word caution regard procedure inlining y ou easily ingested body parent resulting executable lar ge repeatedly spill instruction cache net performance loss advice use information profilers make intelligent decision inlining trying inline subroutine available small routine called generally best candidate people week make decision t fault computer take ten nanosecond appears heavily traveled section code tired delay basic approach reducing impact branch streamline computational suburb particularly loop link easy way reor ganize conditionals execute quickly w ith loop numerical code usually spend time loop don t want inside loop doesn t especially statement gum work extra instruction force strict order iteration loop course t avoid conditionals people place loop process event handled outside ignored year following code show loop test value close zero parameter small n ab small b b c endif enddo idea multiplier reasonably small reason perform math center loop operation weren t pipelined machine comparison branch cheaper test save time older cisc early risc processor comparison branch probably saving architecture cost lot just perform math skip test eliminating branch eliminates control dependency allows compiler pipeline arithmetic operation course answer change slightly test eliminated question dif ference significant s example branch isn t necessary loop find absolute value element array n enddo perform test machine s quicker perform ab operation element array warning coding c absolute value fabs subroutine particular case better f leaving conditional loop footnote machine representation number start sign bit bit number positive number negative fastest absolute value function merely ands sign bit macro t throw conditional thing minimize negative performance learn recognize conditionals loop restructured conditionals loop fall category loop invariant conditionals loop index dependent conditionals independent loop conditionals dependent loop conditionals reduction conditionals transfer control let s look type turn loop invariant conditionals following loop contains invariant test k n b c endif enddo invariant mean outcome regardless happens variable b c value n won t change outcome test recast loop making test outside replicating loop body twice test true false following example n k b c enddo k enddo endif ef fect runtime dramatic eliminated copy test assured computation middle loop easier compiler pipeline remember helping optimize program loop containing similar conditionals checking debug output printed iteration inside highly optimizable loop w e t fault person realizing slowed theprogram performance wasn t important time programmer just trying code produce good answer later performance mattered cleaning invariant conditionals able speed program factor loop index dependent conditionals loop index dependent conditionals test true certain range loop index variable isn t true false like conditional just looked doe change predictable pattern use advantage following loop index variable n n j j j b j c j endif enddo enddo notice partition iteration distinct set true false y ou advantage predictability test restructure loop loop dif ferent partition n j j b j c enddo n j enddo enddo new version faster possible exception n small value like case created clutter loop probably small impact total runtime won t matter way s coded independent loop conditionals nice optimize loop partitioning conditional doesn t directly depend value index variable index variable involved addressing array doesn t create recognizable pattern advance writing program s loop n n b j j j b j c enddo enddo type conditional iteration independent loop unrolled performed parallel dependent loop conditionalswhen conditional based value change iteration loop compiler choice execute code exactly written instance following loop scalar recursion n x x x b enddo t know way branch iteration current iteration t o recognize dependency try unroll loop slightly hand t start second test finished dependent loop conditional y ou want look type loop eliminate iteration value reduction eye loop performing max min function array reduction called reduces array scalar result previous example reduction way getting little bit ahead talking loop want introduce trick restructuring reduction max min expose parallelism following loop search maximum value z array going element time n z z z written s recursive like loop previous section y ou need result given iteration proceed looking greatest element array element essentially matter looking restructure loop check element time assume n evenly divisible include preconditioning loop z new loop calculates new maximum value iteration maximum compared winner new ficial max s analogous f arrangement tournament old loop like player competing time rest sat new loop run match general particular optimization good code hand parallel processor compiler performs reduction way similar example inadvertently limit compiler s flexibility parallel conditionals t ransfer contr ol let s step second noticed similarity loop far w e looked particular type conditional conditional assignment based outcome test variable get reassigned course conditional end assignment y ou statement transfer flow control subroutine call gotostatements following example programmer carefully checking dividing zero test extremely negative impact performance force iteration precisely order n n b j print j stop endif j j b j enddo enddo avoiding test reason designer ieee point standard added trap feature operation dividing zero trap allow programmer critical section code achieve maximum performance detect error clutter clutter come form consider previous section having dealt lar ge piece junk hall closet ironing board hockey stick pool cue little thing widowed checker tennis ball hat owns w e want mention w e apologize advance changing subject lot s nature cleaning closet data t ype conversion statement contain runtime type conversion suf fer little performance penalty time statement executed statement located portion program lot activity total penalty significant people reason writing application mixed typing matter saving memory space memory bandwidth time past instance calculation took twice long counterpart calculation arranged place single precision performance win footnote time saved performing calculation single precision double precision measured additional overhead caused runtime type conversion following code addition b mixed type nowadays calculation longer precision calculation register register integer numel parameter numel real numel real b numel numel b enddo iteration b promoted double precision addition occur don t promotion source code s take time c programmer beware kernighan ritchie k r c point calculation c program place double precision variable involved declared float possible write application precision suf fer penalty type conversion data mistake use character operation test system character operation poorer performance integer operation procedure call optimizers look code using character variable good candidate optimization example following code chvar y b c endif enddo better written using integer variable indicate computation performed iflag b c endif enddo way write code assuming iflag variable follows b c iflag enddo approach actually perform slower computer system approach using integer variable doing y common subexpr ession elimination far given compiler benefit doubt common subexpr ession elimination ability compiler recognize repeated pattern code replace temporary variable probably work machine simple expression following line code compiler recognize common subexpression c b d e q b temp b c temp d e q temp substituting eliminates arithmetic expression reused time saving significant compiler s ability recognize common subexpressions limited especially multiple component order permuted compiler recognize equivalent footnote important part program consider doing common subexpression elimination complicated expression hand guarantee get compromise beauty somewhat situation worth overflow f error situation equivalent s example function sin called twice ar gument x r sin co b y r sin sin b z r co temp r sin x temp co b y temp sin b z r co replaced call temporary variable w e agree saving eliminating transcendental function won t win nobel prize doe attention important point compiler typically perform common subexpression elimination subroutine function call compiler t sure subroutine doesn t change state ar gument variable t time compiler eliminate common subexpressions containing function call intrinsics tran compiler assume thing effect y ou hand subroutine mean better qualified compiler group common subexpressions involving subroutine function doing y code motion optimization biggest payback loop s program s activity concentrated best way cut runtime unnecessary repeated invariant instruction main flow code suburb loop s called hoisting instruction pulled sinking pushed s example n sqrt x x y y enddo temp sqrt x x y y n temp enddo hoisted expensive invariant operation loop assigned result temporary variable notice algebraic simplification exchanged division multiplication inverse multiplication execute quickly compiler smart make transformation assuming instructed compiler legal transformation crawling assembly language t positive course rearrange code hand runtime loop suddenly go know compiler sandbagging want sink operation loop usually s calculation performed iteration result needed t o illustrate s sort loop dif ferent one looking search final character character string p c c new version loop move assignment c iteration admittedly transformation reach compiler saving wouldn t great illustrates notion sinking operation hoisting sinking instruction loop compiler capable doing slightlyrestructure calculation greater benefit handling array element loop s area like trust compiler right thing making repeated use array element loop want char ged just loading memory following loop example reuses x twice n xold x x x xinc enddo reality step retrieving x just additional common pressions address calculation possibly memory load operation y ou operation repeated rewriting loop slightly n x xold temp x temp xinc enddo tran compiler recognize x used twice need loaded compiler aren t smart y ou create temporary scalar variable hold value array element body loop particularly true subroutine call function loop someof variable external common make sure match type temporary variable variable y ou don t want incur type conversion overhead just helping compiler c compiler kind indexed sion greater challenge consider code doinc int xold int x int xinc int n n xold x x x xinc unless compiler definition x xinc xold assume pointer leading storage repeat load store case introducing temporary variable hold value x xinc xold optimization compiler wasn t free make interestingly putting scalar temporary loop useful risc superscalar machine doesn t help code run parallel hardware parallel compiler look opportunity eliminate scalar replace temporary vector run code parallel machine time time want careful introducing scalar temporary variable loop dubious performance gain instance real performance loss note chapter introduced tuning technique eliminating program clutter contributes runtime contributing answer saw example tuning technique asking s left w ell upcoming chapter couple way help compiler parallelism use memory ef fectively possible mean make change beautiful exer cise pr oblem simplify following loop conditional n b enddo exer cise pr oblem time loop computer test run set data s small s greater small split better leave test loop parameter small n ab small b b c endif enddo exer cise pr oblem write simple program call simple subroutine inner loop time program execution tell compiler inline routine test performance finally modify code perform operation body loop time code option ran faster y ou look generated machine code figure nearly high performance application loop majority execution time spent link examined way application developer introduced clutter loop possibly slowing loop chapter focus technique used improve performance clutter loop compiler clever generate faster version loop time rewriting loop help compiler s important remember compiler s performance enhancing modification compiler s clutter make modification performance make sure helping testing performance modification architecture need make sure modification aren t hindering performance reason choose modification wisely original simple version code testing new architecture benefit modification small probably code simple clear form look number dif ferent loop optimization technique including loop unrolling nested loop optimization loop interchange memory reference optimization blocking solution someday possible compiler perform loop optimization automatically typically loop unrolling performed normal compiler optimization optimization triggered using explicit option contemplate making manual change look carefully optimization compiler run test determine compiler optimization good hand counting begin rewrite loop body reor ganize order loop idea body loop doe iteration operation counting process surveying loop understand operation mix y ou need count number load store integer library call iteration loop count operation mix given loop match capability processor course operation counting doesn t guarantee compiler generate ef ficient representation loop footnote generally provides insight loop direct tuning ef fort look assembly language output sure going bit overboard t o assembly language listing machine compile flag use flag bear mind instruction mix balanced machine imbalanced processor market today generally issue combination operation clock cycle address arithmetic embedded instruction reference memory compiler replace complicated loop address calculation simple expression provided pattern address predictable ignore address arithmetic counting operation footnote compiler reduces complexity loop index expression technique called induction variable simplification link let s look loop learn instruction mix n j k j k b j k enddo loop contains addition memory reference load store complicated array index expression probably simplified compiler executed cycle memory operation iteration loop increment index variable test determine loop completed ratio memory reference operation suggests hope peak performance loop unless path memory s bad news good information ratio tell ought consider memory reference optimization loop contains addition memory operation load store operand b j value need loaded entry loop n b j enddo throughput limited severely previous loop ratio memory reference operation example show loop better prospect performs wise multiplication vector complex number assigns result memory operation load store operation addition multiplication n xr xr yr xi yi xi xr yi xi yr appears loop roughly balanced processor perform number memory operation operation cycle processor perform multiply add single instruction compiler good recognize appropriate loop limited memory reference iteration compiled multiplication operation counting simple way estimate requirement loop map capability machine loop performance loop dominated memory reference seen example suggests memory reference tuning loop unrolling basic form loop optimization loop unrolling basic today s compiler automatically look like s benefit great deal clutter introduced old deck tran program loop unrolling serf confuse mislead today s compiler suggesting unroll loop hand purpose section twofold familiar loop unrolling recognize code unrolled programmer time ago simplify code second need understand concept loop unrolling look generated machine code recognize unrolled loop primary benefit loop unrolling perform computation iteration end iteration index value incremented tested control branched loop loop iteration process unrolling loop loop execution unrolling reduces overall number branch significantly give processor instruction branch increase size basic block illustration consider following loop single statement wrapped n b c enddo unroll loop giving operation fewer iteration loop overhead y ou imagine help computer computation iteration depend computation iteration calculation fromdifferent iteration executed superscalar processor portion statement actually execute parallel b c b c b c b c enddo loop exactly previous loop loop unrolled time n divisible spare iteration don t executed t o handle extra iteration add little loop soak extra loop called preconditioning loop ii imod ii b c enddo b c b c b c b c enddo number iteration needed preconditioning loop total iteration count modulo unrolling runtime n turn divisible spare iteration preconditioning loop isn t execution architecture reduce eliminate need unrolling loop operate value retrieved main memory load operation long time relative computation loop naturally unrolled processor waiting load finish speculatively execute iteration loop ahead load ef fectively unrolling loop instruction reorder buf candidate loop unrolling level assuming lar ge value n previous loop ideal candidate loop unrolling iteration executed order loop innards small suspect isn t case kind loop t unrolled easily additionally way loop used program run disqualify loop unrolling look promising section going discus category loop generally prime candidate unrolling idea w e talked previous chapter relevant loop low t rip count ef fective loop unrolling requires fairly lar ge number iteration original loop t o understand picture happens total iteration count low w ith trip count low preconditioning loop doing proportionately lar ge work s supposed way preconditioning loop supposed catch leftover iteration missed unrolled main loop trip count low make pass unrolled loop plus pass preconditioning loop word clutter loop shouldn t unrolled place probably time make sense unroll loop low trip count number iteration constant known compile time instance suppose following loop parameter niter niter b c enddo niter hardwired safely unroll depth worrying preconditioning loop fact throw loop structure altogether leave just unrolled loop innards parameter niter b c b c c course loop s trip count low probably won t contribute significantly overall runtime unless loop center lar ger loop want unroll completely leave fat loop loop unrolling help performance fattens loop calculation iteration token particular loop fat unrolling isn t going help loop overhead spread fair number instruction fact unrolling fat loop slow program increase size text segment placing added burden memory ll explain greater shortly good rule thumb look performance loop innards exceed statement loop containing pr ocedur e call fat loop loop containing subroutine function call generally aren t good candidate unrolling reason contain fair number instruction subroutine called fat make loop call fat size theloop apparent look loop function conceal instruction second calling routine subroutine compiled separately s impossible compiler intermix instruction loop unrolled series function call behaves like original loop unrolling function overhead expensive register saved argument list prepared time spent calling returning subroutine greater loop overhead unrolling amortize cost loop structure call doesn t buy worth ef fort general rule dealing procedure try eliminate remove clutter phase check unrolling give additional performance improvement loop branch link showed eliminate certain type branch course couldn t rid case branch benefit loop unrolling test operation counted determine value loop unrolling doubly nested loop inner loop test value b j n n b j j j b j c enddo enddo iteration independent unrolling won t problem w e ll just leave outer loop undisturbed ii imod n ii b j j j b j c enddo b j j j b j c b b c b b c b b c enddo enddo approach work particularly processor using support conditional execution described earlier conditional execution replace branch operation single conditionally executed assignment superscalar processor conditional execution unrolled loop executes quite nicely loop embed loop loop create loop nest loop loop center called inner loop surrounding loop called outer loop depending construction loop nest flexibility ordering loop time swap outer inner loop great benefit section look common loop nestings optimization performed loop nest working nest loop working multidimensional array computing multidimensional array lead memory access optimization perform loop nest meant improve memory access pattern examine optimization followed memory optimization outer loop unr olling faced loop nest simple approach unroll inner loop unrolling innermost loop nest isn t dif ferent saw y ou just pretend rest loop nest doesn t exist approach mal way time want apply loop unrolling just inner loop outer loop outer loop s typical loop nest n j n k n j k j k b j k c unroll outer loop pick outer loop index variable replicate innermost loop body iteration performed time just like saw link dif ference index variable unroll code unrolled middle j loop twice n j n k n j k j k b k j c k k b k c left k loop untouched unroll outer inner loop unrolling time n j n k n j k j k b k j c k k b k c j j b j c b c unroll loop leaving copy loop innards notice completely ignored preconditioning real application course couldn outer loop unr olling expose computation say doubly nested loop inner loop trip count low average inner loop unrolling doesn t make sense case won t iteration justify cost preconditioning loop able unroll outer loop consider loop assuming m small n lar ge n m j b j c j d enddo enddo unrolling loop give lot operation overlapped ii imod ii m j b j c j d enddo enddo m j b j c j d j b j c j d j b j c j d j b j c j d enddo enddo particular case bad news good news unrolling outer loop cause strided memory reference b probably won t problem inner loop trip count small naturally group reference conserve cache entry outer loop unrolling helpful nest recursion inner loop outer loop example order linear recursion inner loop m n j j j b enddo enddo recursion t unroll inner loop work copy outer loop time unrolled look like jj imod jj n j j j b enddo enddo n j j j b b b b enddo enddo recursion exists loop succeeded finding lot work reason unrolling outer loop hold larger chunk thing parallel outer loop iteration independent inner loop trip count high outer loop iteration represents significant parallel chunk work single cpu doesn t matter tightly coupled multiprocessor translate tremendous increase interchange loop interchange technique rearranging loop nest right stuff center right stuf f depends trying accomplish situation loop interchange let swap high trip count loop low trip count loop activity get pulled center loop nest footnote s good improving memory access pattern loop inter change computation center writes program represents kind model structure code term model make perfect sense computer analysis tool aren t writing code computer s behalf model expressed naturally work point space time tends insignificant inner loop term trip count performance want interchange inner outer loop pull activity center unrolling let s illustrate example s loop kdim quantity point mesh updated parameter idim jdim kdim idim jdim kdim d k j d k j v k j dt enddo enddo enddo practice kdim probably equal j representing number point thousand way written inner loop low trip count making poor candidate unrolling interchanging loop update quantity time point tuning purpose move lar ger trip count inner loop allows strategic unrolling kdim jdim idim d k j d k j v k j dt enddo enddo enddo example straightforward s easy inter iteration dependency tell general loop inter changed interchanging loop violate dependency worse violate occasionally meaning catch optimizing interchange loop n j b j c j b j enddo enddo possible examine loop hand determine dependency better compiler make compiler automatically perform loop interchange compiler vector parallel computer generally interchange loop benefit interchanging loop won t alter program result footnote compiler performs automatic parallel optimization prefers run outermost loop parallel minimize overhead unroll innermost loop make best use superscalar vector processor reason compiler need flexibility ordering loop loop access pattern best pattern straightforward increasing unit sequential array single dimension stepping element time accomplish array access fastest iterate array subscript fering smallest stride step size tran program leftmost subscript c rightmost tran loop unit stride run quickly n n j b j c j d enddo enddo contrast loop slower stride n assume greater n increase length cache line adjusting length element performance worsens n longer length cache line adjusted element size performance won t decrease n n j b j c j d enddo enddo s loop like previous written c n j n j j c j d unit stride give best performance conserve cache entry recall data cache work footnote program make memory reference data cache get returned immediately program suf fers cache miss new cache line fetched main memory replacing old line hold value taken handful neighboring memory location including caused cache miss loaded cache line took piece data threw rest away wasting lot time memory bandwidth brought line cache consumed benefit lar ge number memory reference small number cache miss exactly program make memory reference link pattern jump memory especially large memory particularly apparent rhyme reason viewed outside job operate large data structure pay penalty cache miss tlb miss footnote nice able rein job make better use memory course t eliminate memory reference program data way question restructure memory access pattern best performance t ranslation lookaside buf fer tlb cache translation virtual memory address physical memory address information refer link section going look trick restructuring loop strided albeit predictable access pattern trick familiar loop optimization link used dif ferent reason underlying goal minimize cache andtlb miss possible y ou quite lot going ugly loop inter change ease memory access pattern loop interchange good technique lessening impact strided memory reference let s revisit tran loop stride good news easily interchange loop iteration independent n n j b j c j d enddo enddo interchange b c referenced leftmost subscript varying quickly modification make important dif ference performance w e traded memory reference unit stride n n j b j c j d enddo enddo matrix multiplication matrix multiplication common operation use explore option available optimizing loop nest programmer hasjust finished reading linear algebra textbook probably write matrix multiply appears example n n sum n sum sum k b k j enddo c j sum enddo enddo problem loop k stride iteration inner loop consists load stride multiplication addition given nature matrix multiplication appear t eliminate stride simple rewrite loop memory access unit stride n n c j enddo enddo n n scale b k j n c j c j k scale enddo enddo enddo inner loop access memory using unit stride iteration performs load store multiplication addition comparing previous loop stride load eliminated additional store operation assuming operating matrix lar ger cache extra store won t add execution time store location c j used load case store line cache b k j constant scaling factor inner interchange w o w ork matrix multiplication code encountered stride able eliminate quick interchange loop unfortunately life rarely simple mix variable unit stride case interchanging loop move damage doesn t make away loop perform matrix transpose represents simple example dilemma n m m n j b j j b j enddo enddo enddo enddo whichever way interchange break memory access pattern interesting make choice strided load strided store footnote really need general method improving memory access pattern botha b ll method link t tell better way cast depends brand computer perform better loop left factor perform better interchanged dif ference way processor handle update main memory ease memory access pattern blocking kind memory reference optimization loop interchange challenge retrieve data possible cache miss possible w e d like rearrange loop nest work data little neighborhood striding memory like man stilt given following vector sum rearrange loop n n j j b j enddo enddo loop involves vector referenced unit stride stride w e interchange loop way array reference b undesirable trick block reference grab element b neighborhood w e make happen combining inner outer loop unrolling j j b j b j j b j b enddo enddo use imagination help usually think array think rectangle square link remember make programming easier compiler provides illusion array b rectangular plot memory link actually memory sequential storage tran array constructed memory logically lining memory strip like picket cedar fence s way c row stacked array storage start upper left proceeds start column stepping array unit stride trace shape backwards n repeated moving right array b array element stored imagine horizontal line link cut memory storage piece size individual cache entry picture loop traverse index expression reference backwards n shape consuming bit cache line reference b dash f right using piece cache entry discarding rest link low usage cache entry result high number cache miss rearrange loop consumed array small rectangle strip conserve cache entry discarded exactly accomplished unrolling inner outer loop following example array referenced strip b referenced strip left right link improves cache performance lower runtime really big problem cache entry stake virtual memory machine memory reference translated tlb dealing lar ge array tlb miss addition cache miss going add runtime square s surprise code rewrite loop time blocking reference dif ferent level square save cache entry cutting original loop part save tlb entry j j b j b j j j b j b enddo enddo j j b j b j j j b j b enddo enddo guess adding loop wrong thing work reasonably lar ge value n say significant increase performance array b kb byte mb n equal lar ger handled tlbs cache processor box link illustrate reference b look superimposed blocked unblocked case unblocked reference b zing f memory eating cache tlb entry blocked reference sparing memory picture unblocked versus blocked reference blocking lar ger problem code show method limit size inner loop visit repeatedly ii mod jj mod n jj j j b j enddo enddo ii n j j b j j j enddo enddo j k j k b k j k k b k k k b k k k b k enddo enddo enddo inner loop used execute n iteration time new k loop executes iteration divide conquers lar ge memory address space cutting little blocking technique begin diminishing return system lar ge multiprocessor system nonuniform memory access numa significant benefit carefully arranging memory access maximize reuse cache line main memory page combined unrolling blocking technique just showed loop mixed stride expression work loop nest like looking array reference strided way want try loop unrolling loop interchange require memory y ou people occasionally program memory size requirement great data t fit memory time data reside outside main memory secondary usually disk storage core solution fall category solution virtual solution approach programmer recognized problem big modified source code section data disk retrieval later time method depends computer s memory handling secondary storage requirement time great cost runtime softwar e solution code solution adjustment tell program memory work take care rest important make sure adjustment set correctly code tuned machine limited memory ported taking account storage available problem fit easily writing solution trick group memory reference localized usually occurs naturally ef fect partitioning say matrix factorization group column blocking reference way did previous section corral memory reference treat memory knowing ship f disk entail closely involved program note loop heart nearly high performance program goal loop express simply clearly possible eliminates clutter use profiling timing tool figure routine loop taking time loop using time try determine performance loop improved try simple modification loop don t reduce clarity code y ou experiment compiler option control loop optimization ve exhausted option keeping code looking clean need performance resort modifying code t ypically loop need little loop making bad use memory architecture based hopefully loop end changing overall loop program going far optimizing single processor machine look program executes parallel modification improve performance confuses compiler compiler parallel vector system generally powerful optimization capability identify area code execute specialized hardware compiler interchanging unrolling loop automatically time exer cise pr oblem unrolling iteration generally sufficient simple vector loop risc processor relationship doe unrolling pipeline depth exer cise pr oblem processor execute multiply memory reference cycle s best performance expect following loop b c d e enddo exer cise pr oblem try unrolling interchanging blocking loop subroutine bazfaz increase performance method combination method work best look assembly language created compiler approach highest level optimization note compile main routine bazfaz separately adjust ntimes untuned run take minute use thecompiler s default optimization level program main implicit integer m n j parameter n m ntimes double precision q n m r m n c m n q j r j enddo enddo c ntimes bazfaz q r n m enddo end subroutine bazfaz q r n m implicit integer m n j double precision q n m r n m c n m r j q j r j enddo enddo c end exer cise pr oblem code matrix multiplication algorithm straightforward manner compile various optimization level compiler performs type loop interchange try experiment following code n n j j enddo enddo dif ference compiler s ability optimize loop dif ference explain exer cise pr oblem code matrix multiplication algorithm way shown chapter execute program range value graph execution time divided value n ranging explain performance sense talking parallelism beginning book instead calling parallelism using word like pipelined superscalar compiler flexibility programming multiprocessor increase understanding parallelism order understand ef fectively program system short gain parallel resource need parallelism code talk parallelism need understand concept granularity granularity parallelism indicates size computation performed time synchronization example parallelism order increasing grain size performing integer addition using carry lookahead adder partially add bit time bit pipelined processor decoding instruction fetch instruction superscalar processor execute combination integer instruction single cycle multiprocessor divide iteration loop processor split lar ge array workstation attached network workstation operate local information exchange boundary value end time step chapter start parallelism pipelined superscalar parallelism need multiprocessor system important note dif ferent level parallelism generally conflict increasing thread parallelism coarser grain size expose parallelism following loop plenty parallelism b enddo expressed loop way imply computed followed loop completed mattered computed followed loop computed value computed odd value make difference iteration computed simultaneously using superscalar processor footnote compiler flexibility order execute instruction make program execute instruction simultaneously parallel hardware available interestingly far single instruction multiple data simd computer connection processor instruction cycle process entire loop technique computer scientist use formally analyze potential parallelism algorithm characterize quickly execute superscalar processor loop contain parallelism simple loop w e need identify thing limit parallelism code remove possible previous chapter looked removing clutter rewriting loop simplify body loop chapter supplement link way w e looked mechanic compiling code apply didn t answer basic block analysis technique form basis work compiler doe looking parallelism looking piece data instruction data instruction modern compiler asks question thing depend possible answer yes don t know answer iseffectively yes compiler conservative unsure safe tweak ordering instruction helping compiler recognize parallelism basic approach specialist tuning code slight rewording loop supplementary information supplied compiler change don t know answer opportunity parallelism t o certain facet tuning optimizing memory access pattern best suit hardware recasting algorithm single best approach problem tuning ef fort combination imagine symphony orchestra musician play regard conductor musician tap conductor s baton musician go sheet music finish far ahead leave stage home cacophony wouldn t resemble music come think resemble experimental jazz totally uncoordinated course isn t music played computer program like musical piece woven fabric unfolds time woven loosely certain thing happen rate process computer program event occur event b say b dependent w e relationship dependency dependency exist calculation memory operation data dependency time waiting branch exit place called contr ol dependency present program varying degree goal eliminate dependency possible rearranging program chunk computation dependent expose parallelism opportunity thing contr ol dependency just variable assignment depend assignment variable s value depend flow contr ol program instance assignment occur conditional evaluates true said assignment loop loop entered statement inside loop executed calculation occur consequence flow control say contr ol dependency code shown graphically link assignment located inside executed depending outcome test x word value y depends flow control code sound like concern compiler designer notprogrammers s true time want instruction expensive calculation way provided compiler isn t smart example say link represents little section program flow control enters go branch decision furthermore say square root operation entry point flow control go leg containing statement mean result calculation b discarded get new value time square root operation expensive take lot time execute trouble t just rid occasionally s needed way continue observe control dependency making copy square root operation traveled branch shown link way sqrt execute path actually needed control dependency little section program kind instruction scheduling appearing compiler hardware time go variation technique calculate result needed time gap instruction stream dependency using spare cycle wasted expensive operation moved s rarely executed data dependency calculation way bound previous calculation said data dependent calculation code value b data dependent value s t calculate b value available x y co z b c dependency easy recognize simple time careful rewrite variable new value computation finished using old value w e group data dependency category flow dependency antidependencies output dependency link contains simple example demonstrate type dependency example use arrow start source dependency end statement delayed dependency key problem dependency second statement t execute completed obviously particular output dependency example computation dead code eliminated unless intervening code need value technique eliminate output antidependencies following example contains flow dependency followed output dependency type data dependency x b y x x d e t eliminate flow dependency output dependency eliminated using scratch variable xtemp y xtemp x d e number statement interaction statement increase need better way identify process dependency link show statement dependency multiple dependency second fourth instruction started instruction completes forming dag method analyzing sequence instruction ganize directed acyclic graph dag footnote like instruction represents dag describes calculation relationship variable data flow dag proceeds direction dag constructed identifier constant placed leaf node one operation possibly variable name attached make internal node v ariables appear final state dag s edge order relationship variable operation data flow proceeds graph collection node connected edge directed mean edge traversed specified direction word acyclic mean cycle graph t loop construct dag compiler take intermediate language tuple map node instance tuples represent binary operation addition form portion dag input b bound operation result operation feed operation basic block dag shown link trivial data flow graph basic block code build dag order instruction dag previous instruction shown link particular example dependency opportunity parallelism link show straightforward example show constructing dag identify parallelism dag determine instruction executed parallel computation operate value b processing instruction eliminate common subexpression construction dag determine z variable used outside small block code assume y computation dead code complex data flow graph constructing dag sequence instruction determine executed particular order executed parallel type data flow analysis important codegeneration phase super processor w e introduced concept dependency use data flow opportunity parallelism code sequence basic block w e use data flow analysis identify dependency opportunity parallelism dead code basic block us definition dag constructed compiler make list variable us definition information apply global optimization basic block taken looking dag link variable defined z y x c d variable used considering basic block say far particular variable definition reach value seen recognize situation calculation discarded us given variable completely independent overwrite register value saving memory investigation data flow analysis extracting parallelism dag illustrate suppose flow graph link basic block ve listed variable us variable defines data flow analysis tell notice value defined block x used block mean dead exit block y immediately taking branch leaving x basic block us value tell associated resource register freed us looking link d defined basic block x used mean calculation defining d discarded interesting happening variable block x w use look closely ll us distinct meaning treated independent variable compiler featuring advanced instruction scheduling technique notice w block us value e calculation defining e block y w needed flow graph data flow analysis addition gathering data variable compiler information subexpressions examining recognize case redundant calculation basic block substitute previously computed value place instance expression h appears block x y w calculated just block x propagated use loop center activity application high payback simplifying moving calculation outside computational suburb early compiler parallel architecture used pattern matching identify bound loop limitation meant loop using correctly identified loop modern compiler use data flow graph s practical identify loop particular subset node flow graph t o data flow graph hand constructed loop look compiler loop optimization applied type loop identified loop apply kind flow analysis applied thing looking calculation unchanging loop variable change predictable linear fashion iteration iteration doe compiler identify loop flow graph fundamentally condition met given node dominate node suspected loop mean path node loop pas particular node dominator dominator node form header loop cycle graph given dominator path node dominates loop path known edge loop flow graph link contains loop red herring y ou node b dominates node subset flow graph satisfies condition make candidate loop header path e b b dominates e make edge satisfying condition node b c d e form loop loop go array linked list start pointer traverse list determine total number node list letter extreme right correspond basic block number flow graph flowgraph loop itat glance appears node c d form loop problem c doesn t dominate d vice versa entry b condition isn t satisfied generally flow graph come code segment written weakest appreciation structured design fer better loop candidate identifying loop compiler concentrate portion flow graph looking instruction remove push outside certain type subexpressions array index expression simplified change predictable fashion iteration continuing quest parallelism loop generally best source lar ge amount parallelism loop provide new opportunity dependency dependency notion data dependence particularly important look loop hub activity inside numerical application loop produce million operation performed parallel single misplaced dependency loop force run serial stake higher looking dependency loop construct completely independent right box question want ask dif ferent iteration execute time data dependency consider following loop n b enddo value k calculate value k time manually unrolled iteration previous loop executed b b b result used operand calculation instance calculation occur time calculation calculation independent don t need result determine second fact mixing order calculation won t change result serial order imposed calculation make possible execute loop quickly parallel hardware flow dependency comparison look code fragment n b enddo loop regularity previous example subscript changed s useful manually unroll loop look iteration b b b case dependency problem value depends value value depends iteration depends result previous dependency extend previous calculation previous iteration like loop carried flow dependency backwar d dependency dependency application perform gaussian elimination certain type matrix numerical solution system dif ferential equation impossible run loop parallel written processor wait intermediate result case flow dependency impossible fix calculation dependent choice wait previous one complete time dependency function way calculation expressed instance loop changed reduce dependency replicating arithmetic make second iteration depend operation count go extra addition didn t reduced dependency iteration b b b enddo speed increase workstation won t great machine run recast loop slowly parallel computer trade f additional calculation reduced dependency chalk net win antidependencies s dif ferent story antidependency code n b e b c enddo loop antidependency variable variable sure instruction usesa doe previous redefines clearly problem loop executed serially remember looking opportunity overlap instruction help pull loop apart look iteration recast loop making copy statement followed copy second b e b e b e b c assignment make use new b c value incorrect b c reference need access old value new one calculated perform statement followed second statement answer wrong perform second statement followed statement answer wrong sense run iteration parallel save value use second statement store b value temporary area loop completes directly unroll loop parallelism b e b c b e output dependency b c b e b c statement executed simultaneously statement completed execution statement execute parallel using approach suf ficient intervening statement dependent statement parallel performance improvement superscalar risc processor output dependency class data dependency output dependency particular user parallel computer particularly multiprocessor output dependency involve getting right value right variable calculation completed output dependency violated loop assigns new value element vector iteration n c d e enddo won t problem execute code sequentially iteration performed statement reordered incorrect value assigned element example naive vectorized equivalent take wrong value assignment occur order c c c d e output dependency violated d e d e worry output dependency depends actually parallelizing code y compiler conscious danger able generate legal code possibly fast code s clever output dependency occasionally problem programmer dependency w ithin iteration looked dependency cross iteration boundary haven t looked dependency iteration consider following code fragment n d b d enddo look loop variable d flow dependency second statement start statement completed glance appear limit parallelism significantly look closer manually unroll iteration loop situation get worse d b d d b d d b d variable d flow output antidependencies look like loop hope running parallel simple solution problem cost extra memory space using technique called promoting scalar vector define d array withn element rewrite code follows n d b d enddo iteration independent run parallel w ithin iteration statement run second statement reduction sum array number example reduction called reduces vector scalar following loop determine total value array certainly look able run parallel sum n sum sum enddo perform unrolling trick doesn t look parallel sum sum sum sum sum sum loop type dependency look impossible parallelize willing accept potential ef fect rounding add parallelism loop follows did add preconditioning loop enddo sum precisely computation partial sum computed independently partial sum combined end loop loop look maximum minimum element array multiply element array reduction likewise reor ganized partial result sum expose computation note maximum minimum associativeoperators result reor ganized loop identical sequential reference dependency looked far clear cut exactly dealing looking source code time describing dependency isn t easy recall loop antidependencies section link earlier chapter n b e b c enddo variable reference solely function index s clear kind dependency dealing furthermore far apart iteration variable reference definition called dependency distance negative value represents flow dependency positive value mean antidependency value zero say dependency exists reference definition loop dependency distance iteration array subscript function variable loop index dif ficult tell distance use definition particular element impossible tell dependency flow dependency antidependency dependency exists consequently impossible determine s safe overlap execution dif ferent statement following loop n b e b c k unknown enddo loop use value k unknown wouldn t able tell looking code kind dependency facing k zero dependency iteration dependency k positive antidependency distance depending value k parallelism superscalar processor k negative flow dependency execute loop serially ambiguous r eferences like ef fect parallelism detect loop compiler perspective loop doe contain independent calculation author whimsically decided throw single loop appear compiler treat conservatively interrelated big ef fect performance compiler assume consecutive memory reference ultimately access location instruction involved overlapped option compiler generate version loop check value k runtime determine version loop execute similar situation occurs use integer index array loop loop contains single statement t sure iteration independent knowing content k j array n k k b j c enddo instance value k cause element array rereferenced iteration ridiculous compiler t code like s common value k unique called permutation tell compiler dealing permutation penalty lessened case insult added injury indirect reference require memory activity direct reference slows pointer ambiguity numerical c application tran compiler depend programmer observe aliasing rule programmer supposed modify location pointer alias alias way dummy ar guments receive pointer storage location bob end subroutine bob x y x y alias c compiler don t enjoy restriction aliasing fact case aliasing desirable additionally c blessed pointer type increasing opportunity aliasing occur mean c compiler approach operation pointer conservatively tran compiler let s look example following loop nest look like tran loop cast array declared allocated routine starting address leading dimension visible compiler important mean storage relationship array element known expect good performance define n double n n c n n d n j n j j c j d imagine happens allocate row dynamically make address calculation complicated loop nest hasn t changed guaranteed stride row storage relationship row unknown define n double n c n d n double malloc n sizeof double c double malloc n sizeof double n j n j j c j d fact compiler know expect storage relationship instance sure reference c aren t alias obvious y ou point malloc overlap storage compiler isn t free assume know y ou substituting version malloc let s look dif ferent example storage allocated declaration visible routine using following subroutine bob performs computation previousexample compiler t declaration c main routine doesn t information able overlap memory reference successive iteration reference alias define n main double n n c n n d bob c d n bob double double c double d int n int j double ap cp n ap n cp c j n j n d best performance make available compiler detail size shape data structure possible pointer form formal ar guments subroutine explicitly declared hide important fact using memory information compiler overlap memory reference information come compiler directive making declaration visible routine performance note knew limit parallelism given program know clearly program dependency execute thing given suitable hardware program aren t infinitely parallel hardly parallel contain dependency type saw writing tuning loop number conflicting goal mind balance memory operation computation minimize unnecessary operation access memory using unit stride possible allow loop iteration computed parallel coming chapter begin learn executing program parallel multiprocessor point escape bond compiler automatic optimization begin explicitly code parallel portion code learn compiler dataflow read art compiler design theory practice thomas pittman james peter exer cise pr oblem identify dependency following loop think way ganize loop parallelism enddo enddo n b enddo n n m enddo n j k b enddo j k b enddo n b exer cise pr oblem imagine parallelizing compiler trying generate code loop reference challenge help know k equal zero explain partially vectorize statement involving knew k absolute value n e m e b c d enddo exer cise pr oblem following statement contain flow dependency antidependency output dependency identify given allowed reorder statement permutation produce value variable c b reduce dependency combining rearranging calculation using temporary variable b c b c d c b d introduction multiprocessor pretty expensive pretty rare hardware cost dropping commonplace home computer system range socket second cpu home computer operating system providing capability use processor improve performance specialized resource locked away central computing facility processor viewed logical extension desktop system run operating unix nt desktop application workstation execute multiprocessor server typically workstation processor server processor multiprocessor significant advantage multiprocessor processor share view memory shown link processor described uniform memory access known uma system designation indicates memory equally accessible processor performance popularity system simply demand high performance computing system excellent providing high throughput multiprocessing load function ef fectively performance database server network server internet server w ithin limit throughput increased linearly processor added book interested performance database internet server pass buy processor better throughput w e interested pure raw unadulterated compute speed high performance application instead running hundred small job want utilize worth hardware single job challenge technique make program take hour complete using processor complete minute using processor trivial book far onan endless quest parallelism remaining chapter begin payof f hard work dedication cost multiprocessor range million example system include intel system wide range vendor sgi power challenge series series dec alphaservers cray processor sun enterprise system sgi origin exemplar data general sequent symmetric multiprocessing system linked form lar ger shared nonuniform system system price increase number cpu increase performance individual cpu increase memory performance increase chapter study hardware software environment system learn execute program multiprocessing hardware link viewed ideal multiprocessor section look actually constructed primary advantage system ability cpu access memory peripheral furthermore system need facility deciding access mean hardware support arbitration common architectural underpinnings symmetric multiprocessing bus crossbar bus simplest approach link show processor connected using bus bus thought set parallel wire connecting component computer cpu memory peripheral controller set protocol communication hardware help carry bus expensive build traf fic cross bus load increase bus eventually performance bottleneck multiprocessor typical bus architecture crossbar hardware approach eliminate bottleneck caused single bus crossbar like bus running attachment module machine cpu memory peripheral module path crossbar multiple path active simultaneously crossbar link instance active data transfer progress time diagram look like patchwork wire actually quite bit hardware go constructing crossbar doe crossbar connect party wish communicate actively arbitrate cpu want access memory peripheral event module popular s crossbar decides get access doesn crossbar best performance single shared bus expensive build cost increase number port increased cost crossbar typically high end price performance spectrum us bus crossbar memory bandwidth processor drawing memory quickly saturate available bandwidth technique improve memory performance described link apply design memory subsystem attached bus crossbar crossbar effect cache common multiprocessing commodity processor connected memory peripheral bus interestingly fact processor make use cache somewhat mitigates bandwidth bottleneck architecture connecting processor cache viewing main memory cache significantly reduce memory traf fic bus architecture memory access bus form cache line load flush t o understand consider happens cache hit rate high link high cache hit rate eliminates traf fic gone bus crossbar main memory notion locality reference make work assume fair number memory reference hit cache equivalent attainable main memory bandwidth bus actually capable assumption explains multiprocessor designed bus bandwidth sum cpu consume imagine scenario cpu accessing dif ferent area memory using unit stride cpu access element cache line time bus arbitrarily allows cpu access memory cpu fill cache line begin process data instant cpu completed cache line cache line second cpu begin second cache line completed second cpu begin process data cache line time process data cache line longer time cache line cache line processor completes cache line request arrives processor initial conflict resolved processor appear access memory remainder loop high cache hit rate reduces main memory traf fic actuality fastest system memory bus sufficiently fast processor access memory using unit stride little conflict processor accessing memory using stride bus memory bank conflict apparent fewer processor bus architecture combined local cache popular multiprocessing load memory reference pattern database internet server generally consist combination time period small working set time period access lar ge data structure using unit stride scientific code tend perform stride access code reason expensive system tar geted scientific code tend use crossbar connected multibanked memory system main memory better shielded lar ger cache used reason multiprocessor incorporate cache processor us small local cache backed larger second cache mb memory satisfy memory request data written main memory doe request bus crossbar coher ency happens cpu multiprocessor running single program parallel change value variable cpu try read doe value come question interesting multiple copy variable hold old stale value illustration say running program shared variable processor change value processor go read multiple copy variable link processor keeping register variable processor doesn t stand chance getting correct value go look way know content s register assume processor writes new value question doe new value stored doe remain processor s cache written main memory doe updated processor s cache really asking kind cache coher ency pr otocol vendor us assure processor uniform view value memory generally isn t programmer worry case af fect performance approach used system similar used system extension cache coherency approach called ough policy variable written cache simultaneously written main memory update take place cache main memory reference performed cache continuously monitor known snooping traf fic bus checking address cache cache notice contains copy data location written invalidate copy variable obtain new value depending policy thing note cache demand fair main memory bandwidth write go main memory bus furthermore successive writes location bank subject main memory cycle time slow machine sophisticated cache coherency protocol called copyback writeback idea write value main memory cache housing need space update cached data coordinated cache cache help processor copyback caching us hardware monitor snoop respond memory transaction cache benefit method method memory traf fic reduced considerably let s walk work cache line state approach work cache maintain state line cache possible state used example include modified cache line need written memory exclusive cache cache line shar edthere copy line cache cache line doesn t contain useful data particular coherency protocol called mesi cache coherency protocol complicated state idea multiprocessor writeback cache coherency work start particular cache line memory writeback cache system cache ask data particular memory completes normal memory access main memory return data requested location response cache miss associated cache line marked exclusive meaning cache containing copy data owner data cache go main memory looking thing request intercepted cache data returned cache main memory interception occurred data returned data marked shared cache particular line marked shared cache treat differently exclusive owner data especially want modify particular write shared cache entry preceded broadcast message cache tell invalidate copy data remaining cache line get marked modified signal changed returned main memory space needed mechanism maintain cache coherence multiprocessor adding tremendously memory traf fic way variable shared s possible copy cache symmetric multiprocessor program bounce cpu cpu run little cpu little program operated separate cache mean copy seemingly unshared variable scattered machine operating system try minimize process moved physical cpusduring context switch reason overload available processor data placement pitfall regarding shared memory far failed mention involves data movement convenient think multiprocessor memory big pool seen actually carefully crafted cache coherency protocol main memory problem come application cause lot data traded cache reference fall given processor s cache especially require update processor s cache bus s slower memory processor s cache main memory protocol processing overhead involved need program high locality reference unit stride need minimize data moved cpu software concept examined way multiprocessor hardware operates need examine software operates type computer w e wait chapter begin making tran program run parallel use c program examine fundamental multiprocessing multithreading technique used implement multithreading topic cover include operating multiprocessing user space multithreading operating multithreading primarily use reduce walltime application operating multipr ocessing modern operating system support form multiprocessing multiprocessing doesn t require physical cpu simply operating s ability run process operating process fixed time interval interrupt activity example unix use p command process p pid tty time cmd tcsh xterm telnet xbiff pine elm ansys p grep ansys ansys process process identifier pid terminal executing command cpu time command used command pid unique entire unix command executed separate process example process waiting type event taking resource memory process footnote executing using resource running p confirms cpu time increasing ansys process ansys commonly used package vmstat procs memory page disk fault cpu r b w swap free mf pi po fr sr sy c sy id running vmstat command tell thing activity runnable process cpu actually running given instant t o allow job progress operating process assuming equal priority process executes time process executes time looking vmstat output paging activity pi po context switch c overall user time time sy idle time id process execute completely dif ferent program process completely independent cooperate share information using interprocess communication pipe socket various operating area w e generally don t use multiprocessing system technique increase performance multipr ocessing softwar e section explore program access multiprocessing feature footnote example program creates new process using fork function new process child print message change identity using exec loading new program original process parent print message wait child process complete example written c using posix application programming interface example run unix system system including opennt vms int globvar global variable main int pid status retval int stackvar stack variable globvar stackvar printf main calling fork d globvar stackvar pid fork printf main fork returned pid pid printf child d globvar stackvar sleep printf child woke d globvar stackvar globvar stackvar printf child modified d globvar stackvar retval execl char printf child retval printf parent d globvar stackvar globvar stackvar printf parent sleeping d globvar stackvar sleep printf parent woke d globvar stackvar printf parent waiting pid retval wait status status status return code bit printf parent d status retval key understanding code understand fork function operates simple summary fork function called process return twice original process newly created process newly created process identical copy original process variable local global duplicated process access open file original process link show fork operation creates new dif ference process return value fork function new child process process identifier shown p command original parent process program output recs cc fork recs fork main calling fork main fork returned main fork returned parent parent sleeping child child woke child modified thu nov parent woke parent waiting parent recs tracing program set global stack variable call fork fork operating suspends process make exact duplicate process restarts process y ou message statement immediately fork line coming original process second line coming new process execute p command moment time process running called process identifier fork operatesas process start execute begin perform dif ferent action parent child notice globvar stackvar set parent parent sleep second point child begin executing value globvar stackvar unchanged child process process operating completely independent memory space child process sleep second set copy variable child process call execl function overwrite memory space unix date program note execl return date program take resource child process p moment time process process called date command executes output footnote s uncommon human parent process fork create human child process initially identity parent s uncommon child process change overall identity dif ferent parent later point usually human child wait year change occurs unix happens microsecond way unix parent process disappointed child did turn like parent wake brief sleep notice copy global local variable changed action child process parent call wait function determine child exited wait function return child exited status code returned child process case process user space multithr eading thread dif ferent process add thread added existing process starting new process process start single thread execution add remove thread duration program unlike process operate dif ferent memory space thread process share memory space link show creation thread dif fers creation process memory space process shared thread addition global area shared thread thread thread private area local variable s important programmer know working shared variable working local variable attempting speed high performance computing application thread advantage process multiple thread cooperate work shared data structure hasten computation dividing work smaller portion assigning smaller portion separate thread total work completed quickly multiple thread used high performance database internet server improve overall throughput server single thread program waiting network request reading disk satisfy previous request w ith multiple thread onethread waiting network transaction thread waiting disk complete following example simple multithreaded application footnote begin single master thread creates additional thread thread print message access global local variable terminates example us ieee posix standard interface thread library support posix thread example work similar routine thread function basic line thread include include define void testfunc void int globvar global variable int index local based thread index posix thread id main int retval tid globvar printf main globvar index retval tid null testfunc void index printf main creating d d tid retval tid printf main thread thread started globvar printf main waiting join retval null printf main join d retval printf main thread thread completed globvar void testfunc void parm int self int parm assigned thread ordinal self posix thread library thread number printf testfunc d d self globvar globvar printf testfunc d sleeping globvar sleep printf testfunc d d self globvar creating threadthe global shared area case variable declared static area outside main code local variable variable declared routine thread added thread get function stack c automatic variable declared beginning routine allocated stack thread enters function variable separately allocated particular thread s stack variable unlike fork function function creates new thread control returned calling thread parameter function new thread begin execution function testfunc thread finish return function program executed produce following output recs cc recs main main creating main creating main creating main thread thread started main waiting join testfunc testfunc sleeping testfunc testfunc sleeping testfunc testfunc sleeping testfunc testfunc testfunc main join main waiting join main join main waiting join main join main thread thread completed recs thread getting created loop master thread completes loop executes second loop call function function suspends master thread specified thread completes master thread waiting thread complete master thread suspends new thread started thread start executing initially variable globvar set main program self param variable variable thread copy thread setsglobvar go sleep thread begin execute see globvar set thread thread set globvar go sleep activates thread see current value globvar set thread wake sleep notice latest value globvar return testfunc routine ending thread time master thread middle waiting thread complete thread completes return master thread call repeatedly ensure thread completed finally master thread print value globvar contains latest value summarize application executing thread shared global area thread private area dif ferent thread execute dif ferent time easily work shared area limitation user space multithr eading multithreaded application long multiprocessor existed quite practical multiple thread single cpu matter fact previous example run number processor including look closely code performs sleep operation critical point code reason add sleep call slow program actually going sleep call effect thread enters sleep routine cause thread library search runnable thread runnable thread begin executing immediately calling thread called thr ead context switch process actually operating thread shared logical user thread library routine sleep called thread library footnote jump reschedules thread pthreads library support user thread thread shall soon popular early thread package called explore ef fect substituting following spinfunc function replacing testfunc function previous example void spinfunc void parm int int parm printf spinfunc d sleeping d second sleep printf spinfunc d wake d globvar globvar printf spinfunc d spinning d globvar globvar printf spinfunc d d globvar sleep look function thread entering function print message go sleep second function increment globvar initially set main begin continuously checking value globvar time pass second thread finish sleep increment value globvar begin thread reach loop value globvar thread exit loop isn t happens recs recs main main creating main creating main creating main thread thread started main waiting join spinfunc sleeping second spinfunc sleeping second spinfunc sleeping second spinfunc wake spinfunc spinning recs p pid tty time cmd recs p pid tty time cmd recs kill killed recs run program background footnote run fine thread sleep second thread wake start loop waiting globvar incremented thread unfortunately user space thread automatic time sharing cpu loop make second thread scheduled complete sleep t o fix problem need make following change code know hang ignore interrupt globvar sleep sleep footnote thread chance finish sleep call increment globvar variable program terminates properly thread library support routine check runnable thread find runnable thread run thread thread runnable return immediately calling thread routine allows thread cpu ensure thread make progress period code ask question point user space thread high performance database server internet server multiple logical thread overlap network database background computation technique useful thread want perform simultaneous computation t o need thread created managed scheduled operating user library operating multithr eading operating support multiple thread process begin use thread simultaneous computational activity requirement application executed multiprocessor application us operating thread executed single processor machine thread execute fashion load thread get processor good reason thread processor noncompute application s good idea active thread processor application overhead ef fect thread appendix d fortran manages thr eads runtime using posix thread library simple modification request thread created user thread following code show define basic thread include include define void spinfunc void int globvar global variable int index local based thread index posix thread id attr thread attribute default main int retval tid globvar attr initialize attr default attr printf main globvar index retval tid attr spinfunc void index printf main creating d d tid retval tid printf main thread thread started globvar printf main waiting join retval null printf main join d retval printf main thread thread completed globvar code executed master thread modified slightly create attribute data structure set attribute indicate like new thread created scheduled operating w e use attribute information code changed following execution output new program recs main main creating spinfunc sleeping second main creating main thread thread started main waiting join spinfunc sleeping second spinfunc wake spinfunc spinning spinfunc wake spinfunc spinning spinfunc spinfunc main join main waiting join main join main thread thread completed recs program executes properly thread start spinning operating context switching thread thread come sleep increment shared variable final thread increment shared variable thread instantly notice new value cache coherency protocol finish loop fewer cpu thread wait context switch occur notice updated global variable thread multiple processor program realistically break lar ge computation independent thread compute solution quickly course presupposes computation parallel multithreaded program given multithreaded capability multiprocessor convince thread work accomplish overall goal need way coordinate cooperate thread important technique used program running multiple thread including programming synchronization using critical section lock semaphore mutex barrier technique overhead associated overhead necessary parallel make sure sufficient work make benefit parallel operation worth cost pr ogramming approach simplest method coordinating thread earlier example chapter master thread set global data structure task thread perform use function activate proper number thread thread check global data structure using index task thread performs task completes master thread wait point thread completed update global data structure creates new thread step repeated major iteration step duration program t time step loop setup task ith ith perform task return shortcoming approach overhead cost associated creating destroying operating thread potentially short task approach thread created beginning program communicate duration application t o use technique critical section barrier synchr onization synchronization needed particular operation shared variable performed processor time example previous spinfunc example consider line assembly language take instruction load globvar add store globvar globvar contained thread running precise moment completed load register hadcompleted add store instruction operating interrupted thread switched thread thread catch executes instruction using register loading adding storing globvar thread go sleep thread restarted add instruction register thread contains previously loaded value thread add store globvar wrong picture w e meant use code count number thread passed point t wo thread passed point bad case bad timing variable indicates thread passed increment variable memory atomic halfway increment happen way problem multiprocessor processor execute instruction simultaneously load getting add store memory footnote processor actually got honor storing memory simply race boy getting pretty picky event really happen w ell crash airline reservation transaction way way guaranteeing thread instruction time thread started instruction thread wait enter thread exited area called critical section system simple solution critical section turn f interrupt instruction turn way guarantee way timer interrupt occurred intoff turn interrupt load globvar add store globvar inton turn interrupt technique doe work longer critical section cpu case need lock semaphore mutex thread library provide type routine t o use mutex make modification example code mutex data structure main attr initialize attr default null void spinfunc void parm globvar globvar printf spinfunc d d globvar mutex data structure declared shared area program thread created called initialize mutex globvar incremented lock mutex finish updating globvar instruction later unlock mutex w ith code shown neverbe processor executing globvar line code code hang increment missed semaphore lock used similar way interestingly using user space thread attempt lock locked mutex semaphore lock cause thread context switch allows thread owns lock better chance make progress point unlock critical section act unlocking mutex cause thread waiting mutex dispatched thread library barrier barrier dif ferent critical section multithreaded application need thread arrive point allowing thread execute point example based simulation task process portion simulation wait thread completed current time step thread begin time step t ypically thread created thread executes loop barrier loop rough pseudocode type approach follows main ith ith wait long time exit t time step loop compute total force particle update particle position based force return sense spinfunc function implement barrier set variable initially thread arrive variable incremented critical section immediately critical section thread spin precise moment thread spin loop time thread exit spin loop continue critical section processor executing critical section time barrier processor arrive barrier processor real example example focused mechanic shared memory thread creation thread termination w e used sleep routine slow thing suf ficiently interaction process want fast just learn threading threading s sake example code us multithreading technique described chapter speed sum lar ge array hpcwall routine link code allocates array fill random number using thread sum element array define basic thread include include include define void sumfunc void int threadcount thread try double globsum global variable int index local based thread index posix thread id attr thread attribute default mutex data structure define double array summing void hpcwall double main int retval tid double single multi begtime endtime initialize thing array attr initialize attr default null attr single threaded sum globsum hpcwall begtime globsum globsum array hpcwall endtime single endtime begtime printf single lf globsum single use different number thread accomplish thing threadcount printf threadcount globsum hpcwall begtime threadcount threadcount index retval tid attr sumfunc void index tid threadcount retval null hpcwall endtime multi endtime begtime printf lf globsum multi printf efficiency multi threadcount end threadcount loop void sumfunc void parm int chunk start end double locsum decide iteration belong int parm chunk threadcount start chunk end start chunk actual element end printf sumfunc d d start end compute sum subset locsum end locsum locsum array update global sum return waiting join pthread mutexlock mymutex code performs sum using single thread using parallel sum creates appropriate number thread sumfunc thread start sumfunc initially chooses area operation shared array strip chosen dividing overall array evenly thread thread getting extra division remainder thread independently performs sum area thread finished computation us mutex update global sum variable contribution global sum recs addup single sumfunc sumfunc efficiency sumfunc sumfunc sumfunc efficiency sumfunc sumfunc sumfunc sumfunc globsum globsum locsum efficiency recs interesting pattern interpret pattern know sun enterprise note thread time reduced good result given cost extra cpu w e characterize additional resource used computing ef ficiency factor computed multiplying wall time number thread time take single processor divided number using extra processor evaluates extra processor used pretty thread computation did speed thread wall time dropping ef ficiency thread wall time increase efficiency drop dramatically thread processor thread execute processor footnote worse thread switched processor processor cache processor processor slowing performance ef fect apparent example data structure lar ge memory reference value previously cache important match number runnable thread available resource compute code thread available processor thread compete causing unnecessary overhead reducing ef ficiency computation s important note nature link parallel sum serial sum t o perform summation parallel willing tolerate slight variation note drop price multiprocessor system far common system attractive feature including good compatibility workstation lar ge memory high throughput lar ge shared memory fast system strong multiprogrammed server role affordable high performance computing resource ganizations model allows multithreaded application easily developed examined software paradigm used develop multithreaded application hopefully write c code explicit thread like example chapter nice understand fundamental operation work multiprocessor system using tran language automatic parallelizing compiler advantage detail left tran compiler runtime library point especially advanced architecture explicitly program multithreaded program using type technique shown chapter trend predicted time begin multiple cpu single chip ability increase clock rate single chip slows imagine new workstation processor single chip sound like good time learn write multithreaded program exercise exer cise pr oblem experiment fork code chapter run program multiple time order message change explain result exer cise pr oblem experiment code chapter remove sleep call execute program time single multiprocessor system explain output change run run situation doesn t change exer cise pr oblem experiment parallel sum code chapter sumfunc routine change end globsum globsum array remove line end mutex update globsum execute code explain dif ference value globsum pattern dif ferent single processor multiprocessor explain performance impact single processor multiprocessor exer cise pr oblem explain following code segment cause deadlock process waiting resource t relinquished lock lock unlock unlock lock lock unlock unlock exer cise pr oblem code functionality c look like lockword lockword lockword know section book statement compiled explicit load store comparison branch s danger process load lockword unset continue owned lock race condition suggests implemented dif ferently merely line c suppose implemented introduction link examined hardware used implement parallel processor software environment programmer using thread explicitly chapter view processor simpler vantage point programming system tran advantage compiler s support system end ease use simply add flag compilation code set environment variable voil executing parallel want control add directive particular loop know better compiler loop executed footnote examine loop benefit automatic parallelism look type directive add program assist compiler generating parallel code chapter refers running code parallel technique apply vector supercomputer skipped chapter book jumped don t surprised terminology unfamiliar chapter contain endless boring did contain basic terminology read chapter common terminology needed chapter don t read chapter don t complain big word using chapter automatic parallelization far book ve covered tough thing need know parallel processing point assuming loop clean use unit stride iteration parallel turn compiler flag buy good parallel processor example look following code parameter real n x n b n c niter n x b c enddo x b c enddo iterative code satisfies criterion good parallel loop good parallel processor modern compiler flag away executing parallel sun solaris system autopar flag turn automatic parallelization loopinfo flag cause compiler particular optimization performed loop t o compile code solaris simply add flag daxpy line parallelized unsafe line parallelized daxpy real user sys simply run code s executed using thread code enabled parallel processing loop executed parallel t o execute code parallel need set unix environment number parallel thread wish use execute code solaris using parallel variable setenv parallel daxpy real user sys setenv parallel daxpy real user sys setenv parallel daxpy real user sys setenv parallel daxpy real user sys speedup term used capture faster job run using n processor compared performance processor computed dividing single processor time multiprocessor time number processor link show wall time speedup application improving performance adding processor link show information graphically plotting speedup versus number processor ideal actual performance improvement note nearly perfect speedup begin measurable drop speedup processor cause parallel application portion code t run parallel nonparallel time processor waiting work aren t contributing ef ficiency nonparallel code begin af fect overall performance processor added application say like immediately try run thread graph link data link increasing number thread diminishing return happened thing going slowed w e running program active thread indicated uptime day s min s user load average pas thread available processor thread thread processor significantly slowing overall operation end executing thread processor performance slower thread important don t create thread type application compiler consideration improving performance turning automatic parallelization example smarter compiler discussed earlier chapter addition single compiler flag triggered great deal analysis compiler including loop execute parallel producing exact result sequential execution loop checking dependency span iteration loop interiteration dependency called doall loop loop worth executing parallel generally short loop gain benefit execute slowly executing parallel loop unrolling parallelism cost best used benefit far outweighs cost loop nest loop best candidate parallelized generally best performance occurs parallelize outermost loop loop nest way overhead associated beginning parallel loop amortized longer parallel loop duration loop nest interchanged compiler detect loop nest order order work parallel code giving poor memory performance order unit stride perform poorly multiple thread compiler analyze approach make best choice break iteration thread executing parallel loop iteration short uniform duration long wide variation execution time w e number dif ferent way accomplish programmer given guidance compiler make educated guess complicated compiler surprisingly good job wide variety code magic example following code flow dependency program dep parameter real n niter n c enddo enddo end compile code compiler give following message dep line parallelized unsafe line parallelized unsafe dependence compiler throw hand despair let know loop line unsafe dependence won t automatically parallelize loop code executed adding thread doe af fect execution performance setenv parallel dep real user sys setenv parallel dep real user sys typical application loop loop executed parallel s good idea run profile application routine use cpu time check loop parallelized w ithin loop nest compiler generally chooses loop execute parallel compiler flag addition flag shown compiler flag available apply entire program compiler flag enable automatic parallelization reduction operation order addition af fect final value computing sum number compiler need permission parallelize summation loop flag relax compliance ieee rule compiler flexibility trying parallelize loop sure s causing accuracy problem area code compiler flag called unsafe optimization assume flag enhance performance application loop dependency certainly produce incorrect result value experimenting compiler particular combination yield good performance variety ofapplications set compiler option used starting point encounter new compiler simple wouldn t need book compiler extremely clever lot way improve performance code sacrificing portability instead converting program c using thread library assist compiler adding compiler directive source code compiler directive typically inserted form stylized tran comment nonparallelizing compiler ignore just look tran code sans comment allows tune code parallel architecture letting run badly wide range system category comment assertion manual parallelization directive assertion tell compiler certain thing programmer know code guess looking code assertion attempting assuage compiler s doubt loop eligible parallelization use directive taking responsibility correct execution program y ou telling compiler parallelize responsibility output program program produce meaningless result blame assertion previous example compiled program received following output dep line parallelized unsafe line parallelized unsafe dependence uneducated programmer read book looked code exclaim unsafe dependence code quickly add dependency assertion essence assertion instead telling compiler simply parallelize loop programmer telling compiler conclusion dependence incorrect usually net result compiler doe parallelize loop briefly review type assertion typically supported compiler assertion generally added code using stylized comment dependency dependency ignor e dependency directive tell compiler reference don t overlap tell compiler generate code execute incorrectly dependency y ou saying know m doing s ok overlap dependency directive help following loop n b enddo know k greater compiler parallelize loop c assert n b enddo course blindly telling compiler dependency prescription disaster k equal example recursive loop relation loop contain potential dependency making bad candidate dependency directive able supply local fact certain variable allows partial parallelization compromising result code potential dependency subscript involving k j n b c c b know conflict reference maybe aren t sure c c t say general dependency able say explicit k like k greater leaving j information relationship expression called relation assertion applying relation assertion allows compiler apply optimization statement loop giving partial parallelization footnote notice tuning hand split loop parallelizable supply inaccurate testimony lead compiler make unsafe optimization answer wrong permutation seen element array indirectly addressed worry subscript repeated code value k unique duplicate n k k b c end know duplicate k k permutation inform compiler iteration execute parallel y ou supply information using permutation assertion equivalence equivalenced array tran program provide challenge compiler element equivalenced array appear loop compiler assume reference point memory storage location optimize conservatively true abundantly apparent overlap whatsoever inform compiler reference equivalenced array safe equivalence assertion course don t use equivalence assertion ef fect trip count loop characterized average number iteration loop executed just time hundred time c assert tripcount n b c end compiler going look loop candidate unrolling parallelization s working dark t tell loop important try optimize lead surprising experience seeing runtime optimization trip count assertion provides clue compiler help decide unroll loop parallelize loop footnote loop aren t important identified low zero trip count important loop high trip count assertion hand profiler inline substitution compiler support procedure inlining use directive switch specify nested level procedure like inline threshold procedure size vendor chosen reasonable let choose subroutine think good candidate inlining subject threshold compiler reject choice inlining expand code increased memory activity claim gain eliminating procedure higher optimization level compiler capable making choice inlining candidate provided source code routine consideration compiler support feature called interpr ocedural analysis compiler look routine boundary data flow analysis perform significant optimization routine boundary including automatic inlining constant propagation effect interprocedural analysis looking loop subroutine middle loop compiler treat subroutine worst possible ef fects assume dependency prevent routine executing simultaneously dif ferent thread routine especially function don t ef fects execute quite nicely separate thread thread private stack local variable routine meaty great deal benefit executing parallel computer allow add directive tell successive call independent c assert n bigstuff b c j k end compiler source code use common variable equivalence mask independence manual parallelism point tired giving compiler advice hoping reach conclusion parallelize loop point realm manual parallelism luckily programming model provided tran insulates detail exactly multiple thread managed runtime y ou generally control explicit parallelism adding specially formatted comment line source code wide variety format directive section use syntax openmp link standard y ou generally similar capability vendor compiler precise syntax varies slightly vendor vendor good reason standard basic programming model executing section code single thread multiple thread programmer add directive summon additional thread various point code basic construct called parallel r egion parallel r egions parallel region thread simply appear statement code trivial example following using openmp directive syntax program external integer iglob print hello c omp parallel private iam shared iglob iam print iam iglob c omp end parallel print end c omp sentinel indicates directive just comment output program run look follows setenv hello execution begin single thread program encounter parallel directive thread activated join computation sense execution pass directive thread thread execute statement directive thread executing independently order print statement displayed somewhat random thread wait end parallel directive thread arrived thread completed parallel region single thread continues executing remainder program link private iam indicates iam variable shared thread instead thread private version ofthe variable iglob variable shared thread modification iglob appears thread instantly limitation cache coherency data interaction parallel region parallel region programmer typically divide work thread pattern going multithreaded execution repeated time execution application input output generally completely correct indicate print statement parallel section executed processor time w e use directive indicate section code critical section lock synchronization mechanism ensures processor executing statement critical section time c omp critical print iam iglob c omp end critical parallel loop quite area code valuable execute parallel loop consider following loop b sqrt b enddo manually parallelize loop insert directive beginning loop c omp parallel b sqrt b enddo c omp end parallel statement encountered runtime single thread summons thread join computation thread start working loop detail handled parallel directive accepts data classification andscoping clause parallel section directive earlier indicate variable shared thread variable separate copy thread disaster shared thread thread take square root thread resetting content b come outside loop shared w e need augment directive follows iteration variable variable different thread increment way particular subset array don t want modifying global value number option data operated thread summarizes data semantics available firstprivate variable initial value global variable immediately loop begin executing lastprivate variable thread executes iteration loop copy value global variable reduction indicates variable participates reduction operation safely parallel forming partial reduction using local variable thread combining partial result end omp parallel shared b private b sqrt b enddo c omp end parallel vendor dif ferent term indicate data semantics support common semantics link show dif ferent type data semantics operate data environment set loop remaining problem solved thread perform iteration turn trivial task wrong choice significant negative impact overall performance iteration scheduling basic technique variation dividing iteration loop thread w e look extreme example idea work c vector add iprob b iprob c iprob enddo c particle tracking ranval rand iprob ranval enddo enddo variable parallel regionin loop computation independent processor processor execute single iteration vector add example iteration relatively short execution time relatively constant iteration iteration particle tracking example iteration chooses random number initial particle position iterates minimum ener gy iteration take relatively long time complete wide variation completion time iteration iteration example ef fectively end continuous spectrum iteration scheduling challenge facing tran parallel runtime environment static beginning parallel loop thread take fixed continuous portion iteration loop based number thread executing loop dynamic dynamic scheduling thread process chunk data completed processing new chunk processed chunk size varied programmer fixed duration loop example loop iteration scheduling approach operate executing thread vector add loop static scheduling distribute iteration thread thread thread thread link mapping iteration thread shown static scheduling option iteration assignment static scheduling loop body single statement short consistent execution time static scheduling result roughly overall work time assume dedicated cpu thread assigned thread loop execution advantage static scheduling occur entire loop executed repeatedly iteration assigned thread happen running processor cache actually contain value b c previous loop execution footnote runtime static scheduling loop look follows operating runtime library actually length try make happen reason thread available processor cause unnecessary context switching c vector add static scheduled istart iend istart ilocal istart iend ilocal b ilocal c ilocal enddo s good strategy use static approach giving fixed number iteration thread used second loop example long varying iteration time result poor load balancing better approach processor simply value iprob time loop approach called dynamic scheduling adapt widely varying iteration time link mapping iteration processor using dynamic scheduling shown soon processor finish iteration process available iteration order iteration assignment dynamic scheduling loop executed repeatedly assignment iteration thread vary subtle timing issue af fect thread dynamic scheduled loop runtime follows c particle tracking dynamic scheduled iprob iprob iprob iprob ilocal iprob ranval rand ilocal ranval endwhile ilocal used thread know iteration currently processing iprob value altered thread executing critical section dynamic iteration scheduling approach work particular loop significant negative performance impact programmer use wrong approach loop example dynamic approach used vector loop time process critical section determine iteration process lar ger time actually process iteration furthermore cache affinity data ef fectively lost virtually random assignment iteration processor approach wide variety technique operate chunk iteration technique chunk size fixed varies execution loop approach chunk iteration grabbed time critical section executed reduces scheduling overhead problem producing balanced execution time processor runtime modified follows perform particle tracking loop example using chunk size iprob chunksize iprob istart iprob iprob iprob chunksize ilocal istart ranval rand ilocal ranval enddo endwhile choice chunk size compromise overhead termination imbalance t ypically programmer involved directive order control chunk size challenge iteration distribution balance cost existence critical section work invocation critical section ideal world critical section free scheduling dynamically supercomputer hardware assistance load balancing nearly achieve ideal using dynamic approach relatively small chunk size choice loop iteration approach important compiler relies directive programmer specify approach use following example show request proper iteration scheduling loop c vector add c omp parallel private iprob shared b c schedule static iprob b iprob c iprob enddo c omp end parallel c particle tracking c omp parallel private iprob ranval schedule dynamic ranval rand iprob ranval enddo c omp end parallel closing note using data flow analysis technique modern compiler peer clutter programmer innocently code pattern actual computation field high performance computing having great parallel hardware lousy automatic parallelizing compiler generally result sale t oo benchmark rule allow compiler option set physicist chemist interested physic chemistry computer science take hour execute chemistry code modification week modification code executes minute better w ell chemist s point view took hour took hour minute answer obvious footnote program going executed thousand time tuning win programmer answer obvious take week tune program time make modification program hand person computer scientist improving performance result poster session conference journal article make lot master degree project way assertion popular directive factor compiler getting better detecting parallelism rewrite code kind programmer know exactly parallelize code turn safe flag code assertion fall middle ground programmer doe want control detail kind feel loop parallelized online documentation openmp syntax used example www exer cise pr oblem static highly parallel program relative lar ge inner loop compile application parallel execution execute application increasing thread examine behavior number thread exceed available processor dif ferent iteration scheduling approach make dif ference exer cise pr oblem following loop execute dif ferent iteration scheduling choice scheduling use lar ge chunk size approach performs better static scheduling b enddo exer cise pr oblem execute following loop range value n million n b enddo run loop single processor force loop run parallel point better performance multiple processor number thread af fect observation exer cise pr oblem use explicit parallelization directive execute following loop parallel chunk size j c omp parallel private shared j schedule dynamic j j enddo print j c omp end parallel execute loop varying number thread including compile execute code serial compare output execution time result tell cache coherency cost moving data cache critical section cost introduction chapter discusses programming language used largest parallel processing system usually faced porting tuning code new scalable architecture architecture sit think application moment fundamental change algorithm needed begin work new architecture surprised need rewrite portion application language modification performance benefit application important worth effort improve performance chapter cover tran hpf high performance tran language designed use computing system w e follow simple program language using simple ference computation roughly model heat flow classic problem contains great deal parallelism easily solved wide variety parallel architecture introduce discus concept single program multiple data spmd treat mimd computer simd computer w e write application lar ge simd going solve problem instead actually using simd resulting application compiled mimd implicit synchronization simd system replaced explicit synchronization runtime mimd problem heat flow classic problem explores scalable parallel processing heat flow problem physic problem lie partial dif ferential equation start metal plate known rod plate later example w e start rod zero degree celsius place end degree steam end zero degree ice w e want simulate heat flow end resulting temperature point metal rod temperature stabilized break rod segment track temperature time segment intuitively time step temperature portion plate average surrounding temperature given fixed temperature point rod temperature eventually conver ge steady state suf ficient time step link show setup beginning simulation heat flow rod simplistic implementation follows program heatrod parameter integer tick maxtime real rod rod rod enddo rod maxtime mod print tick rod rod rod rod enddo enddo format end output program follows main heatrod clearly t ime step simulation conver ged decimal place accuracy number stopped changing approximation temperature center segment bar point astute reader saying um look loop flow dependency claim wo parallelize little bit bad ca unroll loop little parallelism person familiar theory heat flow point loop doe exactly implement heat flow model problem value right assignment rod loop supposed previous time step value left time step way loop written rod value time step shown link solved using technique called r alternate array link show version computation operates kill bird stone mathematics precisely correct recurrence sound like real situation computing new value cellusing array eliminate dependency downside approach take twice memory storage twice memory bandwidth footnote modified code follows approach computes element odd element rod pass approach data dependency pas rod array value time step odd value time step ahead end stride double bandwidth doe double memory storage required solve problem program heatred parameter integer tick maxtime real red black red black red enddo red black mod print tick red black red red enddo red black black enddo enddo format end output modified program main heatred interestingly modified program take longer conver ge version conver ge t ime step look version recurrence heat ended flowing faster left right left element average value nifty wrong footnote generally problem approach conver ge eventual value limit representation algorithmic approach solving partial dif ferential equation fast multipole method accelerates conver gence legally assume brute force approach used method solve particular problem programmer look best available algorithm parallel trying scale wrong algorithm folk computer scientist time solution important linear heat flow problem extremely simple form inherently parallel simple data interaction good model wide range problem discretizing space performing simple simulation space problem usually scaled making finer grid benefit scalable processor allow finer grid faster time solution example able worldwide weather simulation using grid hour processor using processor able simulation using grid hour accurate result using processor finer grid simulation hour parallel language seen book biggest tuning challenge getting compiler recognize particular code segment parallelized particularly true numerical code potential payback greatest think know parallel dif ficulty getting compiler recognize ca just write compiler say yes parallel problem commonly used language fer construct expressing parallel computation y ou forced express primitive term caveman grand thought vocabulary voice particularly true tran support notion parallel computation mean programmer reduce calculation sequential step sound cumbersome programmer naturally realize good example let say want add vector w e probably write little loop moment thought n c b end reasonable look happened w e imposed order calculation w ould say c get plus b free compiler add vector using hardware disposal using method like parallel language seek supply primitive suitable expressing parallel computation new parallel language proposed rapidly developer realized come awonderful scheme compatible tran c people care reason simple billion line c tran code line fizgibbet new parallel language predominance c tran significant parallel language activity today seek extend language protecting year investment program written footnote tempting developer new language test language problem game life good result declare ready prime time begin waiting horde programmer converting particular language significant ef fort area completely new language stream iteration single assignment language sisal data flow language easily integrate tran c module interesting aspect sisal number lar ge computational code ported sisal fact sisal proponent generally compared performance tran c performance tran previous american national standard institute ansi tran standard release tran written promote portability tran program dif ferent platform did invent new language component instead incorporated good feature available production compiler unlike tran tran ansi brings new extension feature language just bring tran date newer language like c dynamic memory allocation scoping rule generic function interface new feature unique tran array operation interestingly tran specification developed dominant high performance computer architecture scalable simd system connection machine vector processor system company like cray research tran doe surprisingly good job meeting need dif ferent architecture feature map reasonably new shared uniform memory multiprocessor later tran suf ficient meet need scalable distributed nonuniform access memory system dominant high end computing tran extension tran include array construct dynamic memory allocation automatic variable pointer new data type structure new intrinsic function including operate vector matrix new control structure statement enhanced procedure interface tran array constructswith tran array construct specify array array section participant unary binary operation construct key feature unserializing application better suited vector computer parallel processor example say wish add vector tran express simple addition operation traditional loop write b instead traditional tran loop n b enddo code generated compiler workstation look different parallel machine available workstation just corner dif ference significant tran version state explicitly computation performed order including parallel time important ef fect tran version experienced fault adding element look memory debugger perfectly legal element computed limited array instance wise addition array stated like footnote just case wondering b give multiplication array member matrix multiplication iscovered tran intrinsic function b lieu m n j j b j end end naturally want combine array operation shape compatible adding vector element vector doe make sense multiplying array array array compatible shape relative operation performed say shape conformance following code double precision b b scalar considered shape conformance array scalar binary operation array scalar treated array size single element duplicated limited reference particular array example reference thing element y ou canimagine case interested specifying subset array group consecutive element like eighth element stride array part array possibly noncontiguous called array section tran array section specified replacing traditional subscript triplet form b c meaning element b taken increment omit part triplet provided meaning remains clear example b mean element b mean element upper bound increment remember triplet replaces single subscript array n triplet use triplet expression making sure part expression conformance consider statement real x y x y x y statement assigns element y row second statement express thing slightly dif ferently lone tell compiler range implied tran intrinsics tran extends functionality tran intrinsics add new one including intrinsic subroutine return array section scalar depending invoked example new use sin intrinsic real sin element array replaced sine tran intrinsics work array section long variable receiving result shape conformance passed real real b b co intrinsics sqrt log extended new intrinsics reduction tran vector reduction maxval minval sum higher array vector function perform reduction particular dimension additionally function vector matrix manipulation intrinsics matmul transpose manipulate matrix constructing r eshaping array reshape allows create new array element old dif ferent shape spread replicates array new dimension merge copy portion array control mask cshift allows array shifted dimension inquiry function shape size lbound ubound let ask question array test new reduction intrinsics testing array element parallel new contr ol featur e tran includes new control feature including conditional assignment primitive called put array assignment control mask following example example primitive real b c data b c c b endwhere place logical expression true get c get clause get result operation array c element c order implied conditional assignment meaning parallel lack implied order critical allowing simd computer system spmd environment flexibility performing allocatable array program need temporary variable work space past tran programmer managed scratch space declaring array lar ge handle temporary requirement practice gobble memory albeit virtual memory usually ef fect performance w ith ability allocate memory dynamically programmer wait later decide scratch space set aside tran support dynamic memory allocation new language feature automatic array allocatable array like local variable c program tran automatic array assigned storage life subroutine function contains dif ferent traditional local storage tran array space set aside compile link time size shape automatic array sculpted combination constant ar guments instance declaration automatic array b using tran new specification syntax subroutine relax n integer n real dimension n b array declared dummy ar gument b automatic explicit shape array subroutine return b cease exist notice size b taken ar guments allocatable array ability choose size array examining variable program example want determine input data allocating array little program asks user matrix size allocating storage integer m n real allocatable dimension x write dimension x read m n allocate x m n x deallocate x allocate statement creates m n array later freed deallocate statement c program important allocated memory program consume virtual storage available heat flow tran heat flow problem ideal program use demonstrate nicely tran express regular array program program heatrod parameter integer tick maxtime real rod rod rod enddo rod maxtime mod print tick rod rod rod rod enddo format end program identical inner loop replaced single statement computes new section averaging strip left element strip right element output program follows look closely output implementation tran rod rod rod single assignment statement shown link right completely evaluated resulting array section assigned rod moment unnatural consider following statement know start incremented statement happens right evaluated assignment performed tran variable entire array operation old rod right new rod left really think tran good pretend simd million little cpu carefully align data sliding single instruction add aligned value instant link show graphically act aligning value adding data flow graph extremely simple row data flow using temporary space eliminates dependency approach thinking simd way force focus thought data control simd good architecture problem express simd work goodspmd environment advantage data parallelism identified example actually highlight challenge producing ef ficient implementation tran array contained million element compiler used simple approach need million element old left value old right value new value data flow optimization needed determine just extra data maintained proper result compiler clever extra memory quite small data alignment computation rod rod rod rod enddo doe parallelism implementation doe produce correct result extra data element trick save old left value just wipe good tran compiler us data flow analysis looking template computation move data save element short period time alleviate need complete extra copy data advantage tran language compiler us complete copy array data element insure program executes properly importantly change approach architecture tran v ersus tran interestingly tran fully embraced high performance community reason concern use pointer dynamic data structure ruin performance lose optimization advantage tran people say tran trying better c say want like slower language reason controversy tran implemented leading reluctance adoption programmer vendor said use tran tran faster vendor implemented dif ferent subset tran portable tran user needed maximum portability stuck tran vendor purchased fully compliant tran compiler party demanded high license fee free faster according vendor tran pay slower wink wink tran compiler factor number application developed tran small benchmark used purchase new system exclusively tran furthermotivated vendor improve tran compiler instead tran compiler tran compiler sophisticated using data flow analysis relatively easy write portable parallel code tran using technique discussed book greatest potential benefit tran portability simd supercomputer architecture replaced shared uniform memory multiprocessor tran language af forded maximum portability computer typically used high performance computing programmer tran compiler supported directive allowed programmer performance application taking control parallelism certain dialect tran essentially parallel programming assembly language highly tuned version code relatively portable different vendor shared uniform memory multiprocessor event conspired tran short run tran suited distributed memory system doe lend data layout directive need partition distribute data carefully new system compiler lot flexibility tran language best suited purpose tran summary whirlwind tour tran w e probably language disservice covering briefly wanted feel feature discussed like learn recommend fortran explained michael metcalf john reid oxfor d university pr es tran suf ficient scalable performance distributed memory system far compiler capable performing data flow analysis decide store data andwhen retrieve memory programmer involved data layout w e decompose problem parallel chunk individually processed w e option w e use high performance tran leave detail compiler use explicit care detail decomposition main approach dividing decomposing work distribution multiple cpu decomposing computation discussed technique decomposition based computation come mechanism divide computation iteration loop evenly processor location data generally ignored primary issue iteration duration uniformity preferred technique shared uniform memory system data equally accessed processor decomposing data memory access nonuniform tendency focus distribution data computation assumption retrieving remote data costly minimized data distributed memory processor contains data performs computation data retrieving data necessary perform computation decomposing task operation performed independent time task decomposition performed approach master maintains queue work unit processor available resource retrieves task queue begin processing attractive approach embarrassingly parallel computation footnote distributed ef fort coordinated fashion processor check block key begin testing key point processor fast crashed central reissue block processor allowed recover problem individual computer sense rest chapter primarily data decomposition distributed memory communication cost usually dominant performance factor problem embarrassingly parallel distributed task nearly anytechnique work problem occur discipline vary extremely parallel just sort parallel example fractal calculation extremely parallel point derived independently rest simple divide fractal calculation processor calculation independent processor coordinate share data heat flow problem expressed tran form extremely parallel requires sharing data gravitational model galaxy kind parallel program point exerts influence unlike fractal calculation processor share data case want arrange calculation processor say work work finished problem fer independence region good candidate domain decomposition finite dif ference problem range particle interaction simulation column matrix treated similarly divide domain evenly processor approximately work way solution physical system regular involve interaction node unstructured grid allocated direct correspondence physical location instance model involves force particle attraction problem dif ficult structured parallel machine various simplification lumping intermediate effect needed instance influence group distant particle treated composite particle acting distance spare communication required processor talk regarding case parallel architecture fers opportunity express physical dif ferent clever way make sense context machine instance particle assigned toits processor slide past summing interaction updating time step depending architecture parallel computer problem choice dividing replicating portion domain add unacceptable overhead cost project lar ge problem dollar value main memory make keeping separate local copy data question fact need memory drive people parallel machine problem need solve ca fit memory conventional computer investing ef fort allow domain partitioning evolve program run response uneven load distribution way lot request processor dynamically copy piece domain piece spread processor handling dif ferent subset definition y ou migrate unique copy data place place changing home needed data domain irregular change time parallel program encounter problem problem especially apparent portion parallel computation take longer complete example engineering analysis adaptive grid program run grid refined area showing activity work reapportioned time time section computer responsibility highly refined portion grid fall farther farther performance rest performance tran hpf march high performance fortran forum hpff began meeting discus define set addition tran make practical use scalable computing environment plan develop specification calendar year vendor quickly begin implement standard scope ef fort included following identify scalar array distributed parallel machine say distributed w ill strip block specify variable aligned respect redistribute realign data structure runtime add forall control construct parallel assignment difficult impossible construct using tran array syntax make improvement tran control construct add intrinsic function common parallel operation source inspiration hpf ef fort layout directive tran programming environment simd computer pvm portable environment released year earlier user year experience trying decompose hand program developed basic usable technique data decomposition worked required far bookkeeping footnote shall soon hpf ef fort brought diverse set interest major high performance computing vendor v endors representing major architecture represented result hpf designed implemented nearly type architecture ef fort underway produce tran standard tran tran expected adopt thehpf modification programming hpf core hpf includes tran tran program run hpf compiler produce result run tran compiler assuming hpf program us tran construct hpf directive tran compiler ignore directive produce result hpf compiler user add directive program semantics program changed user completely misunderstands application insert extremely directive program produce correct result slowly hpf compiler doe try improve user directive assumes programmer omniscient footnote safe assumption user determined data distributed processor hpf compiler attempt use minimum communication necessary overlap communication computation possible hpf generally us owner computes rule placement computation particular element array computed processor store array element necessary data perform computation gathered remote processor necessary perform computation programmer clever decomposition alignment data needed local memory remote memory hpf compiler responsible allocating temporary data structure needed support communication runtime general hpf compiler magic simply doe good job communication detail programmer design good data decomposition time retains portability single cpu shared uniform memory system using tran data layout dir ectives important contribution hpf data layout directive using directive programmer control data laid based programmer knowledge data interaction example directive follows real rod hpf distribute rod block hpf prefix comment compiler safely ignored straight tran compiler distribute directive indicates rod array distributed multiple processor directive used rod array allocated processor communicated processor necessary distribution dimension real bob rich hpf distribute bob block cyclic hpf distribute rich cyclic distribution operate follows block array distributed processor using contiguous block index value block lar ge possible cyclic array distributed processor mapping successive element processor processor reached allocation start processor cyclic n array distributed cyclic n successive element placed processor moving processor note element dimension placed processor useful multidimensional array distributing array element processor link show element simple array mapped processor dif ferent directive allocate element processor processor available leftover element allocated element processor link element allocated successive processor wrapping processor processor link using chunk size cyclic compromise pure block pure cyclic explore use look simple array mapped processor link array layout cell indicates processor hold data cell dimensional array link directive decomposes dimension simultaneously approach result roughly square patch array best approach following example use indicate want element particular column allocated processor column value equally distribute column processor row column follow column placed allows unit stride processor portion computation beneficial application syntax called distribution distribution dealing data structure perform computation separately distribute use align directive ensure corresponding element data structure allocated following example plate array scaling factor applied column plate computation dimension plate scale hpf distribute plate block hpf align scale plate j dimension plate scale hpf distribute plate block hpf align scale plate example plate scale variable allocated processor corresponding column plate syntax communicate information used dimension collapsed doe participate distribution used mean dimension follows corresponding dimension variable distributed specify layout scale variable plate variable follow layout scale variable dimension plate scale hpf distribute scale block hpf align plate j scale simple arithmetic expression align directive subject limitation directive include processor allows create shape processor configuration used align data structure redistribute realign allow dynamically reshape data structure runtime communication pattern change course run template allows create array us space instead distributing data structure aligning data structure user create distribute template align real data structure use directive range simple complex situation distribute lar ge shared structure align related structure situation programmer attempt optimize communication based topology interconnection network hypercube interconnection network mesh toroid using detailed directive carefully redistribute data various phase computation hopefully application yield good performance effort hpf contr ol structur e hpf designer midst defining new language set improving saw limitation tran interestingly modification considered new tran standard forall statement allows user express simple iterative operation apply entire array resorting remember force order example forall j j expressed native tran ugly counterintuitive prone error control structure ability declare function pure pure function ef fects parameter programmer guaranteeing pure function execute simultaneously processor ill ef fects allows hpf assume operate local data doe need data communication duration function execution theprogrammer declare parameter function input parameter output parameter parameter hpf intrinsics company marketed simd computer needed come significant tool allow ef ficient collective operation processor perfect example sum operation t o sum value array spread n processor simplistic approach take n step possible accomplish log n step using technique called time hpf development number operation identified implemented hpf took opportunity define standardized syntax operation sample operation includes performs various type summation distributes single value set processor sort decreasing order iany computes logical set value lar ge number intrinsic function application use operation hpf extrinsics order allow vendor diverse architecture provide particular advantage hpf included capability link extrinsic function function did need written tran performed number vendor capability capability allowed user perform task creation hybrid application hpf message passing high performance computing programmer like ability thing way order eke drop flow hpf port heat flow application hpf really single line code need added example changed larger array integer platesiz maxtime parameter hpf distribute plate block real plate platesiz platesiz integer tick plate add boundary plate plate platesiz plate plate tick maxtime plate plate plate plate plate print tick plate format enddo end notice hpf directive distributes array column using block approach keeping element column single processor glance appear block block better distribution advantage block distribution striding column operation just process entire column significant aspect distribution block block distribution force processor communicate processor neighboring value using block distribution processor exchange data processor time step look pvm look program implemented fashion example detail hpf handle properly execute code reviewing code probably choose implement future heat flow application hpf hpf summary way hpf good tran company ibm needed provide language user did want write code ibm invested great deal ef fort implementing optimizing hpf interestingly ef fort directly benefit ability develop sophisticated tran compiler extensive data flow analysis required minimize communication manage dynamic data structure carry tran compiler using hpf directive time tell hpf data distribution directive longer needed compiler capable performing suf ficient analysis straight tran code optimize data placement current form hpf excellent vehicle expressing highly application weakness irregular communication dynamic load balancing new ef fort develop version hpf way address issue unfortunately dif ficult solve runtime problem maintaining good performance wide range note chapter covered ef fort area language developed allow program written scalable computing tension pure tran hpf message passing ultimate tool scalable high performance computing certainly example great success tran thinking machine hpf ibm sp language make excellent use scalable computing system problem language approach using abstract language actually r educes effective portability language designed portable vendor particular scalable computer doe support language variant chosen write application portable vendor language available tuned generate best code architecture solution purchase compiler company pacific sierra kuck associate vendor sell compiler run wide range system user af ford option compiler af ford higher level portability fundamental issue problem user use language vendor wo improve language influential user money use message passing existence excellent hpf compiler real value user good news tran hpf provide road map portable scalable computing doe require explicit message passing question road user interface set function subroutine call c tran way split application parallel execution data divided passed processor message receiving processor unpack work send result pas processor parallel computer way message passing assembly language parallel processing y ou ultimate responsibility talented problem cooperates ultimate performance nice scalable problem satisfied resulting performance pretty blame compiler completely unaware parallel aspect program popular environment parallel virtual machine pvm interface mpi important feature available environment mastered message passing moving pvm mpi won t cause trouble y ou operate provides vendor interface understand message passing concept properly decomposed application usually s ef fort library footnote notice said ef parallel v irtual machine idea pvm assemble diverse set resource virtual user marshal resource idle workstation internet personal scalable processing work pvm started early oak ridge national lab pvm pretty instant success computer scientist provided rough framework experiment using network workstation parallel processor pvm v ersion virtual machine consist single processor multiprocessor scalable multiprocessor pvm attempt knit resource single consistent execution environment run pvm simply need login account set network computer pvm software installed y ou install home directory create personal virtual machine create list computer file cat hostfile nontrivial machination path environment variable start pvm console pvm hostfile pvmd running pvm conf host data format host dtid arch speed frodo gollum mordor pvm p host tid flag command frodo f pvmgs pvm reset pvm p host tid flag command pvm dif ferent user running virtual machine using pool resource user view machine way detect virtual machine using resource percentage time application cpu wide range command issue pvm console p command show running process virtual machine s quite possible process computer system process load reset command performs soft reboot virtual machine y ou virtual administrator virtual machine assembled execute program virtual computer compile link program pvm library routine footnote note exact compilation dif ferent aimk mast slav making cc dsysvstr mast mv mast cc dsysvstr slav mv slav pvm encountered application contact virtual machine enrolls virtual machine point output p command issued pvm console point application issue pvm call create process interact process pvm take responsibility distributing process dif ferent system virtual machine based load assessment s relative performance message moved network using user datagram protocol udp delivered appropriate process typically pvm application start additional pvm process additional copy program pvm process run dif ferent pvm application work distributed process result gathered necessary basic model computing typically used working pvm operating mode process usually initial process designated master spawn number worker process w ork unit sent worker process result returned master master maintains queue work slave finish master delivers new work item slave approach work little data interaction work unit independent approach advantage overall problem naturally variation execution time individual process type application typically characterized fact shared data structure relatively small easily copied processor s node beginning time step global data structure broadcast master process process process operates portion data process produce partial result sent gathered master process pattern repeated time step decomposition overall data structure large copy stored process decomposed multiple process generally beginning time step process exchange data neighboring process local data augmented necessary subset remote data perform computation end time step necessary data exchanged neighboring process process restarted complicated application nonuniform data flow data migrates application change load change section example program master operation data solution heat flow problem queue t asksin example process mast creates slave process slav dole work unit add number slave process responds s given new work told work unit exhausted cat include include define maxproc define job main int mytid info int tids maxproc int tid input output answer work mytid slav char maxproc tids send work work maxproc pvmdatadefault work tids work msgtype send rest work request work maxproc answer job task msgtype tid input output printf thanks d tid input output pvmdatadefault work job work input input tell stop interesting aspect pvm interface separation call prepare new message pack data message send message reason pvm capability convert dif ferent format byte ordering character format allows single message multiple data item dif ferent type purpose message type pvm send receive allow sender wait particular type message example use message type t ype message master slave type response performing receive process wait message specific process message second phase computation master wait response slave print response dole work unit slave tell slave terminate sending message value slave code quite simple wait message unpacks check termination message return response repeat cat include include simple program double integer main int mytid int input output mytid task input input break output input pvmdatadefault mytid input output master program executed produce following output pheat thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks thanks clearly process operating parallel order execution somewhat random code excellent skeleton handling wide range computation example perform computation solve heat flow problem using pvm heat flow pvmthis example complicated application implement heat flow problem pvm way give insight work performed hpf environment w e solve heat flow plate heat source edge degree water shown link plate constant heat source data spread process using block distribution column distributed process contiguous block row element column stored process hpf process owns data cell performs computation cell retrieving data necessary perform computation use approach simplicity copy data end iteration true perform computation opposite direction time step note instead spawning slave process parent process spawn additional copy typical program additional process spawned process wait barrier look process number member group process arrived barrier retrieve list dif ferent process number cat program pheat include integer nproc row col totcols offset parameter point code nproc process executing spmd mode step determine subset array process parameter parameter real red black logical iamfirst iamlast integer inum info tids ierr integer r c integer tick maxtime character fname spmd thing going join pheat group pvmfjoingroup pheat inum pheat group make helper pvmfspawn pheat tids ierr enddo endif barrier make sure look pvmfbarrier pheat nproc info pal tids tids necessary sending pvmfgettid pheat tids enddowill compute driven inum variable range uniquely identifies process decompose data store quarter data process using inum variable choose continuous set column store compute offset variable map global column entire array local column local subset array link show map indicates processor store data element value marked b boundary value won t change simulation set code tricky figure performing block block distribution requires decomposition exchanging data neighbor addition neighbor left right assigning grid element processor compute geometry subset process value actual column offset column offset column neighbor left column send left column mylen cell compute column mylen send right column neighbor right column iamfirst inum iamlast inum offset inum mylen iamlast mylen totcols offset print inum inum local mylen global start cold black r c enddo enddo run time step act time step reset heat source simulation heat source placed near middle plate w e restore value time simulation modified main loop begin running time step maxtime set heat persistent source store black row col offset mylen inum store black row col offset mylen inum store black row col offset mylen inum store black row col offset mylen inum perform exchange ghost value neighboring process example process contains element global column t o compute time step value column need column stored process similarly process compute new value column need process s value column link show data transferred processor process sends leftmost column left rightmost column right process border unchanging boundary value left right respectively necessary column properly process receive ghost value left right neighbor pattern communication ghost valuesthe net result transfer space computed s surrounded layer boundary value ghost value right left neighbor send left right iamfirst pvmfinitsend pvmdefault true pvmfpack black row info pvmfsend tids info endif iamlast pvmfinitsend pvmdefault true pvmfpack black mylen row info pvmfsend tids info endif receive right left iamlast pvmfrecv tids bufid pvmfunpack black row info endif iamfirst pvmfrecv tids bufid pvmfunpack black row info endif segment easy appropriate ghost value place simply perform computation subspace end copy red black array real simulation perform time step black red red black save extra copy perform flow mylen row red r c black r c black r black c black c black r enddo enddo copy normally red black version loop mylen row black r c red r c enddo enddo enddo center cell send master process necessary printed w e dump data file debugging later visualization result file unique appending instance number filename program terminates sendcell red row col offset mylen inum tids dump data verification row fname char ichar open formatted mylen write black r c row format enddo close endif let pvmfbarrier pheat nproc info pvmfexit info end sendcell routine find particular cell print master process routine called spmd style process enter routine precisely time depending inum cell looking process dif ferent cell question master process master process print process cell question stored process process cell sends master process master process receives value print process simple example typical style spmd code process execute code roughly time based information local process action performed dif ferent process quite dif ferent subroutine sendcell red row col offset mylen inum ptid r c include integer row col offset mylen inum ptid r c real red real center compute local row number determine c offset mylen inum print master red r r c pvmfinitsend pvmdefault true pvmfpack red r info print inum inum returning r c red r pvmfsend ptid info endif inum pvmfrecv bufid pvmfunpack center info print master received r c center endif endif return end like previous routine store routine executed process idea store value global row column position determine cell process cell process compute local column subset overall matrix store value subroutine store red row col offset mylen r c value inum real red real value integer row col offset mylen r c inum c offset mylen return red r value return end program executes following output pheat inum local global master received line print line indicates value process used geometry computation second line output master process temperature cell time step interesting technique useful debugging type program change number process created program quite moving data properly usually dif ferent result different number process used look closely code performs correctly process process notice barrier operation end time step contrast way parallel loop operate shared uniform memory multiprocessor force barrier end loop used owner computes rule computed required ghost data received need barrier receipt message proper ghost value allows process begin computing immediately regard process currently doing example used framework developing based computation good excuse use hpf appreciate hard work hpf compiler developer hpf implementation simulation outperform pvmimplementation hpf make tighter optimization unlike hpf compiler doesn t generated code readable pvm summary pvm widely used tool af ford portability architecture simd ef fort invested making code message passing tends run architecture primary complaint pvm include need pack step separate send step fact designed work heterogeneous environment incur overhead doesn t automate common task geometry computation certain set programmer pvm tool use like learn pvm pvm user s guide tutorial networked parallel computing al geist adam beguelin jack dongarra w eicheng jiang robert manchek v aidy sunderam mit press information available www interface interface mpi designed strength environment portable wide range hardware environment like high performance tran mpi developed group computer vendor application developer computer scientist idea come specification strength existing proprietary message passing environment wide variety architecture come specification implemented architecture ranging simd system thousand small processor mimd network workstation interestingly mpi ef fort completed year high performance tran hpf ef fort completed viewed mpi portable interface support good hpf compiler having mpi make compiler portable having compiler use mpi environment insures mpi heavily tested suf ficient resource invested mpi implementation pvm v ersus mpi folk involved pvm participated mpi ef fort mpi simply pvm pvm developed lab environment evolved time new feature needed example group capability designed pvm fundamental level underlying assumption pvm based network workstation connected ethernet model didn t export scalable computer footnote way mpi robust pvm way mpi simpler pvm mpi doesn t specify management detail pvm mpi doesn t specify virtual machine created operated used diminish positive contribution pvm pvm widely able portable pioneered idea heterogeneous distributed computing format conversion mpi featur e mpi number useful feature basic send receive capability include communicator communicator subset active process treated group collective operation broadcast reduction barrier sending receiving w ithin communicator process rank range zero size group process member communicator dif ferent rank communicator default communicator refers mpi process called topology communicator topology associated arranges process belong communicator layout common layout cartesian decomposition example process arranged grid footnote topology defined queried neighboring process topology addition cartesian grid topology mpi support topology sound little like hpf communication mode mpi support multiple style communication including blocking blocking user choose use explicit buf fers sending allow mpi manage buffer nonblocking capability allow overlap communication computation mpi support model available memory space buf fers data copied directly address space sending process memory space receiving process mpi support single perform send receive quite useful process need exchange data collective operation call mpi automate collective operation single example broadcast operation sends value master slave receives thevalues slave operation net result value updated process similarly single sum value process single value bundling functionality single system support collective operation hardware make best use hardware mpi operating environment broadcast simplified slave simply make local copy shared variable clearly developer mpi specification significant experience developing application added widely used feature library feature programmer needed use primitive operation construct version higher operation heat flow mpi example implement heat flow problem mpi using similar decomposition pvm example way approach lem w e translate pvm call corresponding mpi call using communicator showcase mpi feature create cartesian communicator program mheatc include include integer row col totcols parameter simulation run minproc greater process ok set minproc testing purpose large number row column best set minproc actual number runtime process parameter parameter c double precision red black integer s e mylen r c integer tick maxtime character fname basic data structure pvm example w e allocate subset heat array process example space allocated process set variable minproc simulation execute minproc process wasting space process t execute minproc process won t suf ficient total space process hold array integer inum nproc ierr integer dims coords logical period logical reorder integer ndim integer status integer rightproc leftproc data structure used interaction mpi doing cartesian decomposition array dimensioned decomposition array need element print calling ierr print nproc ierr creates appropriate number process note output print statement appears second print appears process w e determine size global communicator use value set cartesian topology create new communicator cartesian topology associated return communicator descriptor dims nproc period reorder ndim ndim dims period reorder ierr create arrangement process parameter input value ierr integer communicator print value actually data merely handle used call quite similar file descriptor unit number used performing topology use decomposition isn t periodic specified wanted periodic decomposition far left far process neighbor fashion making ring given isn t periodic far far process neighbor pvm example declared process far process process far process process arranged linearly set reorder mpi chooses arrangement set reorder mpi choose arrange process fashion achieve better performance assuming communicating close neighbor communicator set use communication operation rank new communicator inum ierr communicator process rank zero size communicator minus tell process rank communicator process dif ferent rank communicator communicator reordering given cartesian topology communicator footnote extract information communicator using routine remember communicator topology associated topology grid graph interestingly communicator topology associated given communicator handle topology position topology ndim dims period coords ierr parameter output value input value coords variable tell coordinate communicator useful dimensional example process decomposition tell current position grid return left right neighbor unit away zeroth dimension cartesian map periodic neighbor exist handle leftproc rightproc ierr totcols nproc inum s e mylen e s print space need mylen col print totcols nproc inum s e stop endif print inum nproc coords leftproc rightproc s e use determine rank number left right neighbor exchange common point neighbor necessary t simply send mpi chosen reorder cartesian decomposition far far process neighbor doesn t exist set indicates neighbor later performing message sending check value sends message real process sending message null process mpi saved test determine strip global array store compute process utility routine called simply doe calculation evenly split column process contiguous strip pvm version need perform computation hand routine example extended mpi library mpe prefix extension include graphic support logging tool addition general utility mpe library consists routine useful standardize required supported mpi implementation y ou mpe routine supported mpi implementation communicator group set know strip process handle begin computation start cold black r c enddo enddo pvm example set plate including boundary value zero process begin time step loop interestingly like pvm need synchronization message implicitly synchronize loop step store permanent heat source w e need use routine make store operation relative strip global array begin running time step maxtime set persistent heat source store black row col s e um store black row col s inum store black row col s e inum store black row col s inum process set value independently depending process strip overall array exchange data neighbor determined cartesian communicator note don t need test determine far far process edge neighbor setting call given source destination value saving test note specify communicator rank value using call relative communicator send left receive right black row ierr black row n status ierr send right receive left single statement black mylen row black row leftproc status ierr just f use separate send receive combined send receive given choice s probably good idea use combined operation runtime environment flexibility term buf fering downside occurs anetwork workstation interconnect t send operation receive operation overlap communication delay ghost point neighbor perform algorithm subset space perform flow mylen row red r c black r c black r black c black c black r enddo enddo copy normally red black version loop mylen row black r c red r c enddo enddo enddo simplicity don t complete computation footnote synchronization loop message implicitly synchronize process loop note time step iteration exchanged ghost column dump data verification pvm example good test basic correctness make sure exactly result varying number process dump data verification row fname char ichar open formatted mylen write black r c row format enddo close endif terminate program let ierr end pvm example need routine store value proper strip global array routine simply check particular global element process computes proper location strip value global element process routine simply return doing subroutine store red row col s e r c value inum real red real value integer row col s e r c inum c s c e return c s print store inum r c s e r inum r c s e r value red r value return end program executed following output main mheatc store mheatc mheatc calling activate process print statement immediately appears time activated process process print thestrip array process w e neighbor process including process neighbor left right notice process left neighbor process right neighbor mpi provided utility simplify code need add implement type based application compare example pvm implementation problem contrast approach programmer wrote line code pvm combined single mpi mpi think data parallel express program fashion way mpi feel like assembly language pvm mpi doe little getting used compared pvm concept cartesian communicator foreign understanding flexible powerful tool heat mpi using br style parallel programming seen style application naturally solved using style programming application use approach effectively modification required make code run environment minimal application benefit approach generally lot computation using small shared information requirement complete copy shared information fit process grid size small actually program heat flow application using approach certainly ef ficient implementation earlier implementation problem core computation simple core computation complex needed access value farther unit away good data structure simpler approach actually different tran hpf version w e allocate complete red black array process program mheat include include integer row col parameter parameter double precision red black need fewer variable mpi call aren t creating communicator simply use default communicator start process size rank process group integer inum nproc ierr src dest tag integer s e l le mylen integer status integer r c integer tick maxtime character fname print calling ierr nproc ierr inum ierr col nproc inum s e ierr print share inum nproc s e broadcasting initial value process set thing master process start cold black r c enddo enddo endif run time step synchronization set persistent heat source directly shape data structure master process use real array coordinate mapping previous example w e skip persistent setting nonmaster process doesn t hurt process begin running time step maxtime set heat source black black black black broadcast entire array process rank zero process communicator note doe sending rank zero process receiving process net result process value master process single broadcast array black ierr perform subset computation process note using global coordinate array shape process need make sure set particular strip column according s e perform flow subset e row red r c black r c black r black c black c black r enddo enddo need gather appropriate strip process appropriate strip master array rebroadcast time change loop master receive message order check status variable strip received gather black array master inum inum e row black r c red r c enddo enddo col nproc l le ierr mylen le l src tag black l mylen src tag status ierr print recv mylen enddo mylen e s dest tag red s mylen dest tag ierr print send inum mylen endif enddo use determine strip receiving process application value gathered sum single value t o accomplish use mpi reduction routine coalesce set distributed value single value using single end dump data testing gathered master process need dump process dump data verification inum row fname open formatted col write black r c row format enddo close endif ierr end program executes process produce following output main mheat mheat mheat calling share share share share rank process subset computation process shown output somewhat contrived example approach parallelizing application data structure right size computation relative communication appropriate ef fective approach require smallest number code modification compared version code mpi summary chose pvm mpi depends library vendor prefers mpi better choice contains newest feature support multicast broadcast significantly improve overall performance scatter application good text mpi using mpi portable parallel pr ogramming interface w illiam gropp ewing lusk anthony skjellum mit press y ou want retrieve print mpi specification http note chapter looked assembly language parallel programming daunting rethink application simple change make port code message passing depending application master decomposed data approach appropriate s important realize application just don t decompose message passing y ou working just application experience message passing easier identify critical point data communicated process hpf pvm mpi mature popular technology s clear technology solution use year possibility use tran tran data layout directive directive optional interesting possibility simply using tran scalable memory system popular evolve data allocation primitive example support following data storage attribute shared dynamic data structure allocated placed class memory shared thread single node shared thread declare storage class data data layout new machine pvm mpi need capability supporting style computing allows application complete resource fail available compute power available application tolerate unreliability resource lar ge number moderately successful attempt area condor really caught run powerful computer world absolute maximum performance level need portable somewhat reduced making particular application faster scale higher number processor fascinating activity flop introduction high performance micr oprocessors said history rewritten victor clear high performance microprocessor defining current history high performance computing w e begin study basic building block modern high performance computing high performance risc microprocessor complex instruction set computer cisc instruction set powerful primitive close functionality primitive language like c tran capture sense don t software risc hand emphasizes primitive far complexity language y ou compute want using approach probably machine instruction using risc important dif ference risc trade set complexity speed fair risc isn t really new important early machine pioneered risc philosophy cdc ibm project risc machine posed direct challenge cisc installed base heated debate broke risc versus cisc lingers today clear risc footnote approach greatest favor generation cisc machine looking old family cisc dec v ax retired interesting remaining topic definition don t fooled thinking definition risc best heard far john mashey risc label commonly used set instruction set architecture characteristic chosen ease use aggressive implementation technique high performance processor regardless risc cisc irrelevant chapter cisc risc instruction set architecture difference w e newer processor canexecute instruction time execute instruction order cisc ask risc faster did people bother cisc design place short answer beginning cisc right way risc wasn t feasible af fordable kind design incorporates f time best system make dif ferently past design variable favored cisc space t ime start ll ask know assembly language station answer probably haven t seen bother compiler development tool good problem debug source level year ago respectable programmer understood machine s instruction set level language compiler commonly available didn t generate fastest code weren t terribly thrifty memory programming needed save space time meant knew program assembly language accordingly develop opinion machine s instruction set good instruction set easy use powerful way quality powerful instruction accomplished lot saved programmer specifying little step turn easy use apparent important feature powerful instruction saved memory time computer little storage today s standard instruction roll step complex operation loop single opcode footnote plus memory precious t o stake ground consider computer ibm built model hardware point including division operation index register instruction operate directly memory location instance add number store result memory single command philco early transistorized machine operation repeat sequence instruction content counter decremented zero like werecomplex operation today s standard machine limited memory word memory program took available data likely resort overlaying portion program opcode operation code instruction complex instruction saved time lar ge computer following ibm memory slower central processing unit cpu single instruction perform operation overall number instruction retrieved memory reduced minimizing number instruction particularly important exception machine late sequential current instruction completed did computer initiate process going memory instruction footnote contrast modern machine form bucket brigade passing instruction memory figuring way fewer gap processing ibm began constructing machine known stretch computer process instruction time stage streamed fetched meal fashion goal make time faster ibm year stretch delivered los alamo national laboratory faster expensive build sold loss million designer early machine fast abundant instruction memory sophisticated compiler wherewithal build instruction bucket brigade cheaply chosen create machine simple instruction set time technological choice indicated instruction powerful thrifty memory belief complex instruction setsso given lot cast favor complex instruction set computer architect license experiment matching intended purpose machine instance instruction philco looked like good companion procedural language like tran machine designer assumed compiler writer generate object program using powerful machine instruction possibly compiler eliminated machine execute source code directly hardware imagine idea set tone product marketing early common practice equate bigger instruction set powerful computer clock speed increasing multiple increase instruction set complexity fetter new model computer wasn t tremendous net increase speed cisc machine kept getting faster spite increased operation complexity turned assembly language programmer used complicated machine instruction compiler generally did dif ficult compiler recognize complicated instruction used real problem optimization verbatim translation source construct isn t ef ficient optimizing compiler work simplifying eliminating redundant computation pas optimizing compiler opportunity use complicated instruction tend disappear risc risc machine built fact seymour cray built cdc given cost component technical barrier expectation computer used probably chosen cisc design benefit hindsight exact inspiration led developing high performance risc microprocessor subject debate regardless motivation risc designer obvious pressure affected development risc number transistor fit single chip increasing clear eventually able fit component processor board single chip technique pipelining explored improve performance v instruction instruction execution time varying number microcode step implementing pipeline dif ficult compiler improved sequence lined instruction outperformed equivalent complicated instruction appendix processor architecture appendix b looking assembly language risc designer sought create high performance processor fast clock rate cpu fit single chip cost decreased reliability increased clock speed increased risc processor implementation use single chip accomplish task necessary discard existing cisc instruction set develop new minimal instruction set fit single chip term reduced instruction set computer sense reducing instruction set end mean end generation risc chip restriction number component manufactured single chip severe forcing designer leave hardware support instruction earliest risc processor support hardware did support integer multiply hardware instruction implemented using software routine combined instruction microcode sort earliest risc processor severely reduced overwhelming success reason took time compiler operating system user software retuned advantage new processor application depended performance implemented instruction performance suf fered dramatically risc instruction simpler instruction needed accomplish task risc instruction bit long commonly used cisc instruction short bit risc program executables lar ger result issue risc program fetch memory instruction cisc program increased appetite instruction actually clogged memory bottleneck suf ficient cache added risc processor sense view cache risc processor microcode store cisc processor reduced overall appetite instruction loaded memory risc processor designer worked issue manufacturing capability improved battle existing called cisc processor new risc successful processor cisc processor designer mature design tuned popular software kept adding performance trick system time motorola evolved cisc processor referred risc processor footnote did taking single instruction risc processor eventually successful logic available single chip increased operation added chip additional logic used add cache solve memory bottleneck problem lar ger appetite instruction memory change moved risc architecture defensive fensive risc processor quickly known af fordable point capability compared cisc processor footnote excellent performance scientific engineering application ef fectively created new type computer workstation w orkstations expensive personal computer cost suf ficiently low workstation heavily used cad graphic design area emer ging workstation market ef fectively created new computer company apollo sun microsystems silicon graphic typical cisc microprocessor supported operation separate coprocessor existing company created competitive risc processor addition cisc design ibm developed rio processor excellent performance alpha dec excellent performance number computing benchmark developed p series processor excellent performance motorola ibm teamed develop powerpc series risc processor used ibm apple system end risc revolution performance risc processor impressive single multiprocessor server system quickly took minicomputer market currently encroaching traditional mainframe market characterizing risc risc design philosophy set goal course risc processor personality number feature commonly machine people consider risc instruction pipelining pipelining execution uniform instruction length delayed branching architecture simple addressing mode list highlight dif ferences risc cisc processor naturally type architecture common us register memory technique used cisc machine cache instruction pipeline fundamental dif ferences risc speed advantage focusing smaller set powerful instruction make possible build faster computer notion risc machine generally simpler cisc machine isn t correct feature functional pipeline sophisticated memory system ability issue instruction clock make latest risc processor complicated built furthermore complexity lifted instruction set driven compiler making good optimizing compiler prerequisite machine performance let s role computer architect look item list understand s important pipeline digital computer risc cisc happens step clock signal pace computer s circuitry rate clock clock speed determines overall speed processor upper limit fast clock given computer number parameter place upper limit clock speed including semiconductor technology packaging length wire tying piece longest path processor possible reach blazing speed optimizing parameter costcan prohibitive furthermore exotic computer don t make good fice mate require power produce noise heat lar ge incentive manufacturer stick manufacturable marketable technology reducing number clock tick take execute individual instruction good idea cost practicality issue certain point greater benefit come partially overlapping instruction progress simultaneously instance addition perform nice execute time obvious approach start simultaneously addition execute complete time take perform result throughput effectively doubled downside need hardware adder situation space usually premium especially early risc processor approach overlapping execution fective execution imagine like moment launching operation launch waiting complete start type right like addition nearly performance execution duplicated hardware mechanism doe exist varying degree computer cisc risc s called pipeline pipeline take advantage fact operation divided identifiable step us different resource processor footnote simple analogy imagine line drive window window customer order pay food bagged delivered customer second customer order busier restaurant window order ahead second window pay ahead window pull grab food roar f distance wait pipelined slightly longer wait restaurant thepipeline solution significantly better multiple customer processed simultaneously pipeline link show conceptual diagram pipeline operation entering left proceeds clock tick emer ging right given pipeline stage independent operation flight time long instruction delayed long previous instruction clear pipeline stage consider powerful mechanism taken clock tick single result pipeline produce result clock tick pipelining useful procedure divided stage instruction processing fit category job retrieving instruction memory figuring doe doing separate step usually lump talk executing instruction number step varies depending processor using illustration let s say instruction fetch processor fetch instruction memory instruction decode instruction recognized decoded operand fetch processor fetch operand instruction need operand register memory execute instruction get executed writeback processor writes result supposed register possibly memory ideally instruction entering operand fetch stage instruction enters instruction decode stage instruction start instruction fetch pipeline stage deep possible instruction flight instruction complete clock cycle simple illustration instruction pipelining complicated real life step able occur dif ferent instruction simultaneously delay stage coordinated follow link instruction executed simultaneously processor instruction dif ferent stage execution instruction flight pipeline instance complicated memory access occurs stage instruction need delayed going stage take time calculate operand s address retrieve memory rest pipeline stalled simpler instruction sitting earlier stage t continue traf fic ahead clear imagine jump new program address caused statement disrupt pipeline flow processor doesn t know instruction branch decode stage usually doesn t know branch taken execute stage shown link cycle branch instruction fetched processor blindly fetch instruction sequentially start instruction pipeline detecting branch branch fall great shape pipeline simply executes instruction s branch instruction branch jump away partially processed instruction executed order business discard instruction pipeline turn instruction actually going execute stage throw away hurting ef ficiency processor able clear pipeline restart pipeline branch destination unfortunately branch instruction occur instruction program executed branch fifth instruction half branch fell lost ef ficiency restarting pipeline branch percent need optimal condition pipeline moving condition instruction pipelining big win especially risc processor interestingly idea date late early v ac larc ibm stretch instruction pipelining mainstreamed cdc ibm family introduced pipelined instruction unit machine represented cisc design respectively day sophisticated technique applied instruction pipelining machine overlap instruction execution commonplace pipelined operation execution stage operation longer execution stage computation operation typically pipelined generally includes addition subtraction multiplication comparison conversion include square root division pipelined operation started calculation continue stage delaying rest processor result appears register point future processor limited overlap pipeline support internal component pipeline shared adding multiplying normalizing rounding intermediate result forcing restriction begin new operation case point operation started cycle regardless previous point operation w e say operation fully pipelined number stage pipeline af fordable computer decreased year transistor newer algorithm make possible perform addition multiplication just cycle generally dif ficult instruction performin single cycle multiply dedicate hardware design operate single cycle moderate clock rate uniform instruction length sample instruction pipeline stage instruction fetch instruction decode operand fetch execution writeback w e want pipeline able process instruction various stage stalling decomposing operation identifiable part roughly time challenging risc computer designer working cisc instruction set s especially dif ficult cisc instruction come varying length simple return subroutine instruction byte long instance longer instruction say add register memory location leave result register number byte fetched known fetch stage pipeline shown link variable length instruction make pipelining dif ficult processor way knowing long instruction reach decode stage determines turn long instruction processor memory portion left stall pipeline w e eliminate problem requiring instruction length limited number instruction format shown link way instruction entering pipeline known priori complete needing memory access easier processor locate instruction field specify register constant altogether risc assume fixed instruction length pipeline flow smoothly cisc versus risc instruction delayed branch described earlier branch significant problem pipelined architecture penalty cleaning pipeline misguessed branch risc design require instruction branch instruction called branch delay slot executed matter way branch go instruction position useful harmless whichever way branch proceeds expect processor execute instruction following branch case plan pinch used slight variation processor ability annul squash instruction appearing branch delay slot turn shouldn t issued add add store sub subtract store bra branch zero instruction branch delay slot branch delay slot appeared clever solution eliminating pipeline stall associated branch operation processor moved cuting instruction simultaneously approach needed footnote interestingly delay slot longer critical processor execute instruction simultaneously strong reason remove feature removing delay slot compatible breaking existing code t o degree branch delay slot baggage new architecture continue support robust way eliminating pipeline stall predict direction branch using table stored decode unit decode stage cpu notice instruction branch consult table kept recent behavior branch make guess based guess cpu immediately begin fetching predicted location long guess correct branch cost exactly instruction prediction wrong instruction process celled resulting wasted time ef fort simple branch prediction scheme typically correct time significantly reducing overall negative performance impact pipeline stall branch recent risc design incorporate type branch prediction making branch delay slot ef fectively unnecessary mechanism reducing branch penalty conditional execution instruction look like branch source code turn special type instruction object code useful replace test branch sequence altogether following line code capture sense conditional branch b c d e endif using branch require branch ensure proper value ended using conditional execution generate code look follows compare b c true d conditional instruction false e conditional instruction sequence instruction branch assignment executes act branch prediction needed pipeline operates perfectly cost taking approach lar ge number instruction branch path seldom executed using traditional branch instruction model e architectur e instruction set architecture memory reference limited explicit load store instruction instruction make memory reference instruction cisc processor arithmetic logical instruction include embedded memory reference reason limiting load store instruction improvement want instruction length reason given fixed length impose budget limit come describing operation doe register us instruction referenced memory performed calculation wouldn t fit instruction word second giving instruction option reference memory plicate pipeline computation address calculation plus instruction supposed execution stage throw hardware restricting memory reference explicit load store avoid problem entirely instruction perform address calculation operation instruction reason limiting memory reference explicit load store time instruction clock cycle general instruction embedded memory reference hung operand fetch stage extra cycle waiting reference complete faced instruction pipeline stall explicit load store instruction kick f memory reference pipeline s execute stage completed later time complete immediately depends processor cache operation downstream require result reference s right long far downstream reference time complete simple addr essing mode just want simplify instruction set want simple set memory addressing mode reason complicated address calculation require multiple memory reference time stall pipeline doesn t mean program t use elegant data structure compiler explicitly generates extra address arithmetic need long count fundamental addressing mode hardware fact extra addressarithmetic easier compiler optimize faster form link link course cutting number addressing mode mean memory reference real instruction taken cisc machine executes quickly generally performance risc processor holy grail early risc machine achieve instruction clock idealized risc computer running say mhz able issue million instruction second assuming perfect pipeline scheduling seen single instruction clock tick instruction pipeline pipeline kept aggregate rate fact approach instruction clock basic pipelined risc processor design successful competition ensued determine company build best risc processor risc designer used basic method develop competitive risc processor improve manufacturing process simply make clock rate faster simple design make smaller faster approach taken alpha processor alpha processor typically clock rate double closest competitor add duplicate compute element space available manufacture chip transistor allow instruction executed cycle double performance increasing clock rate technique called superscalar increase number stage pipeline instruction truly decomposed evenly say stage clock rate theoretically doubled requiring new manufacturing process technique called superpipelining mips processor used technique success superscalar pr ocessors way instruction clock starting operation possibly separate pipeline link integer addition multiplication perform possible begin simultaneously provided independent long multiplication doe need output addition operand vice versa y ou execute multiple compare integer addition time provided independent term used superscalar processor multiple instruction issue processor decomposing serial stream number variety operation run parallel depends program processor program usable parallelism multiple thing processor appropriate assortment functional unit ability busy idea conceptually simple challenge hardware designer compiler writer opportunity thing parallel expose danger violating precedence performing computation wrong order superpipelined pr ocessors roughly stated simpler circuitry run higher clock speed role cpu designer looking instruction pipeline processor decide reason t speed stage complicated going placing limit fast pipeline stage clocked unison slowest form weak link chain divide complicated stage complicated portion increase overall speed pipeline called superpipelining instruction pipeline stage complexity stage work pipelined processor higher throughput increased clock speed link show pipeline used mips processor mips instruction pipeline theoretically reduced complexity allows processor clock faster achieve nearly performance superscalar processor instruction mix preference illustration picture superscalar processor unit executing program composed solely calculation unit go unused reduces superscalar performance half compared theoretical maximum superpipelined processor hand perfectly happy handle unbalanced instruction mix speed superpipelines new deep pipeline employed past notably cdc label marketing creation draw contrast superscalar processing form ef ficient computing superpipelining combined approach y ou superscalar machine deep pipeline dec axp mips example fact probably expect faster pipeline stage commonplace remember superpipelines risc mean fast know r risc mean lately number component manufactured chip increased cpu designer looking way make processor faster adding feature w e talked feature multiplier fast lot register cache feature space left design control section processor automated bad add just new instruction especially simulation indicate overall increase speed doe mean add instruction risc instruction set architecture isa w ould suggested term trend fisc fast instruction set computer point reducing number instruction goal goal build fastest possible processor manufacturing cost constraint footnote people ar gue forever sense reducing instruction set end mean end type instruction added architecture include addressing mode decrement counter branch specialized graphic instruction sun vi set hp graphic instruction mips digital medium extentions mdmx intel mmx instruction interestingly reason feasible adder unit little space possible adder decode unit unit visualization instruction set little chip area provide ganged computation allow register used perform operation single execution architecture satisfied performance level computing equipment processor designer t superscalar processor successful design able execute instruction cycle average using trick described far able manufacture chip increasing transistor count naturally progress superscalar processor fundamental problem face trying functional unit busy s difficult contiguous set instruction executed parallel s easy say compiler solve solution problem allow processor effectively use functional unit cycle hide memory latency der execution speculative execution execution allows later instruction processed earlier instruction completed processor betting instruction execute processor precomputed answer instruction need way portion risc design philosophy turned new processor speculative computation understand architecture important separate concept computing value instruction actually executing instruction let s look simple example ld load memory instruction various kind fdiv fdiv assume executing load instruction loaded earlier instruction take cycle divide instruction need divide unit ld fdiv start divide unit computing fdiv right storing result temporary scratch area better arrive fdiv know result calculation copy scratch area fdiv appear execute cycle sound farfetched processor processor able speculatively compute result processor know instruction actually execute accomplishes allowing instruction start finish allowing later instruction start earlier instruction finish store instruction limbo started finished processor need space processor space instruction called instruction r eorder buffer irb pipeline processor pipeline link look somewhat dif ferent risc pipeline stage instruction fetch decode decode includes branch prediction using table indicates probable behavior branch instruction decoded branch predicted instruction placed irb computed soon possible pipelinethe irb hold instruction waiting execute reason sense fetch phase operate buf fer fill time decode unit predicts branch following instruction marked dif ferent indicator easily prediction turn wrong w ithin buf fer instruction allowed computational unit instruction operand value instruction computing result executed instruction input value available computation unit computed result computation stored extra register visible programmer called rename r egisters processor allocates rename register needed instruction computed execution unit pipeline stage depending type instruction look like traditional superscalar risc processor t ypically instruction begin computation irb cycle provided instruction available input operand suf ficient computational unit instruction result instruction computed stored rename register instruction wait preceding instruction finish know instruction actually executes addition computed result instruction flag associated exception example happy program crashed following message error divide zero precomputing divide case got instruction save time branch mispredicted turned going execute divide blow hard feeling signed speculatively computed instruction divide zero cpu simply store fact know instruction execute moment program legitimately crashed branch doe mispredicted lot bookkeeping occur quickly message sent unit discard instruction control flow path incorrect branch instead calling phase pipeline writeback s called retire phase executes instruction computed retire phase keep track instruction execution order retires instruction program order posting result rename register actual register raising exception necessary typically instruction retired cycle pipeline actually pipeline connected buffer allow instruction processed order speculative computation going retire unit force processor appear simple risc processor predictable execution note congratulation reaching end long chapter w e talked little bit old computer cisc risc epic mentioned supercomputer passing think s interesting observe risc processor branch f tree idea gone risc design borrowed type computer evolved risc risc started discontinuity hint risc revolution cdc ibm project really forced world good cpu designer berkeley stanford risc matured improvement time appears reached limit performance microprocessor new architectural breakthrough improving single cpu performance long continue clear long competition continues significant performance headroom using execution clock rate typical mhz mhz dec s alpha planned order execution mhz vendor beginning reveal plan processor clocked mhz ghz unfortunately developing new processor expensive task company mer ge competition diminishes rate innovation slow hopefully seeing processor chip superscalar clocked ghz eliminate competition let cpu designer rest laurel point scalable parallel processing suddenly interesting designer tackle fundamental architectural problem lar gest memory system architecture epic alleviate latency problem somewhat memory bottleneck good news memory performance improves slowly cpu performance memory performance doe improve time w e ll look technique building memory discussed link exercise come end chapter book like exercise engineering text exercise thought experiment answer designed thinking hardware exer cise pr oblem speculative execution safe certain type instruction result discarded turn instruction shouldn t executed point instruction memory operation class instruction speculative execution trickier particularly chance generating exception instance dividing zero taking square root negative number cause exception circumstance speculative memory reference cause exception exer cise pr oblem picture machine pipeline stage deep s ridiculously deep deliver new result nanosecond pipeline peak throughput rate gflop case throughput rate mflop characteristic program need advantage pipeline assembly language appendix look assembly language produced number dif ferent compiler number dif ferent architecture survey revisit issue cisc versus risc strength weakness dif ferent architecture survey roughly identical segment code used code relatively long loop adding array storing result array loop written tran tran loop follows subroutine addem b c n real b c integer n n b c enddo end c version n b c gathered example year number dif ferent compiler result particularly scientific intended review particular architecture compiler version just example kind thing learn looking output compiler intel intel processor used original ibm personal computer traditional cisc processing feature severely limited transistor count register register generally specific function t o support lar ge memory model set segment register leading memory operation limitation mean memory access take minimum instruction interestingly similar pattern occurs risc processor notice point code move value ax register bx register need perform computation ax register note integer computation intel mov word ptr bp bp mov ax word ptr bp load cmp ax word ptr bp check bge shl multiply mov bx ax bx add bx word ptr bp bx address b offset mov e word ptr bp address mov ax e word ptr bx load b mov bx word ptr bp load shl multiply add bx word ptr bp bx address c offset mov e word ptr bp address add ax e word ptr bx load c mov bx word ptr bp load shl multiply add bx word ptr bp bx address offset mov e word ptr bp address mov e word ptr bx ax store word ptr bp increment memory jmp register variable kept memory loaded time loop instruction end loop actually update value memory interestingly loop value reloaded memory type architecture available register strain flexibility compiler optimization practical motor ola section examine classic cisc processor motorola used build macintosh computer sunworkstations w e happened run code bbn butterfly parallel processing processor motorola architecture relatively easy program assembly language plenty register relatively easy use cisc instruction set keep assembly language programming quite simple instruction perform multiple operation single instruction use example progression optimization level using compiler version loop example optimization note contains value movl store memory loop end lea address b fmoves load b lea address c fadds load c add lea address fmoves store addql increment subql decrement n tstl bnes value stored register time loop s incremented time register initialized value n decremented time loop time loop stored memory proper value end memory loop terminates register preloaded address array b c respectively tran array begin subtract address use fset lea instruction effectively subtracting address register storing following instruction performs address computation translation array reference fmoves load b instruction retrieves value memory address computed multiplying number adding value matter fact lea fmoves instruction combined follows fmoves load b compute memory address instruction multiplies add content subtracts resulting address used load byte register literal translation fetching b assembly set track compiler trying f make use nifty assembly language instruction like intel architecture fadds instruction add value memory value register leaf result addition register unlike intel register store quite value used loop n address b c register save memory operation c example compiled c version loop normal optimization turned w e c perspective array code c view array extension pointer c loop index advance fset pointer beginning array address address b address c n moveq initialize bra jump end loop movl make copy movl asll multiply word size movl address register fmoves l load b movl address c fadds l add c fmoves l store addql increment cmpl bit value copied register multiplied using left shift strength reduction interestingly value register multiplied register address c b respectively load add store base address computation added fset compute address simplistic optimization primarily trying maximize value kept register loop execution overall s relatively literal translation c language semantics c assembly way c designed generate relatively ef ficient code requiring highly sophisticated optimizer optimization example tran version compiled highest level optimization available compiler aggressive approach loop address c address b address fmoves load b fadds add c fmoves store addql advance addql advance addql advance subql decrement tstl bnes f compiler smart address adjustment outside loop store adjusted address b c register load add store quick succession advance array address perform subtraction determine loop complete tight code bear little resemblance original tran code sparc ar chitectur e example performed using sp arc architecture using tran sp arc architecture classic risc processor using access memory register delayed branching examine code lowest optimization loop ld address b sethi hi address lo ld load sll multiply add figure effective address b ld load b ld address c sethi hi address lo ld load sll multiply add figure effective address b ld load c fadds floating point add ld address sethi hi address lo ld load sll multiply add figure effective address st store sethi hi address lo ld load add increment sethi hi address lo st store sethi hi address lo ld load ld load n cmp compare ble nop branch delay slot pretty poor code w e don t need line line quick observation make value loaded memory time loop address computedsix time loop time take instruction tricky memory addressing mode multiplying byte offset explicitly time use shift t o add insult injury branch delay slot ask generate code bad w ell s compiler isn t capable generating ef ficient code shall explanation optimization level simply doe translation tuples intermediate code machine language y ou draw line example precisely identify instruction came tuples reason generate code using simplistic approach guarantee program produce correct result looking code s pretty easy ar gue doe exactly tran code doe y ou track single assembly statement directly tran statement s pretty clear don t want execute code high performance production environment optimization moderate optimization example enable optimization save sp sp rotate register window add address st store stack add address b st store stack add address c st store stack sethi hi address portion add lo address lower portion ld n fourth parameter addition st store n stack st set memory copy ld kind redundant cmp check n bg don t loop nop delay slot ld load branch delay slot loop ld address b sll multiply ld b ld load memory ld address c sll multiply ld c fadds add ld load memory ld address sll multiply yes st ld load memory add increment register st store memory ld load register ld load n register cmp n ble ld branch delay slot significant improvement previous example loop constant computation subtracting hoisted loop w e loaded time loop iteration strangely compiler didn t choose store address b c register alleven plenty register perplexing fact loaded value memory immediately stored exact register bright spot branch delay slot iteration load loop started successive iteration load branch delay slot loop comparing code moderate optimization code begin sense risc overnight sensation turned unsophisticated compiler generate tighter code cisc processor risc processor risc processor executing extra instruction compensate lack slick feature instruction set processor faster clock rate execute instruction doe better performance slower ef ficient processor shall soon cisc advantage evaporate particular example higher optimization increase optimization compiler generates better code s important remember compiler used example optimization level compiler looked code suf ficiently know didn t need rotate register window save instruction clearly compiler looked register usage entire routine note didn t rotate register window just use o register caller address element calling convention address element b calling convention address element c calling convention address n calling convention ld load n cmp check bl check zero trip loop delay slot set ld load b time ld load c fadds add add increment add increment address b add increment address c cmp check loop termination st store add increment address ble branch annul ld load b retl leaf return window nop branch delay slot tight code register contain address element b c respectively point right value iteration loop value stored memory kept global register instead multiplying simply advance address byte iteration branch delay slot utilized branch branch loop us annul feature cancel following load branch fall interesting observation regarding code striking similarity code code generated optimization level fmoves load b fadds add c fmoves store addql advance addql advance addql advance subql decrement tstl bnes code sequence nearly identical sp arc doe extra load architecture sp arc incremented compared n decremented compared zero aptly show advancing compiler optimization capability quickly nifty feature cisc architecture useless cisc processor code used simple form instruction produce fastest execution time note code sequence generated able eliminate addql instruction using saving instruction add little loop unrolling tight code course broadly deployed workstation processor really got chance test drive convex section show result compiling convex supercomputer addition normal register vector computer vector register contain element processor perform operation subset register single instruction hard claim vector supercomputer risc cisc simple lean instruction set instruction implement loop somewhat convex scalar register vector register address register vector register element vector length register control element vector register processed vector instruction vector length entire register processed code implement loop follows vl set vector length n load b vector register load c vector register add vector register store result decrement n advance address advance address b advance address c check n initially vector length register set assume iteration n greater instruction vector load instruction register load element register instruction load element following instruction add register place result vector register element register stored memory element processed n decremented did process element add address byte element loop point iteration n exact multiple vector length register vector instruction process remaining element challenge vector processor allow instruction begin executing previous instruction completed example load register partially completed processor actually begin adding element waiting rest element arrive approach starting vector instruction previous vector instruction completed called chaining chaining important feature maximum performance vector processor ibm ibm generally credited risc processor cracked linpack benchmark characterized strong performance excellent memory bandwidth risc workstation basis ibm s scalable parallel processor example program run use style instruction middle risc processor support instruction combine decrement test branch operation single instruction special register count register instruction fetch unit store current value counter fetch unit add unit perform decrement type feature creeping risc architecture occuring plenty chip space wide range program run faster type instruction s added assembly code ai address ai address b ai address c bcr mtspr ctr store counter register lfsu pre increment load lfsu pre increment load fa frsp stfsu store bc branch counter support memory addressing mode add value address register using address register interestingly feature branch count load eliminate instruction compared pure sp arc processor sparc processor instruction body loop advantage particular loop significant processor superscalar instruction eliminated integer instruction superscalar processor integer instruction simply execute integer unit unit busy performing point computation conclusion section attempted understanding variety assembly language produced compiler dif ferent optimization level dif ferent computer architecture point tuning code quite instructive look generated assembly language sure compiler doing really stupid slowing don t tempted rewrite portion assembly language usually problem solved cleaning streamlining level source code setting proper compiler flag interesting people actually learn assembly language folk compiler best teacher assembly language adding appropriate option compiler start giving lesson suggest don t print code page useless variable declaration example cut useless information best view assembly editor print portion pertains particular loop tuning